<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>simpaticoai | Intelligent Interviewer</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/pdf.js/3.11.174/pdf.min.js"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600&display=swap" rel="stylesheet">
    <style>
        :root {
            --bg: #05050a;
            --surface: #0f1016;
            --primary: #6366f1;
            --accent: #a855f7;
            --text: #e2e8f0;
            --text-dim: #64748b;
        }

        body {
            margin: 0;
            background: var(--bg);
            color: var(--text);
            font-family: 'Inter', sans-serif;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            min-height: 100vh;
            overflow: hidden;
        }

        /* --- THE ORB --- */
        .orb-container { position: relative; width: 200px; height: 200px; display: flex; align-items: center; justify-content: center; margin-bottom: 40px; }
        .orb {
            width: 120px; height: 120px;
            background: linear-gradient(135deg, var(--primary), var(--accent));
            border-radius: 50%;
            box-shadow: 0 0 60px rgba(99, 102, 241, 0.4);
            position: relative; z-index: 2;
            transition: all 0.2s cubic-bezier(0.25, 0.46, 0.45, 0.94);
        }

        /* Animation States */
        .orb.idle { animation: breathe 4s ease-in-out infinite; }
        .orb.listening { 
            background: linear-gradient(135deg, #22c55e, #10b981);
            box-shadow: 0 0 60px rgba(34, 197, 94, 0.4);
            animation: pulse-green 1.5s infinite;
        }
        .orb.thinking {
            background: linear-gradient(135deg, #f59e0b, #d97706);
            box-shadow: 0 0 60px rgba(245, 158, 11, 0.4);
            animation: spin 1.5s linear infinite;
            border-radius: 40%;
        }
        .orb.speaking {
            animation: breathe-fast 1s ease-in-out infinite;
        }

        .ring { position: absolute; border-radius: 50%; border: 1px solid rgba(255, 255, 255, 0.05); top: 50%; left: 50%; transform: translate(-50%, -50%); z-index: 1; }
        .ring:nth-child(1) { width: 200px; height: 200px; animation: spin 10s linear infinite; border-color: rgba(99, 102, 241, 0.1); }
        .ring:nth-child(2) { width: 300px; height: 300px; animation: spin-rev 15s linear infinite; border-style: dashed; }
        
        .interface { width: 100%; max-width: 500px; text-align: center; z-index: 10; }
        h1 { font-weight: 300; margin-bottom: 5px; font-size: 1.5rem; }
        .status-pill { display: inline-block; padding: 6px 16px; background: rgba(255, 255, 255, 0.05); border: 1px solid rgba(255, 255, 255, 0.1); border-radius: 50px; font-size: 0.85rem; color: var(--text-dim); margin-bottom: 30px; backdrop-filter: blur(5px); }
        .timer { font-family: monospace; color: var(--text-dim); margin-top: 10px; opacity: 0; }
        .timer.active { opacity: 1; }

        .btn { background: var(--surface); color: var(--text); border: 1px solid rgba(255, 255, 255, 0.1); padding: 12px 24px; border-radius: 12px; cursor: pointer; font-weight: 600; margin-top: 10px; }
        .btn-primary { background: var(--primary); border-color: var(--primary); }
        .btn-danger { background: rgba(239, 68, 68, 0.1); color: #ef4444; border-color: rgba(239, 68, 68, 0.2); }
        .btn-danger:hover { background: rgba(239, 68, 68, 0.2); }
        .file-trigger { border: 2px dashed rgba(255, 255, 255, 0.2); padding: 30px; border-radius: 16px; cursor: pointer; display:block; color: var(--text-dim); }
        .file-trigger:hover { border-color: var(--primary); color: var(--text); background: rgba(99, 102, 241, 0.05); }
        input[type="file"] { display: none; }

        @keyframes breathe { 0%, 100% { transform: scale(1); } 50% { transform: scale(1.05); } }
        @keyframes breathe-fast { 0%, 100% { transform: scale(1); } 50% { transform: scale(1.15); } }
        @keyframes pulse-green { 0% { box-shadow: 0 0 0 0 rgba(34, 197, 94, 0.7); } 70% { box-shadow: 0 0 0 20px rgba(34, 197, 94, 0); } 100% { box-shadow: 0 0 0 0 rgba(34, 197, 94, 0); } }
        @keyframes spin { 100% { transform: rotate(360deg); } }
        @keyframes spin-rev { 100% { transform: rotate(0deg); } }

        /* Modal */
        .modal { position: fixed; top:0; left:0; width:100%; height:100%; background: rgba(0,0,0,0.9); display: none; align-items: center; justify-content: center; z-index: 100; }
        .modal-content { background: var(--surface); padding: 40px; border-radius: 24px; max-width: 600px; width: 90%; max-height: 80vh; overflow-y: auto; text-align: left; border: 1px solid rgba(255,255,255,0.1); }
    </style>
</head>
<body>

    <div class="orb-container">
        <div class="ring"></div>
        <div class="ring"></div>
        <div id="orb" class="orb idle"></div>
    </div>

    <div class="interface">
        <h1 id="mainTitle">Evalis AI</h1>
        <div id="status" class="status-pill">Waiting for Resume</div>
        
        <div id="setupPanel">
            <label class="file-trigger">
                <span>ðŸ“‚ Upload PDF Resume</span>
                <input type="file" id="cvInput" accept=".pdf">
            </label>
            <br>
            <button id="startBtn" class="btn btn-primary" style="display:none; width:100%;">Start Interview</button>
        </div>

        <div id="activePanel" style="display:none;">
            <button id="endBtn" class="btn btn-danger">End Session</button>
            <div id="timer" class="timer">15:00</div>
        </div>
    </div>

    <div id="reportModal" class="modal">
        <div class="modal-content">
            <h2 style="color:var(--primary); margin-top:0;">Evaluation Report</h2>
            <div id="reportText" style="line-height: 1.6; color: var(--text-dim); white-space: pre-wrap;"></div>
            <button onclick="location.reload()" class="btn btn-primary" style="margin-top:20px; width:100%;">Start New Session</button>
        </div>
    </div>

<script>
    // --- CONFIGURATION ---
    const API_URL = "https://evalis-ai.simpaticohrconsultancy.workers.dev";
    pdfjsLib.GlobalWorkerOptions.workerSrc = "https://cdnjs.cloudflare.com/ajax/libs/pdf.js/3.11.174/pdf.worker.min.js";

    // --- DETECT PLATFORM ---
    const isAndroid = typeof Android !== "undefined";

    // --- STATE ---
    let state = {
        cvText: "",
        history: [],
        timeLeft: 900 // 15 mins
    };
    
    // Safety flags for continuous listening
    let isSessionActive = false;
    let isAiSpeaking = false;
    let currentUtterance = null; // Global variable prevents Chrome garbage collection mid-speech

    // --- DOM ELEMENTS ---
    const orb = document.getElementById('orb');
    const status = document.getElementById('status');
    const timerDisplay = document.getElementById('timer');

    // --- UNIFIED VISUAL UPDATES ---
    function setOrbState(mode) {
        orb.className = 'orb ' + mode;
        if(mode === 'listening') status.textContent = "Listening...";
        else if(mode === 'thinking') status.textContent = "Analysing response...";
        else if(mode === 'speaking') status.textContent = "AI Speaking...";
        else status.textContent = "Ready";
    }

    // --- CORE INTERFACE FUNCTIONS (The Bridge) ---

    // 1. START LISTENING
    function startListening() {
        if (!isSessionActive) return;
        setOrbState('listening');
        if (isAndroid) {
            Android.startInterview(); 
        } else {
            try {
                recognition.start();
            } catch(e) { /* ignore if already started */ }
        }
    }

    // 2. SPEAK TEXT
    function speak(text) {
        setOrbState('speaking');
        isAiSpeaking = true;

        if (isAndroid) {
            Android.speak(text);
        } else {
            // Stop listening before speaking to prevent the AI from hearing itself
            try { recognition.stop(); } catch(e){} 

            currentUtterance = new SpeechSynthesisUtterance(text);
            const voices = window.speechSynthesis.getVoices();
            const preferred = voices.find(v => v.name.includes('Google US English') || v.name.includes('Natural'));
            if(preferred) currentUtterance.voice = preferred;
            
            // OPTIMIZED: Slower, more natural speaking rate
            currentUtterance.rate = 0.95; 
            
            currentUtterance.onend = () => {
                isAiSpeaking = false;
                onFinishedSpeaking(); 
            };
            
            currentUtterance.onerror = () => {
                isAiSpeaking = false;
                onFinishedSpeaking();
            };

            window.speechSynthesis.speak(currentUtterance);
        }
    }

    // 3. HANDLE RESULTS (Called by PC or Android)
    async function handleUserResponse(transcript) {
        if (!transcript.trim()) return;

        setOrbState('thinking');
        
        // Prepare Data
        const fd = new FormData();
        fd.append("mode", "interview");
        fd.append("history", JSON.stringify(state.history));
        fd.append("text", transcript);
        fd.append("cvText", state.cvText);

        try {
            const res = await fetch(API_URL, { method: "POST", body: fd });
            const data = await res.json();
            
            state.history = data.history;
            speak(data.reply);
        } catch (e) {
            console.error(e);
            status.textContent = "Connection Error. Retrying...";
            setTimeout(() => startListening(), 2000);
        }
    }

    // --- ANDROID SPECIFIC CALLBACKS ---
    window.onRecognitionResult = (text) => {
        handleUserResponse(text);
    };

    window.onFinishedSpeaking = () => {
        if(state.history.length > 0 && isSessionActive) {
            startListening();
        }
    };

    // --- PC SPECIFIC SETUP (Web Speech API) ---
    let recognition;
    if (!isAndroid) {
        const Recognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        if (Recognition) {
            recognition = new Recognition();
            
            // OPTIMIZED: True continuous listening (allows user pauses without cutting off)
            recognition.continuous = true; 
            recognition.interimResults = false;
            recognition.lang = 'en-US';
            
            recognition.onresult = (event) => {
                // Get the very last finalized result because continuous=true accumulates them
                const lastResultIndex = event.results.length - 1;
                const text = event.results[lastResultIndex][0].transcript;
                
                if (text.trim()) {
                    try { recognition.stop(); } catch(e){} // Pause mic to process
                    handleUserResponse(text);
                }
            };
            
            // OPTIMIZED: Auto-restart logic for mobile browsers that randomly kill the mic
            recognition.onend = () => {
                if (isSessionActive && !isAiSpeaking) {
                    setTimeout(() => {
                        if (isSessionActive && !isAiSpeaking) {
                            try { recognition.start(); } catch(e) {}
                        }
                    }, 300);
                }
            };

            recognition.onerror = (e) => {
                console.log("Web Speech Error", e.error);
                // Errors like 'no-speech' will trigger onend, which handles the reliable restart
            };
        } else {
            status.textContent = "Browser not supported (Use Chrome)";
        }
    }

    // --- FILE UPLOAD & START ---
    document.getElementById('cvInput').onchange = async (e) => {
        const file = e.target.files[0];
        if(!file) return;
        
        status.textContent = "Reading Resume...";
        const buffer = await file.arrayBuffer();
        
        // Slightly safer PDF document loading
        const pdf = await pdfjsLib.getDocument({ data: new Uint8Array(buffer) }).promise;
        
        let fullText = "";
        for (let i = 1; i <= pdf.numPages; i++) {
            const page = await pdf.getPage(i);
            const textContent = await page.getTextContent();
            fullText += textContent.items.map(s => s.str).join(" ");
        }
        
        state.cvText = fullText;
        status.textContent = "Resume Loaded";
        document.getElementById('startBtn').style.display = "block";
    };

    document.getElementById('startBtn').onclick = async () => {
        isSessionActive = true;
        document.getElementById('setupPanel').style.display = 'none';
        document.getElementById('activePanel').style.display = 'block';
        document.getElementById('timer').classList.add('active');
        
        // Start Timer
        let timerInterval = setInterval(() => {
            if(state.timeLeft <= 0) {
                finishSession();
                clearInterval(timerInterval);
            }
            state.timeLeft--;
            const m = Math.floor(state.timeLeft / 60);
            const s = state.timeLeft % 60;
            timerDisplay.textContent = `${m}:${s < 10 ? '0'+s : s}`;
        }, 1000);

        // Initial AI Interaction
        setOrbState('thinking');
        
        const fd = new FormData();
        fd.append("mode", "start");
        fd.append("cvText", state.cvText);
        
        try {
            const res = await fetch(API_URL, { method: "POST", body: fd });
            const data = await res.json();
            state.history = data.history;
            speak(data.reply);
        } catch (e) {
            alert("Could not connect to AI Server.");
            isSessionActive = false;
        }
    };

    document.getElementById('endBtn').onclick = finishSession;

    async function finishSession() {
        isSessionActive = false; // Immediately stop auto-restarts
        if(!isAndroid) {
            try { recognition.stop(); } catch(e){}
            window.speechSynthesis.cancel();
        }
        
        document.getElementById('activePanel').style.display = 'none';
        setOrbState('thinking');
        status.textContent = "Generating Final Score...";
        
        const fd = new FormData();
        fd.append("mode", "score");
        fd.append("history", JSON.stringify(state.history));
        
        try {
            const res = await fetch(API_URL, { method: "POST", body: fd });
            const data = await res.json();
            
            document.getElementById('reportText').textContent = data.reply;
            document.getElementById('reportModal').style.display = 'flex';
        } catch(e) {
            console.error(e);
            document.getElementById('reportText').textContent = "Failed to load report. Check connection.";
            document.getElementById('reportModal').style.display = 'flex';
        }
    }

    // --- WAKE LOCK ---
    let wakeLock = null;

    async function requestWakeLock() {
        try {
            wakeLock = await navigator.wakeLock.request("screen");
            console.log('Wake Lock is active');
        } catch (err) {
            console.error('Wake Lock request failed:', err);
        }
    }

    document.addEventListener('visibilitychange', () => {
        if (document.visibilityState === 'visible') {
            requestWakeLock();
        } else {
            if (wakeLock) {
                wakeLock.release().then(() => {
                    wakeLock = null;
                    console.log('Wake Lock released');
                });
            }
        }
    });

    requestWakeLock();
</script>

</body>
</html>
