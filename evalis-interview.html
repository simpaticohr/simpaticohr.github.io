<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>simpaticoai | Intelligent Interviewer</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/pdf.js/3.11.174/pdf.min.js"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600&display=swap" rel="stylesheet">
    <style>
        :root {
            --bg: #05050a;
            --surface: #0f1016;
            --primary: #6366f1;
            --accent: #a855f7;
            --text: #e2e8f0;
            --text-dim: #64748b;
            --success: #22c55e;
        }

        body {
            margin: 0;
            background: var(--bg);
            color: var(--text);
            font-family: 'Inter', sans-serif;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            min-height: 100vh;
            overflow: hidden;
        }

        /* --- THE ORB & VISUALIZER --- */
        .orb-container { position: relative; width: 220px; height: 220px; display: flex; align-items: center; justify-content: center; margin-bottom: 40px; }
        
        .orb {
            width: 130px; height: 130px;
            background: linear-gradient(135deg, var(--primary), var(--accent));
            border-radius: 50%;
            box-shadow: 0 0 60px rgba(99, 102, 241, 0.3);
            position: relative; z-index: 2;
            transition: all 0.4s cubic-bezier(0.175, 0.885, 0.32, 1.275);
            display: flex; align-items: center; justify-content: center;
            overflow: hidden; /* Clips the waves to the orb shape */
        }

        #visualizer {
            position: absolute;
            width: 100%;
            height: 100%;
            opacity: 0.6;
        }

        /* Animation States */
        .orb.idle { animation: breathe 4s ease-in-out infinite; }
        .orb.listening { 
            background: #000;
            border: 2px solid var(--success);
            box-shadow: 0 0 40px rgba(34, 197, 94, 0.2);
        }
        .orb.thinking {
            background: linear-gradient(135deg, #f59e0b, #d97706);
            animation: spin 2s linear infinite;
            border-radius: 35%;
        }
        .orb.speaking {
            background: #000;
            border: 2px solid var(--primary);
        }

        .ring { position: absolute; border-radius: 50%; border: 1px solid rgba(255, 255, 255, 0.05); top: 50%; left: 50%; transform: translate(-50%, -50%); z-index: 1; }
        .ring:nth-child(1) { width: 200px; height: 200px; animation: spin 10s linear infinite; border-color: rgba(99, 102, 241, 0.1); }
        .ring:nth-child(2) { width: 320px; height: 320px; animation: spin-rev 15s linear infinite; border-style: dashed; }
        
        .interface { width: 100%; max-width: 500px; text-align: center; z-index: 10; }
        h1 { font-weight: 300; margin-bottom: 5px; font-size: 1.5rem; letter-spacing: 1px; }
        .status-pill { display: inline-block; padding: 6px 16px; background: rgba(255, 255, 255, 0.05); border: 1px solid rgba(255, 255, 255, 0.1); border-radius: 50px; font-size: 0.85rem; color: var(--text-dim); margin-bottom: 30px; backdrop-filter: blur(5px); transition: 0.3s; }
        .timer { font-family: monospace; color: var(--text-dim); margin-top: 10px; opacity: 0; font-size: 1.1rem; }
        .timer.active { opacity: 1; }

        .btn { background: var(--surface); color: var(--text); border: 1px solid rgba(255, 255, 255, 0.1); padding: 14px 28px; border-radius: 14px; cursor: pointer; font-weight: 600; margin-top: 10px; transition: 0.2s; }
        .btn-primary { background: var(--primary); border-color: var(--primary); }
        .btn-danger { background: rgba(239, 68, 68, 0.1); color: #ef4444; border-color: rgba(239, 68, 68, 0.2); }
        .file-trigger { border: 2px dashed rgba(255, 255, 255, 0.2); padding: 40px; border-radius: 20px; cursor: pointer; display:block; color: var(--text-dim); transition: 0.3s; }
        .file-trigger:hover { border-color: var(--primary); color: var(--text); background: rgba(99, 102, 241, 0.05); }
        input[type="file"] { display: none; }

        @keyframes breathe { 0%, 100% { transform: scale(1); } 50% { transform: scale(1.08); } }
        @keyframes spin { 100% { transform: rotate(360deg); } }
        @keyframes spin-rev { 100% { transform: rotate(-360deg); } }

        .modal { position: fixed; top:0; left:0; width:100%; height:100%; background: rgba(0,0,0,0.95); display: none; align-items: center; justify-content: center; z-index: 100; backdrop-filter: blur(10px); }
        .modal-content { background: var(--surface); padding: 40px; border-radius: 28px; max-width: 600px; width: 85%; max-height: 80vh; overflow-y: auto; border: 1px solid rgba(255,255,255,0.1); }
    </style>
</head>
<body>

    <div class="orb-container">
        <div class="ring"></div>
        <div class="ring"></div>
        <div id="orb" class="orb idle">
            <canvas id="visualizer"></canvas>
        </div>
    </div>

    <div class="interface">
        <h1 id="mainTitle">Evalis AI</h1>
        <div id="status" class="status-pill">Waiting for Resume</div>
        
        <div id="setupPanel">
            <label class="file-trigger">
                <span>ðŸ“‚ Upload PDF Resume</span>
                <input type="file" id="cvInput" accept=".pdf">
            </label>
            <br>
            <button id="startBtn" class="btn btn-primary" style="display:none; width:100%;">Start Interview</button>
        </div>

        <div id="activePanel" style="display:none;">
            <button id="endBtn" class="btn btn-danger">End Session</button>
            <div id="timer" class="timer">15:00</div>
        </div>
    </div>

    <div id="reportModal" class="modal">
        <div class="modal-content">
            <h2 style="color:var(--primary); margin-top:0;">Evaluation Report</h2>
            <div id="reportText" style="line-height: 1.7; color: var(--text-dim); white-space: pre-wrap;"></div>
            <button onclick="location.reload()" class="btn btn-primary" style="margin-top:25px; width:100%;">Start New Session</button>
        </div>
    </div>

<script>
    const API_URL = "https://evalis-ai.simpaticohrconsultancy.workers.dev";
    pdfjsLib.GlobalWorkerOptions.workerSrc = "https://cdnjs.cloudflare.com/ajax/libs/pdf.js/3.11.174/pdf.worker.min.js";

    const isAndroid = typeof Android !== "undefined";

    let state = {
        cvText: "",
        history: [],
        timeLeft: 900
    };
    
    let isSessionActive = false;
    let isAiSpeaking = false;
    let currentUtterance = null;

    // --- AUDIO VISUALIZER SETUP ---
    let audioCtx, analyser, dataArray, source;
    const canvas = document.getElementById('visualizer');
    const ctx = canvas.getContext('2d');

    async function initAudio() {
        if (audioCtx) return true;
        try {
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            audioCtx = new (window.AudioContext || window.webkitAudioContext)();
            analyser = audioCtx.createAnalyser();
            analyser.fftSize = 256;
            source = audioCtx.createMediaStreamSource(stream);
            source.connect(analyser);
            dataArray = new Uint8Array(analyser.frequencyBinCount);
            draw();
            return true;
        } catch (e) {
            alert("Microphone access is required for the interview.");
            return false;
        }
    }

    function draw() {
        requestAnimationFrame(draw);
        const width = canvas.width = canvas.offsetWidth;
        const height = canvas.height = canvas.offsetHeight;
        
        ctx.clearRect(0, 0, width, height);
        
        if (!isAiSpeaking && !isSessionActive) return;

        analyser.getByteFrequencyData(dataArray);
        
        let barWidth = (width / dataArray.length) * 2.5;
        let barHeight;
        let x = 0;

        // Change color based on who is speaking
        ctx.fillStyle = isAiSpeaking ? '#6366f1' : '#22c55e';

        for (let i = 0; i < dataArray.length; i++) {
            barHeight = dataArray[i] / 2;
            // Draw mirrored waves from the center for a cleaner look
            ctx.fillRect(x, (height / 2) - barHeight / 2, barWidth, barHeight);
            x += barWidth + 1;
        }
    }

    const orb = document.getElementById('orb');
    const status = document.getElementById('status');
    const timerDisplay = document.getElementById('timer');

    function setOrbState(mode) {
        orb.className = 'orb ' + mode;
        if(mode === 'listening') {
            status.textContent = "Listening...";
            status.style.color = "var(--success)";
            status.style.borderColor = "var(--success)";
        }
        else if(mode === 'thinking') {
            status.textContent = "Analyzing...";
            status.style.color = "var(--text-dim)";
        }
        else if(mode === 'speaking') {
            status.textContent = "AI Speaking...";
            status.style.color = "var(--primary)";
            status.style.borderColor = "var(--primary)";
        }
        else status.textContent = "Ready";
    }

    function startListening() {
        if (!isSessionActive) return;
        setOrbState('listening');
        if (isAndroid) {
            Android.startInterview(); 
        } else {
            try { recognition.start(); } catch(e) {}
        }
    }

    function speak(text) {
        setOrbState('speaking');
        isAiSpeaking = true;

        if (isAndroid) {
            Android.speak(text);
        } else {
            try { recognition.stop(); } catch(e){} 

            currentUtterance = new SpeechSynthesisUtterance(text);
            const voices = window.speechSynthesis.getVoices();
            currentUtterance.voice = voices.find(v => v.name.includes('Google US English') || v.name.includes('Natural')) || voices[0];
            
            // NATURAL AI SPEED
            currentUtterance.rate = 0.95; 
            
            currentUtterance.onend = () => {
                isAiSpeaking = false;
                onFinishedSpeaking(); 
            };
            window.speechSynthesis.speak(currentUtterance);
        }
    }

    async function handleUserResponse(transcript) {
        if (!transcript.trim()) return;
        setOrbState('thinking');
        
        const fd = new FormData();
        fd.append("mode", "interview");
        fd.append("history", JSON.stringify(state.history));
        fd.append("text", transcript);
        fd.append("cvText", state.cvText);

        try {
            const res = await fetch(API_URL, { method: "POST", body: fd });
            const data = await res.json();
            state.history = data.history;
            speak(data.reply);
        } catch (e) {
            status.textContent = "Network Error. Retrying...";
            setTimeout(() => startListening(), 2000);
        }
    }

    window.onFinishedSpeaking = () => {
        if(state.history.length > 0 && isSessionActive) startListening();
    };

    let recognition;
    if (!isAndroid) {
        const Recognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        if (Recognition) {
            recognition = new Recognition();
            recognition.continuous = true; 
            recognition.interimResults = false;
            recognition.lang = 'en-US';
            
            recognition.onresult = (event) => {
                const text = event.results[event.results.length - 1][0].transcript;
                if (text.trim()) {
                    try { recognition.stop(); } catch(e){}
                    handleUserResponse(text);
                }
            };
            
            recognition.onend = () => {
                if (isSessionActive && !isAiSpeaking) {
                    setTimeout(() => { if (isSessionActive && !isAiSpeaking) recognition.start(); }, 300);
                }
            };
        }
    }

    document.getElementById('cvInput').onchange = async (e) => {
        const file = e.target.files[0];
        if(!file) return;
        status.textContent = "Reading Resume...";
        const buffer = await file.arrayBuffer();
        const pdf = await pdfjsLib.getDocument({ data: new Uint8Array(buffer) }).promise;
        
        let fullText = "";
        for (let i = 1; i <= pdf.numPages; i++) {
            const page = await pdf.getPage(i);
            const textContent = await page.getTextContent();
            fullText += textContent.items.map(s => s.str).join(" ");
        }
        
        state.cvText = fullText;
        status.textContent = "Resume Ready";
        document.getElementById('startBtn').style.display = "block";
    };

    document.getElementById('startBtn').onclick = async () => {
        const audioReady = await initAudio();
        if (!audioReady) return;

        isSessionActive = true;
        document.getElementById('setupPanel').style.display = 'none';
        document.getElementById('activePanel').style.display = 'block';
        document.getElementById('timer').classList.add('active');
        
        setInterval(() => {
            if(state.timeLeft <= 0) finishSession();
            else {
                state.timeLeft--;
                const m = Math.floor(state.timeLeft / 60);
                const s = state.timeLeft % 60;
                timerDisplay.textContent = `${m}:${s < 10 ? '0'+s : s}`;
            }
        }, 1000);

        setOrbState('thinking');
        const fd = new FormData();
        fd.append("mode", "start");
        fd.append("cvText", state.cvText);
        
        try {
            const res = await fetch(API_URL, { method: "POST", body: fd });
            const data = await res.json();
            state.history = data.history;
            speak(data.reply);
        } catch (e) {
            alert("Connection error.");
            isSessionActive = false;
        }
    };

    async function finishSession() {
        isSessionActive = false;
        if(!isAndroid) {
            try { recognition.stop(); } catch(e){}
            window.speechSynthesis.cancel();
        }
        document.getElementById('activePanel').style.display = 'none';
        setOrbState('thinking');
        status.textContent = "Finalizing Score...";
        
        const fd = new FormData();
        fd.append("mode", "score");
        fd.append("history", JSON.stringify(state.history));
        
        try {
            const res = await fetch(API_URL, { method: "POST", body: fd });
            const data = await res.json();
            document.getElementById('reportText').textContent = data.reply;
        } catch(e) {
            document.getElementById('reportText').textContent = "Could not generate report.";
        }
        document.getElementById('reportModal').style.display = 'flex';
    }

    // Wake Lock
    let wakeLock = null;
    async function requestWakeLock() {
        try { wakeLock = await navigator.wakeLock.request("screen"); } catch (err) {}
    }
    document.addEventListener('visibilitychange', () => {
        if (document.visibilityState === 'visible') requestWakeLock();
    });
    requestWakeLock();
</script>
</body>
</html>
