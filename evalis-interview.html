<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Zara AI Interview</title>

    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web@1.14.0/dist/ort.wasm.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@ricky0123/vad-web@0.0.7/dist/bundle.standard.js"></script>

    <style>
        body { margin: 0; background: #020617; font-family: system-ui; height: 100vh; display: flex; align-items: center; justify-content: center; color: white; }
        .card { background: #0f172a; padding: 40px; border-radius: 24px; text-align: center; border: 1px solid #1e293b; width: 300px; box-shadow: 0 20px 50px rgba(0,0,0,0.5); }
        #status { font-size: 11px; color: #3b82f6; text-transform: uppercase; letter-spacing: 1px; margin-bottom: 20px; font-weight: bold; }
        #question { font-size: 15px; color: #94a3b8; margin-bottom: 30px; line-height: 1.5; min-height: 60px; }
        .btn { width: 100%; padding: 16px; border-radius: 12px; border: none; background: #2563eb; color: white; font-weight: bold; cursor: pointer; }
        .btn:disabled { background: #1e293b; color: #475569; cursor: not-allowed; }
        .pulse { width: 12px; height: 12px; background: #22c55e; border-radius: 50%; margin: 0 auto 15px; display: none; box-shadow: 0 0 10px #22c55e; animation: pulse-kf 1.5s infinite; }
        @keyframes pulse-kf { 0% { opacity: 1; transform: scale(1); } 50% { opacity: 0.5; transform: scale(1.3); } 100% { opacity: 1; transform: scale(1); } }
    </style>
</head>
<body>

<div class="card">
    <div class="pulse" id="pulse"></div>
    <div id="status">Loading AI Engine...</div>
    <div id="question">Please wait while Zara connects.</div>
    <button class="btn" id="startBtn" disabled>Starting...</button>
</div>

<script>
    const startBtn = document.getElementById("startBtn");
    const statusEl = document.getElementById("status");
    const questionEl = document.getElementById("question");
    const pulse = document.getElementById("pulse");
    const synth = window.speechSynthesis;

    // --- DECISION ENGINE ---
    const questions = [
        "Tell me about your HR experience.",
        "How do you handle recruitment pressure?",
        "What is your sourcing strategy?",
        "Thank you. We will contact you soon."
    ];
    let qIndex = 0;

    // --- ENGINE LOADER ---
    function init() {
        if (typeof vad !== 'undefined') {
            startBtn.disabled = false;
            startBtn.innerText = "Start Interview";
            statusEl.innerText = "AI Ready";
            questionEl.innerText = "Click below to begin your voice session.";
        } else {
            setTimeout(init, 1000); // Retry every second
        }
    }
    init();

    startBtn.onclick = async () => {
        startBtn.style.display = 'none';
        statusEl.innerText = "Requesting Microphone...";

        try {
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            const recognition = new SpeechRecognition();
            recognition.lang = "en-US";

            recognition.onresult = () => {
                qIndex++;
                if (qIndex < questions.length) {
                    ask(questions[qIndex]);
                } else {
                    statusEl.innerText = "Finished";
                    questionEl.innerText = "Interview complete.";
                }
            };

            const myvad = await vad.MicVAD.new({
                stream: stream,
                onSpeechStart: () => { if (synth.speaking) synth.cancel(); pulse.style.display = 'block'; },
                onSpeechEnd: () => { pulse.style.display = 'none'; try { recognition.start(); } catch(e) {} }
            });

            myvad.start();
            ask(questions[0]);

        } catch (err) {
            statusEl.innerText = "Error: Mic Access";
            questionEl.innerText = "Please enable your microphone and refresh.";
        }
    };

    function ask(text) {
        questionEl.innerText = text;
        statusEl.innerText = "Zara is Speaking";
        const msg = new SpeechSynthesisUtterance(text);
        msg.onend = () => { statusEl.innerText = "Zara is Listening"; };
        synth.speak(msg);
    }
</script>
</body>
</html>
