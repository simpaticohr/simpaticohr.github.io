<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, viewport-fit=cover">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <title>simpatico AI | simpatico hr consultancy </title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/pdf.js/3.11.174/pdf.min.js"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <style>
        :root {
            --bg: #0a0a0f;
            --surface: #121218;
            --surface-elevated: #1a1a24;
            --primary: #6366f1;
            --primary-glow: rgba(99, 102, 241, 0.3);
            --accent: #a855f7;
            --success: #10b981;
            --success-glow: rgba(16, 185, 129, 0.3);
            --warning: #f59e0b;
            --warning-glow: rgba(245, 158, 11, 0.3);
            --text: #f1f5f9;
            --text-secondary: #94a3b8;
            --text-dim: #64748b;
            --border: rgba(255, 255, 255, 0.08);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            background: var(--bg);
            color: var(--text);
            font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            min-height: 100vh;
            overflow: hidden;
            position: relative;
        }

        /* Animated Background */
        .bg-gradient {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: radial-gradient(ellipse at 50% 30%, rgba(99, 102, 241, 0.08) 0%, transparent 50%),
                        radial-gradient(ellipse at 80% 70%, rgba(168, 85, 247, 0.06) 0%, transparent 50%);
            pointer-events: none;
            z-index: 0;
        }

        /* Enhanced Orb Container */
        .orb-container {
            position: relative;
            width: 280px;
            height: 280px;
            display: flex;
            align-items: center;
            justify-content: center;
            margin-bottom: 50px;
            z-index: 2;
        }

        /* Main Orb */
        .orb {
            width: 140px;
            height: 140px;
            background: linear-gradient(135deg, var(--primary), var(--accent));
            border-radius: 50%;
            box-shadow: 0 0 80px var(--primary-glow),
                        0 0 120px var(--primary-glow),
                        inset 0 0 40px rgba(255, 255, 255, 0.1);
            position: relative;
            z-index: 3;
            transition: all 0.4s cubic-bezier(0.34, 1.56, 0.64, 1);
            cursor: pointer;
            user-select: none;
            -webkit-tap-highlight-color: transparent;
            touch-action: manipulation;
        }

        .orb:active {
            transform: scale(0.95);
        }

        /* Orb States with Enhanced Animations */
        .orb.idle {
            animation: breathe 4s ease-in-out infinite;
        }

        .orb.listening {
            background: linear-gradient(135deg, #22c55e, #10b981);
            box-shadow: 0 0 80px var(--success-glow),
                        0 0 120px var(--success-glow),
                        inset 0 0 40px rgba(255, 255, 255, 0.15);
            animation: pulse-listening 1.2s ease-in-out infinite;
            transform: scale(1.1);
        }

        .orb.thinking {
            background: linear-gradient(135deg, #f59e0b, #d97706);
            box-shadow: 0 0 80px var(--warning-glow),
                        0 0 120px var(--warning-glow),
                        inset 0 0 40px rgba(255, 255, 255, 0.15);
            animation: spin-thinking 2s linear infinite;
            border-radius: 45%;
        }

        .orb.speaking {
            animation: breathe-speaking 0.6s ease-in-out infinite;
            transform: scale(1.05);
        }

        /* Enhanced Rings */
        .ring {
            position: absolute;
            border-radius: 50%;
            border: 2px solid rgba(99, 102, 241, 0.1);
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            z-index: 1;
            pointer-events: none;
        }

        .ring:nth-child(1) {
            width: 220px;
            height: 220px;
            animation: float 8s ease-in-out infinite, spin 20s linear infinite;
            border-color: rgba(99, 102, 241, 0.15);
        }

        .ring:nth-child(2) {
            width: 280px;
            height: 280px;
            animation: float-reverse 10s ease-in-out infinite, spin-reverse 25s linear infinite;
            border-style: dashed;
            border-color: rgba(168, 85, 247, 0.12);
        }

        .ring:nth-child(3) {
            width: 340px;
            height: 340px;
            animation: float 12s ease-in-out infinite, spin 30s linear infinite;
            border-color: rgba(99, 102, 241, 0.08);
        }

        /* Listening indicator particles */
        .listening-indicator {
            position: absolute;
            width: 100%;
            height: 100%;
            pointer-events: none;
            opacity: 0;
            transition: opacity 0.3s;
        }

        .listening-indicator.active {
            opacity: 1;
        }

        .particle {
            position: absolute;
            width: 4px;
            height: 4px;
            background: var(--success);
            border-radius: 50%;
            animation: particle-float 2s ease-in-out infinite;
        }

        /* Interface */
        .interface {
            width: 100%;
            max-width: 560px;
            text-align: center;
            z-index: 10;
            padding: 0 24px;
        }

        .logo {
            font-weight: 300;
            margin-bottom: 8px;
            font-size: 2rem;
            background: linear-gradient(135deg, var(--primary), var(--accent));
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
            letter-spacing: -0.02em;
        }

        .tagline {
            color: var(--text-secondary);
            font-size: 0.95rem;
            margin-bottom: 6px;
            font-weight: 400;
        }

        /* Enhanced Status Pill */
        .status-pill {
            display: inline-flex;
            align-items: center;
            gap: 8px;
            padding: 10px 20px;
            background: var(--surface-elevated);
            border: 1px solid var(--border);
            border-radius: 100px;
            font-size: 0.9rem;
            color: var(--text-secondary);
            margin-bottom: 36px;
            backdrop-filter: blur(10px);
            transition: all 0.3s ease;
            font-weight: 500;
        }

        .status-indicator {
            width: 8px;
            height: 8px;
            background: var(--text-dim);
            border-radius: 50%;
            animation: pulse-subtle 2s ease-in-out infinite;
        }

        .status-pill.listening .status-indicator {
            background: var(--success);
            animation: pulse-active 1s ease-in-out infinite;
        }

        .status-pill.thinking .status-indicator {
            background: var(--warning);
            animation: pulse-active 0.8s ease-in-out infinite;
        }

        .status-pill.speaking .status-indicator {
            background: var(--primary);
            animation: pulse-active 0.6s ease-in-out infinite;
        }

        /* Timer */
        .timer {
            font-family: 'SF Mono', 'Monaco', 'Courier New', monospace;
            color: var(--text-secondary);
            margin-top: 16px;
            font-size: 1.1rem;
            opacity: 0;
            transition: opacity 0.3s;
            font-weight: 500;
            letter-spacing: 0.05em;
        }

        .timer.active {
            opacity: 1;
        }

        .timer.warning {
            color: var(--warning);
            animation: pulse-timer 1s ease-in-out infinite;
        }

        /* Enhanced Buttons */
        .btn {
            background: var(--surface-elevated);
            color: var(--text);
            border: 1px solid var(--border);
            padding: 14px 28px;
            border-radius: 12px;
            cursor: pointer;
            font-weight: 600;
            font-size: 0.95rem;
            margin-top: 12px;
            transition: all 0.2s cubic-bezier(0.34, 1.56, 0.64, 1);
            font-family: 'Inter', sans-serif;
        }

        .btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 8px 24px rgba(0, 0, 0, 0.3);
        }

        .btn:active {
            transform: translateY(0);
        }

        .btn-primary {
            background: linear-gradient(135deg, var(--primary), var(--accent));
            border-color: transparent;
            color: white;
            box-shadow: 0 4px 16px var(--primary-glow);
        }

        .btn-primary:hover {
            box-shadow: 0 8px 28px var(--primary-glow);
        }

        .btn:disabled {
            opacity: 0.5;
            cursor: not-allowed;
            transform: none !important;
        }

        .btn:disabled:hover {
            transform: none !important;
            box-shadow: none;
        }

        .btn-danger {
            background: rgba(239, 68, 68, 0.1);
            border-color: rgba(239, 68, 68, 0.3);
            color: #ef4444;
        }

        .btn-danger:hover {
            background: rgba(239, 68, 68, 0.15);
            box-shadow: 0 8px 24px rgba(239, 68, 68, 0.2);
        }

        /* File Upload */
        .file-trigger {
            border: 2px dashed var(--border);
            padding: 40px 32px;
            border-radius: 20px;
            cursor: pointer;
            display: block;
            color: var(--text-secondary);
            transition: all 0.3s ease;
            background: var(--surface);
        }

        .file-trigger:hover {
            border-color: var(--primary);
            color: var(--text);
            background: rgba(99, 102, 241, 0.05);
            transform: translateY(-2px);
            box-shadow: 0 8px 24px rgba(99, 102, 241, 0.1);
        }

        .file-trigger .icon {
            font-size: 2.5rem;
            margin-bottom: 12px;
            display: block;
        }

        .file-trigger .text {
            font-weight: 600;
            margin-bottom: 4px;
        }

        .file-trigger .subtext {
            font-size: 0.85rem;
            color: var(--text-dim);
        }

        input[type="file"] {
            display: none;
        }

        /* Modal */
        .modal {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: rgba(0, 0, 0, 0.92);
            backdrop-filter: blur(10px);
            display: none;
            align-items: center;
            justify-content: center;
            z-index: 1000;
            padding: 24px;
        }

        .modal-content {
            background: var(--surface);
            padding: 48px;
            border-radius: 24px;
            max-width: 680px;
            width: 100%;
            border: 1px solid var(--border);
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.5);
            animation: modal-appear 0.3s cubic-bezier(0.34, 1.56, 0.64, 1);
        }

        .modal h2 {
            color: var(--primary);
            margin-top: 0;
            margin-bottom: 24px;
            font-weight: 600;
            font-size: 1.75rem;
        }

        #reportText {
            line-height: 1.7;
            color: var(--text-secondary);
            white-space: pre-wrap;
            background: var(--bg);
            padding: 24px;
            border-radius: 12px;
            border: 1px solid var(--border);
            max-height: 400px;
            overflow-y: auto;
        }

        /* Responsive */
        @media (max-width: 640px) {
            .orb-container {
                width: 240px;
                height: 240px;
                margin-bottom: 40px;
            }

            .orb {
                width: 120px;
                height: 120px;
            }

            .ring:nth-child(1) { width: 180px; height: 180px; }
            .ring:nth-child(2) { width: 240px; height: 240px; }
            .ring:nth-child(3) { width: 300px; height: 300px; }

            .logo {
                font-size: 1.75rem;
            }

            .modal-content {
                padding: 32px 24px;
            }

            .btn {
                padding: 16px 24px;
                font-size: 1rem;
            }

            .status-pill {
                font-size: 0.85rem;
                padding: 8px 16px;
            }
        }

        /* iOS Safe Area */
        @supports (padding: max(0px)) {
            body {
                padding-left: max(12px, env(safe-area-inset-left));
                padding-right: max(12px, env(safe-area-inset-right));
                padding-bottom: max(12px, env(safe-area-inset-bottom));
            }
        }
        @keyframes breathe {
            0%, 100% { transform: scale(1); }
            50% { transform: scale(1.04); }
        }

        @keyframes breathe-speaking {
            0%, 100% { transform: scale(1.05); }
            50% { transform: scale(1.12); }
        }

        @keyframes pulse-listening {
            0%, 100% {
                box-shadow: 0 0 80px var(--success-glow),
                           0 0 120px var(--success-glow),
                           inset 0 0 40px rgba(255, 255, 255, 0.15);
            }
            50% {
                box-shadow: 0 0 100px var(--success-glow),
                           0 0 150px var(--success-glow),
                           inset 0 0 50px rgba(255, 255, 255, 0.2);
            }
        }

        @keyframes spin-thinking {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }

        @keyframes spin {
            100% { transform: translate(-50%, -50%) rotate(360deg); }
        }

        @keyframes spin-reverse {
            100% { transform: translate(-50%, -50%) rotate(-360deg); }
        }

        @keyframes float {
            0%, 100% { transform: translate(-50%, -50%) translateY(0); }
            50% { transform: translate(-50%, -50%) translateY(-10px); }
        }

        @keyframes float-reverse {
            0%, 100% { transform: translate(-50%, -50%) translateY(0); }
            50% { transform: translate(-50%, -50%) translateY(10px); }
        }

        @keyframes pulse-subtle {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.5; }
        }

        @keyframes pulse-active {
            0%, 100% { opacity: 1; transform: scale(1); }
            50% { opacity: 0.7; transform: scale(1.2); }
        }

        @keyframes pulse-timer {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.6; }
        }

        @keyframes modal-appear {
            from {
                opacity: 0;
                transform: scale(0.9) translateY(20px);
            }
            to {
                opacity: 1;
                transform: scale(1) translateY(0);
            }
        }

        @keyframes particle-float {
            0% {
                transform: translateY(0) scale(1);
                opacity: 0;
            }
            50% {
                opacity: 1;
            }
            100% {
                transform: translateY(-50px) scale(0);
                opacity: 0;
            }
        }

        /* Responsive */
        @media (max-width: 640px) {
            .orb-container {
                width: 240px;
                height: 240px;
                margin-bottom: 40px;
            }

            .orb {
                width: 120px;
                height: 120px;
            }

            .ring:nth-child(1) { width: 180px; height: 180px; }
            .ring:nth-child(2) { width: 240px; height: 240px; }
            .ring:nth-child(3) { width: 300px; height: 300px; }

            .logo {
                font-size: 1.75rem;
            }

            .modal-content {
                padding: 32px 24px;
            }
        }

        /* Loading State */
        .loading-dots {
            display: inline-flex;
            gap: 4px;
        }

        .loading-dots span {
            width: 4px;
            height: 4px;
            background: currentColor;
            border-radius: 50%;
            animation: dot-bounce 1.4s ease-in-out infinite;
        }

        .loading-dots span:nth-child(2) {
            animation-delay: 0.2s;
        }

        .loading-dots span:nth-child(3) {
            animation-delay: 0.4s;
        }

        @keyframes dot-bounce {
            0%, 80%, 100% {
                transform: translateY(0);
                opacity: 0.5;
            }
            40% {
                transform: translateY(-6px);
                opacity: 1;
            }
        }
    </style>
</head>
<body>
    <div class="bg-gradient"></div>

    <div class="orb-container">
        <div class="ring"></div>
        <div class="ring"></div>
        <div class="ring"></div>
        <div id="orb" class="orb idle"></div>
        <div class="listening-indicator" id="listeningIndicator"></div>
    </div>

    <div class="interface">
        <h1 class="logo">Evalis AI</h1>
        <p class="tagline">Elite Interview Intelligence</p>
        
        <div id="status" class="status-pill">
            <span class="status-indicator"></span>
            <span class="status-text">Awaiting Resume</span>
        </div>
        
        <div id="setupPanel">
            <label class="file-trigger">
                <span class="icon">ðŸ“„</span>
                <div class="text">Upload Your Resume</div>
                <div class="subtext">PDF format â€¢ Professional analysis</div>
                <input type="file" id="cvInput" accept=".pdf">
            </label>
            <button id="startBtn" class="btn btn-primary" style="width:100%;" disabled>
                Begin Interview Session
            </button>
        </div>

        <div id="activePanel" style="display:none;">
            <button id="endBtn" class="btn btn-danger" style="width:100%;">
                End Interview
            </button>
            <div id="timer" class="timer">15:00</div>
        </div>
    </div>

    <div id="reportModal" class="modal">
        <div class="modal-content">
            <h2>ðŸ“Š Performance Evaluation</h2>
            <div id="reportText"></div>
            <button onclick="location.reload()" class="btn btn-primary" style="margin-top:28px; width:100%;">
                Start New Session
            </button>
        </div>
    </div>

<script>
    // --- CONFIGURATION ---
    const API_URL = "https://evalis-ai.simpaticohrconsultancy.workers.dev";
    pdfjsLib.GlobalWorkerOptions.workerSrc = "https://cdnjs.cloudflare.com/ajax/libs/pdf.js/3.11.174/pdf.worker.min.js";

    // --- PLATFORM DETECTION ---
    const isAndroid = typeof Android !== "undefined";
    const isMobile = /Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent);

    /* 
     * ANDROID INTEGRATION NOTES:
     * For full Android WebView support, implement these methods in your native code:
     * - Android.startInterview() - Start speech recognition
     * - Android.speak(text) - Text-to-speech
     * - Android.stopSpeaking() - Stop TTS (for bargie-in)
     * 
     * Callback from Android to JavaScript:
     * - window.onRecognitionResult(text) - Called when user speaks
     * - window.onFinishedSpeaking() - Called when TTS completes
     */

    // --- STATE ---
    let state = {
        cvText: "",
        history: [],
        timeLeft: 900, // 15 minutes
        isInterviewing: false,
        isSpeaking: false,
        isListening: false,
        continuousMode: true // Always listen after speaking
    };

    let timerInterval = null;
    let retryTimeout = null;

    // --- DOM ELEMENTS ---
    const orb = document.getElementById('orb');
    const statusPill = document.getElementById('status');
    const statusText = statusPill.querySelector('.status-text');
    const timerDisplay = document.getElementById('timer');
    const transcriptDiv = document.getElementById('transcript');
    const transcriptContent = document.getElementById('transcriptContent');
    const listeningIndicator = document.getElementById('listeningIndicator');

    // --- VISUAL STATE MANAGEMENT ---
    function setOrbState(mode, message) {
        orb.className = 'orb ' + mode;
        statusPill.className = 'status-pill ' + mode;
        
        const messages = {
            idle: "Ready",
            listening: "Listening to your response...",
            thinking: "Processing your answer...",
            speaking: "AI is responding..."
        };
        
        statusText.textContent = message || messages[mode] || "Active";
        
        // Update state flags
        state.isListening = (mode === 'listening');
        state.isSpeaking = (mode === 'speaking');
        
        // Update listening indicator
        if (mode === 'listening') {
            listeningIndicator.classList.add('active');
            createParticles();
        } else {
            listeningIndicator.classList.remove('active');
        }
    }

    // --- STOP AI SPEAKING (For Bargie-In) ---
    function stopSpeaking() {
        if (!state.isSpeaking) return;
        
        console.log('ðŸ›‘ Interrupted - Stopping AI speech');
        state.isSpeaking = false;
        
        if (isAndroid) {
            // Android: Call native method to stop TTS
            if (typeof Android.stopSpeaking === 'function') {
                Android.stopSpeaking();
            }
        } else {
            // Web: Cancel speech synthesis
            window.speechSynthesis.cancel();
        }
        
        // Clear any pending speaking callbacks
        clearTimeout(retryTimeout);
    }

    // --- PARTICLE EFFECT FOR LISTENING ---
    function createParticles() {
        listeningIndicator.innerHTML = '';
        const particleCount = 12;
        for (let i = 0; i < particleCount; i++) {
            const particle = document.createElement('div');
            particle.className = 'particle';
            const angle = (i / particleCount) * 360;
            const radius = 100;
            const x = Math.cos(angle * Math.PI / 180) * radius;
            const y = Math.sin(angle * Math.PI / 180) * radius;
            particle.style.left = `calc(50% + ${x}px)`;
            particle.style.top = `calc(50% + ${y}px)`;
            particle.style.animationDelay = `${i * 0.1}s`;
            listeningIndicator.appendChild(particle);
        }
    }

    // --- PARTICLE EFFECT FOR LISTENING ---
    function createParticles() {
        listeningIndicator.innerHTML = '';
        const particleCount = 12;
        for (let i = 0; i < particleCount; i++) {
            const particle = document.createElement('div');
            particle.className = 'particle';
            const angle = (i / particleCount) * 360;
            const radius = 100;
            const x = Math.cos(angle * Math.PI / 180) * radius;
            const y = Math.sin(angle * Math.PI / 180) * radius;
            particle.style.left = `calc(50% + ${x}px)`;
            particle.style.top = `calc(50% + ${y}px)`;
            particle.style.animationDelay = `${i * 0.1}s`;
            listeningIndicator.appendChild(particle);
        }
    }

    // --- SPEECH RECOGNITION (Continuous with Manual Bargie-In) ---
    function startListening() {
        if (!state.isInterviewing) return;
        
        // BARGIE-IN: If AI is speaking, interrupt it (only via manual trigger)
        if (state.isSpeaking) {
            console.log('ðŸ›‘ Manual interrupt - Stopping AI speech');
            stopSpeaking();
        }
        
        setOrbState('listening');
        
        if (isAndroid) {
            Android.startInterview();
        } else {
            try {
                if (recognition && !state.isSpeaking) {
                    recognition.start();
                }
            } catch (e) {
                // Already started, ignore
                console.log('Recognition already active');
            }
        }
    }

    // --- TEXT-TO-SPEECH (With Manual Bargie-In Only) ---
    function speak(text) {
        // Stop any ongoing recognition before AI starts speaking
        if (!isAndroid && recognition) {
            try {
                recognition.stop();
            } catch (e) {
                console.log('Recognition already stopped');
            }
        }
        
        setOrbState('speaking');
        
        if (isAndroid) {
            Android.speak(text);
        } else {
            const utterance = new SpeechSynthesisUtterance(text);
            const voices = window.speechSynthesis.getVoices();
            
            // Prefer natural-sounding voices
            const preferredVoice = voices.find(v => 
                v.name.includes('Google US English') || 
                v.name.includes('Natural') ||
                v.name.includes('Premium') ||
                v.lang === 'en-US'
            );
            
            if (preferredVoice) utterance.voice = preferredVoice;
            utterance.rate = 1.05; // Slightly faster for natural feel
            utterance.pitch = 1.0;
            
            utterance.onend = () => {
                onFinishedSpeaking();
            };
            
            utterance.onerror = (e) => {
                console.error('Speech error:', e);
                onFinishedSpeaking(); // Continue anyway
            };
            
            window.speechSynthesis.speak(utterance);
        }
    }

    // --- HANDLE USER RESPONSE ---
    async function handleUserResponse(transcript) {
        if (!transcript || !transcript.trim()) {
            console.log('Empty transcript, restarting listening...');
            setTimeout(startListening, 500);
            return;
        }

        console.log('ðŸ’¬ User said:', transcript);
        
        setOrbState('thinking');
        
        const fd = new FormData();
        fd.append("mode", "interview");
        fd.append("history", JSON.stringify(state.history));
        fd.append("text", transcript);
        fd.append("cvText", state.cvText);

        try {
            const res = await fetch(API_URL, { method: "POST", body: fd });
            
            if (!res.ok) {
                throw new Error(`API returned ${res.status}`);
            }
            
            const data = await res.json();
            
            state.history = data.history || state.history;
            
            if (data.reply) {
                speak(data.reply);
            } else {
                console.error('No reply from API');
                setTimeout(startListening, 1000);
            }
        } catch (e) {
            console.error('API Error:', e);
            statusText.textContent = "Connection issue, retrying...";
            
            // Retry logic
            clearTimeout(retryTimeout);
            retryTimeout = setTimeout(() => {
                if (state.isInterviewing) {
                    startListening();
                }
            }, 2000);
        }
    }

    // --- CALLBACKS (Android & Web) ---
    window.onRecognitionResult = (text) => {
        handleUserResponse(text);
    };

    window.onFinishedSpeaking = () => {
        console.log('âœ… Finished speaking, continuous mode:', state.continuousMode);
        
        // Mark that we're no longer speaking
        state.isSpeaking = false;
        
        // Continuous listening: Auto-restart after AI speaks
        if (state.isInterviewing && state.continuousMode) {
            // Small delay for natural pacing
            setTimeout(() => {
                if (!state.isSpeaking && state.isInterviewing) {
                    startListening();
                }
            }, 600);
        }
    };

    // --- WEB SPEECH API SETUP (Optimized for Mobile & Bargie-In) ---
    let recognition;
    if (!isAndroid) {
        const Recognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        
        if (Recognition) {
            recognition = new Recognition();
            recognition.continuous = false; // Manual restart for better control
            recognition.interimResults = false; // Final results only
            recognition.lang = 'en-US';
            recognition.maxAlternatives = 1;
            
            // Mobile optimization
            if (isMobile) {
                console.log('ðŸ“± Mobile optimizations enabled');
            }
            
            recognition.onstart = () => {
                console.log('ðŸŽ¤ Recognition started');
            };
            
            recognition.onresult = (event) => {
                const text = event.results[0][0].transcript;
                const confidence = event.results[0][0].confidence;
                console.log('âœ… Recognition result:', text, 'Confidence:', confidence);
                handleUserResponse(text);
            };
            
            recognition.onerror = (e) => {
                console.log('âŒ Recognition error:', e.error);
                
                // Handle errors gracefully
                if (e.error === 'no-speech') {
                    console.log('No speech detected, restarting...');
                    setTimeout(() => {
                        if (state.isInterviewing && state.isListening && !state.isSpeaking) {
                            try { recognition.start(); } catch(ex) {}
                        }
                    }, 500);
                } else if (e.error === 'aborted') {
                    // Intentional stop, don't restart
                    console.log('Recognition aborted');
                } else if (e.error === 'audio-capture') {
                    statusText.textContent = "Microphone access needed";
                } else if (e.error === 'not-allowed') {
                    statusText.textContent = "Please allow microphone access";
                } else {
                    // Other errors, retry only if not speaking
                    setTimeout(() => {
                        if (state.isInterviewing && !state.isSpeaking) {
                            try { recognition.start(); } catch(ex) {}
                        }
                    }, 1000);
                }
            };
            
            recognition.onend = () => {
                console.log('â¹ï¸ Recognition ended');
                // Auto-restart ONLY if still listening AND AI is NOT speaking
                if (state.isInterviewing && state.isListening && !state.isSpeaking) {
                    setTimeout(() => {
                        try { 
                            if (!state.isSpeaking) {
                                recognition.start(); 
                            }
                        } catch(e) {
                            console.log('Could not restart recognition:', e);
                        }
                    }, 300);
                }
            };
            
            // Load voices when available
            if ('speechSynthesis' in window) {
                speechSynthesis.onvoiceschanged = () => {
                    const voices = speechSynthesis.getVoices();
                    console.log('ðŸ”Š Voices loaded:', voices.length);
                };
            }
        } else {
            statusText.textContent = "Speech not supported (Use Chrome/Edge/Safari)";
        }
    }

    // --- TIMER MANAGEMENT ---
    function startTimer() {
        timerDisplay.classList.add('active');
        
        timerInterval = setInterval(() => {
            if (state.timeLeft <= 0) {
                finishSession();
                clearInterval(timerInterval);
                return;
            }
            
            state.timeLeft--;
            const m = Math.floor(state.timeLeft / 60);
            const s = state.timeLeft % 60;
            timerDisplay.textContent = `${m}:${s < 10 ? '0' + s : s}`;
            
            // Warning at 2 minutes
            if (state.timeLeft === 120) {
                timerDisplay.classList.add('warning');
            }
        }, 1000);
    }

    // --- FILE UPLOAD ---
    document.getElementById('cvInput').onchange = async (e) => {
        const file = e.target.files[0];
        if (!file) return;
        
        setOrbState('thinking', "Reading your resume...");
        
        try {
            const buffer = await file.arrayBuffer();
            const pdf = await pdfjsLib.getDocument(buffer).promise;
            
            let fullText = "";
            for (let i = 1; i <= pdf.numPages; i++) {
                const page = await pdf.getPage(i);
                const textContent = await page.getTextContent();
                fullText += textContent.items.map(s => s.str).join(" ") + "\n";
            }
            
            state.cvText = fullText;
            setOrbState('idle', "Resume loaded successfully");
            document.getElementById('startBtn').disabled = false;
            
            console.log('Resume loaded, length:', fullText.length);
        } catch (error) {
            console.error('PDF parsing error:', error);
            setOrbState('idle', "Error reading PDF. Please try again.");
        }
    };

    // --- START INTERVIEW ---
    document.getElementById('startBtn').onclick = async () => {
        document.getElementById('setupPanel').style.display = 'none';
        document.getElementById('activePanel').style.display = 'block';
        
        state.isInterviewing = true;
        startTimer();
        
        setOrbState('thinking', "Initializing interview...");
        
        const fd = new FormData();
        fd.append("mode", "start");
        fd.append("cvText", state.cvText);
        
        try {
            const res = await fetch(API_URL, { method: "POST", body: fd });
            const data = await res.json();
            
            state.history = data.history || [];
            
            if (data.reply) {
                speak(data.reply);
            } else {
                console.error('No initial reply');
                setOrbState('idle', "Failed to start. Please refresh.");
            }
        } catch (e) {
            console.error('Failed to start interview:', e);
            alert("Could not connect to the AI server. Please check your connection.");
            location.reload();
        }
    };

    // --- END SESSION ---
    document.getElementById('endBtn').onclick = finishSession;

    async function finishSession() {
        state.isInterviewing = false;
        state.isSpeaking = false;
        state.isListening = false;
        
        if (timerInterval) clearInterval(timerInterval);
        if (retryTimeout) clearTimeout(retryTimeout);
        
        // Stop all speech
        if (!isAndroid) {
            if (recognition) {
                try { recognition.stop(); } catch (e) {}
            }
            window.speechSynthesis.cancel();
        } else {
            if (typeof Android.stopSpeaking === 'function') {
                Android.stopSpeaking();
            }
        }
        
        document.getElementById('activePanel').style.display = 'none';
        setOrbState('thinking', "Generating evaluation report...");
        
        const fd = new FormData();
        fd.append("mode", "score");
        fd.append("history", JSON.stringify(state.history));
        
        try {
            const res = await fetch(API_URL, { method: "POST", body: fd });
            const data = await res.json();
            
            document.getElementById('reportText').textContent = data.reply || "Evaluation complete.";
            document.getElementById('reportModal').style.display = 'flex';
        } catch (e) {
            console.error('Failed to generate report:', e);
            document.getElementById('reportText').textContent = "Unable to generate report. Please try again.";
            document.getElementById('reportModal').style.display = 'flex';
        }
    }

    // --- WAKE LOCK (Prevent screen sleep) ---
    let wakeLock = null;

    async function requestWakeLock() {
        if ('wakeLock' in navigator) {
            try {
                wakeLock = await navigator.wakeLock.request("screen");
                console.log('Wake Lock active');
                
                wakeLock.addEventListener('release', () => {
                    console.log('Wake Lock released');
                });
            } catch (err) {
                console.error('Wake Lock failed:', err);
            }
        }
    }

    document.addEventListener('visibilitychange', async () => {
        if (document.visibilityState === 'visible' && state.isInterviewing) {
            await requestWakeLock();
        }
    });

    // --- INITIALIZE ---
    window.addEventListener('load', () => {
        console.log('ðŸš€ Evalis AI loaded');
        console.log('ðŸ“± Platform:', isAndroid ? 'Android' : isMobile ? 'Mobile Web' : 'Desktop');
        console.log('ðŸŽ¤ Speech Recognition:', !!recognition ? 'Available' : 'Not Available');
        
        requestWakeLock();
        
        // Add orb tap/click handler for manual interrupt
        orb.addEventListener('click', () => {
            if (state.isSpeaking && state.isInterviewing) {
                console.log('ðŸ‘† User tapped orb - interrupting');
                stopSpeaking();
                setTimeout(startListening, 300);
            }
        });
        
        // Mobile-specific: show hint on first touch
        if (isMobile && !localStorage.getItem('evalis_hint_shown')) {
            setTimeout(() => {
                statusText.textContent = "Tap orb anytime to interrupt";
                localStorage.setItem('evalis_hint_shown', 'true');
            }, 3000);
        }
    });

    // Prevent accidental navigation during interview
    window.addEventListener('beforeunload', (e) => {
        if (state.isInterviewing) {
            e.preventDefault();
            e.returnValue = '';
        }
    });
</script>

</body>
</html>
