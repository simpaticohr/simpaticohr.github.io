<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>Evalis AI – Elite Live Interview</title>

<script src="https://cdnjs.cloudflare.com/ajax/libs/pdf.js/3.11.174/pdf.min.js"></script>

<style>
:root { --primary:#6366f1; --bg:#020617; }
body {
  margin:0;
  background:var(--bg);
  color:white;
  font-family:system-ui,sans-serif;
  display:flex;
  align-items:center;
  justify-content:center;
  min-height:100vh;
}
.card {
  width:90%;
  max-width:440px;
  background:rgba(255,255,255,0.05);
  backdrop-filter:blur(15px);
  border-radius:24px;
  padding:30px;
  text-align:center;
  border:1px solid rgba(255,255,255,0.1);
}
canvas { width:100%; height:60px; }
.btn {
  background:var(--primary);
  color:white;
  border:none;
  padding:16px;
  border-radius:14px;
  width:100%;
  font-size:16px;
  font-weight:bold;
}
.btn:disabled { opacity:0.3 }
#log {
  margin-top:20px;
  max-height:200px;
  overflow:auto;
  text-align:left;
  font-size:14px;
}
.success { color:#10b981; font-size:12px }
.error { color:#ef4444; font-size:12px }
</style>
</head>

<body>

<div class="card">
  <h2 id="timer">15:00</h2>
  <p id="status">Upload Resume to Start</p>

  <canvas id="wave"></canvas>

  <input type="file" id="cvInput" accept="application/pdf" />
  <div id="uploadStatus"></div>

  <button id="startBtn" class="btn" disabled>Start Interview</button>
  <button id="endBtn" class="btn" style="display:none;background:#ef4444">End Interview</button>

  <div id="log"></div>
</div>

<script>
/* ================= CONFIG ================= */
const API = "https://evalis-ai.simpaticohrconsultancy.workers.dev";

pdfjsLib.GlobalWorkerOptions.workerSrc =
  "https://cdnjs.cloudflare.com/ajax/libs/pdf.js/3.11.174/pdf.worker.min.js";

/* ================= STATE ================= */
let cvText = "";
let history = [];
let interviewActive = false;
let recognition = null;
let audioCtx = null;
let analyser = null;
let isAISpeaking = false;

let timeLeft = 15 * 60;
let timerInterval = null;

/* ================= TIMER ================= */
function startTimer() {
  timerInterval = setInterval(() => {
    if (!interviewActive) return;
    timeLeft--;
    const m = String(Math.floor(timeLeft / 60)).padStart(2,"0");
    const s = String(timeLeft % 60).padStart(2,"0");
    document.getElementById("timer").textContent = `${m}:${s}`;
    if (timeLeft <= 0) {
      clearInterval(timerInterval);
      document.getElementById("endBtn").click();
    }
  }, 1000);
}

/* ================= PDF LOAD ================= */
document.getElementById("cvInput").addEventListener("change", async e => {
  const file = e.target.files[0];
  const status = document.getElementById("uploadStatus");
  const btn = document.getElementById("startBtn");

  if (!file) return;

  status.textContent = "⏳ Reading resume…";
  btn.disabled = true;

  try {
    const buffer = await file.arrayBuffer();
    const pdf = await pdfjsLib.getDocument({
      data: buffer,
      disableWorker: true
    }).promise;

    let text = "";
    for (let i = 1; i <= pdf.numPages; i++) {
      const page = await pdf.getPage(i);
      const content = await page.getTextContent();
      text += content.items.map(it => it.str).join(" ") + " ";
    }

    cvText = text.trim();
    if (cvText.length < 30) throw new Error("No readable text");

    btn.disabled = false;
    status.innerHTML = "<div class='success'>✓ Resume loaded</div>";
    document.getElementById("status").textContent = "Resume Ready ✓";

  } catch {
    status.innerHTML = "<div class='error'>PDF read failed</div>";
  }
});

/* ================= WAVE ================= */
function initWave(stream) {
  audioCtx = new (window.AudioContext || window.webkitAudioContext)();
  analyser = audioCtx.createAnalyser();
  audioCtx.createMediaStreamSource(stream).connect(analyser);

  const canvas = document.getElementById("wave");
  const ctx = canvas.getContext("2d");
  const data = new Uint8Array(analyser.frequencyBinCount);

  function draw() {
    if (!interviewActive) return;
    requestAnimationFrame(draw);
    analyser.getByteFrequencyData(data);
    ctx.clearRect(0,0,canvas.width,canvas.height);
    ctx.fillStyle = "#6366f1";
    for (let i=0;i<64;i++) {
      ctx.fillRect(i*5, 30 - data[i]/4, 3, data[i]/2);
    }
  }
  draw();
}

/* ================= SPEAK ================= */
function speak(text) {
  return new Promise(resolve => {
    if (!window.speechSynthesis) return resolve();

    const run = () => {
      const u = new SpeechSynthesisUtterance(text);
      u.lang = "en-US";
      u.rate = 0.95;

      u.onstart = () => {
        isAISpeaking = true;
        if (recognition) recognition.stop();
      };

      u.onend = () => {
        isAISpeaking = false;
        if (interviewActive && recognition) {
          setTimeout(() => recognition.start(), 600);
        }
        resolve();
      };

      speechSynthesis.cancel();
      speechSynthesis.speak(u);

      const d = document.createElement("div");
      d.innerHTML = `<b>AI:</b> ${text}`;
      document.getElementById("log").prepend(d);
    };

    if (speechSynthesis.getVoices().length === 0)
      speechSynthesis.onvoiceschanged = run;
    else run();
  });
}

/* ================= RECOGNITION ================= */
function initRecognition() {
  const SR = window.SpeechRecognition || window.webkitSpeechRecognition;
  if (!SR) return;

  recognition = new SR();
  recognition.continuous = false;
  recognition.lang = "en-US";

  recognition.onresult = async e => {
    if (isAISpeaking) return;
    const text = e.results[e.results.length-1][0].transcript.trim();
    if (!text) return;

    document.getElementById("status").textContent = "Thinking…";

    const fd = new FormData();
    fd.append("mode","interview");
    fd.append("text",text);
    fd.append("history",JSON.stringify(history));
    fd.append("cvText",cvText);

    const r = await fetch(API,{method:"POST",body:fd});
    const d = await r.json();
    history = d.history;

    await speak(d.reply);
    document.getElementById("status").textContent = "Listening…";
  };

  recognition.onend = () => {
    if (interviewActive && !isAISpeaking) {
      setTimeout(() => recognition.start(), 600);
    }
  };
}

/* ================= START ================= */
document.getElementById("startBtn").onclick = async () => {
  interviewActive = true;

  const stream = await navigator.mediaDevices.getUserMedia({ audio:true });
  initWave(stream);
  initRecognition();
  startTimer();

  document.getElementById("startBtn").style.display="none";
  document.getElementById("endBtn").style.display="block";

  await speak("Please wait while I review your resume.");

  const fd = new FormData();
  fd.append("mode","start");
  fd.append("cvText",cvText);

  const r = await fetch(API,{method:"POST",body:fd});
  const d = await r.json();
  history = d.history;

  await speak(d.reply);
  document.getElementById("status").textContent = "Listening…";
  recognition.start();
};

/* ================= END ================= */
document.getElementById("endBtn").onclick = async () => {
  interviewActive = false;
  clearInterval(timerInterval);
  if (recognition) recognition.stop();
  speechSynthesis.cancel();

  const fd = new FormData();
  fd.append("mode","score");
  fd.append("history",JSON.stringify(history));

  const r = await fetch(API,{method:"POST",body:fd});
  const d = await r.json();

  document.body.innerHTML = `
    <div class="card">
      <h2>Interview Complete</h2>
      <pre>${d.reply}</pre>
      <button class="btn" onclick="location.reload()">New Interview</button>
    </div>`;
};
</script>
</body>
</html>
