<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<title>Evalis AI â€“ Voice Interview</title>
<meta name="viewport" content="width=device-width, initial-scale=1" />

<!-- VAD -->
<script src="https://cdn.jsdelivr.net/npm/@ricky0123/vad-web@0.0.7/dist/bundle.standard.js"></script>

<style>
body {
  margin: 0;
  background: #0f172a;
  font-family: system-ui, -apple-system, Segoe UI, Roboto;
  color: #e5e7eb;
  display: flex;
  justify-content: center;
  align-items: center;
  height: 100vh;
}

.card {
  background: #020617;
  padding: 28px;
  width: 92%;
  max-width: 420px;
  border-radius: 18px;
  box-shadow: 0 0 40px rgba(0,0,0,.6);
  text-align: center;
}

h3 {
  margin: 0 0 10px;
  font-weight: 600;
}

#question {
  font-size: 18px;
  margin: 18px 0;
  min-height: 70px;
}

#status {
  font-size: 14px;
  color: #22c55e;
  min-height: 20px;
}

button {
  width: 100%;
  margin-top: 18px;
  padding: 14px;
  border-radius: 14px;
  border: none;
  background: #2563eb;
  color: white;
  font-size: 16px;
  cursor: pointer;
}

.mic {
  margin-top: 10px;
  font-size: 26px;
  opacity: 0.4;
  transition: transform 0.2s, opacity 0.2s;
}

.mic.active {
  opacity: 1;
  transform: scale(1.2);
}
</style>
</head>

<body>
<div class="card">
  <h3>Evalis AI Interview</h3>
  <div id="question">Ready to begin</div>
  <div id="status">Tap start</div>
  <div id="mic" class="mic">ðŸŽ¤</div>
  <button id="startBtn">Start Interview</button>
</div>

<script>
/* ================= CONFIG ================= */
const WORKER_URL = "https://evalis-ai.simpaticohrconsultancy.workers.dev";

/* ================= STATE ================= */
let interviewStarted = false;
let isAISpeaking = false;
let audioContext;
let myvad;
let micStream;

/* ================= UI ================= */
const questionEl = document.getElementById("question");
const statusEl = document.getElementById("status");
const micEl = document.getElementById("mic");
const startBtn = document.getElementById("startBtn");

function setStatus(t) { statusEl.innerText = t; }
function setMic(active) {
  micEl.classList.toggle("active", active);
}

/* ================= SPEECH SYNTH ================= */
const synth = window.speechSynthesis;

function speak(text) {
  synth.cancel();

  const utter = new SpeechSynthesisUtterance(text);
  utter.lang = "en-US";
  utter.rate = 0.95;

  utter.onstart = () => {
    isAISpeaking = true;
    setStatus("AI speakingâ€¦");
    setMic(false);
  };

  utter.onend = () => {
    isAISpeaking = false;
    setStatus("Listeningâ€¦");
  };

  questionEl.innerText = text;
  synth.speak(utter);
}

/* ================= SPEECH RECOGNITION ================= */
const recognition =
  new (window.SpeechRecognition || window.webkitSpeechRecognition)();

recognition.lang = "en-US";
recognition.continuous = false;
recognition.interimResults = false;

recognition.onresult = async (event) => {
  const answer = event.results[0][0].transcript;
  setStatus("Thinkingâ€¦");
  setMic(false);

  try {
    const res = await fetch(WORKER_URL, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({
        text: answer,
        // OPTIONAL: resume can be injected later
        // resume: window.resumeText
      })
    });

    const data = await res.json();
    speak(data.reply || "Can you explain that further?");
  } catch (e) {
    speak("Please repeat that.");
  }
};

/* ================= VAD ================= */
async function initVAD(stream) {
  myvad = await vad.MicVAD.new({
    stream,
    onSpeechStart: () => {
      setMic(true);
      if (isAISpeaking) synth.cancel();
    },
    onSpeechEnd: () => {
      setMic(false);
      recognition.start();
    }
  });

  myvad.start();
}

/* ================= START ================= */
startBtn.onclick = async () => {
  if (interviewStarted) return;
  interviewStarted = true;

  startBtn.disabled = true;
  startBtn.style.display = "none";
  setStatus("Requesting microphoneâ€¦");

  try {
    micStream = await navigator.mediaDevices.getUserMedia({ audio: true });

    audioContext = new (window.AudioContext || window.webkitAudioContext)();
    await audioContext.resume();

    await initVAD(micStream);

    setStatus("Listeningâ€¦");
    speak("Tell me about yourself.");

  } catch (err) {
    console.error(err);
    setStatus("Microphone permission required.");
    startBtn.disabled = false;
    startBtn.style.display = "block";
    interviewStarted = false;
  }
};
</script>
</body>
</html>
