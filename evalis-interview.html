<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Evalis AI - Elite Live Interview</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/pdf.js/3.11.174/pdf.min.js"></script>
    <style>
        :root { --primary: #6366f1; --bg: #020617; }
        * { box-sizing: border-box; }
        body { margin: 0; background: var(--bg); color: white; font-family: system-ui, sans-serif; display: flex; align-items: center; justify-content: center; min-height: 100vh; overflow-x: hidden; }
        .card { width: 90%; max-width: 440px; background: rgba(255,255,255,0.05); backdrop-filter: blur(15px); border-radius: 24px; padding: 30px; text-align: center; border: 1px solid rgba(255,255,255,0.1); box-shadow: 0 25px 50px rgba(0,0,0,0.5); }
        .wave-box { height: 80px; margin: 15px 0; position: relative; }
        canvas { width: 100%; height: 60px; filter: drop-shadow(0 0 5px var(--primary)); }
        #timer { font-size: 28px; font-weight: 700; color: var(--primary); margin-bottom: 5px; font-variant-numeric: tabular-nums; }
        #status { font-size: 13px; color: #94a3b8; text-transform: uppercase; letter-spacing: 1px; margin-bottom: 20px; font-weight: 600; min-height: 20px; }
        #status.listening { color: #4ade80; }
        #status.thinking { color: #fbbf24; }
        #status.speaking { color: #a78bfa; }
        .indicator { display: inline-block; width: 8px; height: 8px; border-radius: 50%; background: #4ade80; margin-right: 6px; animation: pulse 2s infinite; }
        @keyframes pulse { 0%, 100% { opacity: 1; transform: scale(1); } 50% { opacity: 0.5; transform: scale(0.8); } }
        .btn { background: var(--primary); color: white; border: none; padding: 16px; border-radius: 14px; width: 100%; font-weight: bold; cursor: pointer; font-size: 16px; transition: all 0.3s; margin-bottom: 10px; }
        .btn:hover:not(:disabled) { background: #4f46e5; transform: translateY(-2px); }
        .btn:disabled { opacity: 0.3; cursor: not-allowed; }
        .btn.secondary { background: #334155; }
        .btn.danger { background: #ef4444; }
        .btn.danger:hover { background: #dc2626; }
        #log { margin-top: 20px; max-height: 250px; overflow-y: auto; text-align: left; font-size: 13px; border-top: 1px solid #334155; padding-top: 15px; }
        .user-msg { color: #86efac; margin: 10px 0; padding: 8px 12px; background: rgba(134, 239, 172, 0.1); border-radius: 8px; border-left: 3px solid #86efac; }
        .ai-msg { color: #a5b4fc; margin: 10px 0; padding: 8px 12px; background: rgba(165, 180, 252, 0.1); border-radius: 8px; border-left: 3px solid #a5b4fc; }
        .system-msg { color: #fbbf24; margin: 8px 0; font-size: 11px; opacity: 0.8; font-style: italic; }
        .report-box { background: rgba(99, 102, 241, 0.1); padding: 20px; border-radius: 15px; text-align: left; line-height: 1.6; border: 1px solid var(--primary); white-space: pre-wrap; }
        .controls { display: flex; gap: 10px; }
        .controls .btn { margin: 0; }
        #fileLabel { display: inline-block; padding: 12px 16px; background: rgba(255,255,255,0.1); border-radius: 12px; cursor: pointer; margin-bottom: 15px; font-size: 13px; border: 1px dashed rgba(255,255,255,0.3); transition: all 0.3s; }
        #fileLabel:hover { background: rgba(255,255,255,0.15); border-color: var(--primary); }
        #cvInput { display: none; }
        .mic-status { font-size: 40px; margin: 10px 0; }
        ::-webkit-scrollbar { width: 6px; }
        ::-webkit-scrollbar-track { background: rgba(255,255,255,0.05); }
        ::-webkit-scrollbar-thumb { background: var(--primary); border-radius: 3px; }
    </style>
</head>
<body>

<div class="card">
    <div id="timer">15:00</div>
    <div id="status">Upload Resume to Start</div>
    <div class="wave-box">
        <canvas id="canvas"></canvas>
        <div class="mic-status" id="micStatus">üéôÔ∏è</div>
    </div>
    
    <label for="cvInput" id="fileLabel">üìÑ Choose PDF Resume</label>
    <input type="file" id="cvInput" accept=".pdf">
    
    <button id="startBtn" class="btn" disabled>Start Interview</button>
    
    <div class="controls" id="controls" style="display:none;">
        <button id="muteBtn" class="btn secondary" style="flex:1;">üîá Mute AI</button>
        <button id="endBtn" class="btn danger" style="flex:1;">End Interview</button>
    </div>
    
    <div id="log"></div>
</div>

<script>
const API = "https://evalis-ai.simpaticohrconsultancy.workers.dev";
const pdfjsLib = window['pdfjs-dist/build/pdf'];
pdfjsLib.GlobalWorkerOptions.workerSrc = "https://cdnjs.cloudflare.com/ajax/libs/pdf.js/3.11.174/pdf.worker.min.js";

let cvText = "", history = [], interviewActive = false, recognition;
let audioCtx, analyser, dataArray, canvasCtx, timerInterval, timeLeft = 15 * 60;
let isProcessing = false;
let lastTranscriptTime = 0;
let aiMuted = false;
let currentUtterance = null;

// UI HELPERS
function log(msg, type = 'system') {
    console.log(`[${type}]`, msg);
    const d = document.createElement("div");
    d.className = type === 'user' ? 'user-msg' : type === 'ai' ? 'ai-msg' : 'system-msg';
    d.innerHTML = type === 'user' ? `<b>You:</b> ${msg}` : type === 'ai' ? `<b>AI:</b> ${msg}` : msg;
    document.getElementById("log").prepend(d);
    document.getElementById("log").scrollTop = 0;
}

function setStatus(text, className = '') {
    const el = document.getElementById("status");
    el.innerHTML = className === 'listening' ? `<span class="indicator"></span>${text}` : text;
    el.className = className;
}

function setMicStatus(icon) {
    document.getElementById("micStatus").textContent = icon;
}

/* PDF LOADING */
document.getElementById("cvInput").onchange = async e => {
    try {
        const file = e.target.files[0];
        if (!file) return;
        
        setStatus("Loading PDF...", "thinking");
        const pdf = await pdfjsLib.getDocument(await file.arrayBuffer()).promise;
        let text = "";
        
        for (let i = 1; i <= pdf.numPages; i++) {
            const page = await pdf.getPage(i);
            const content = await page.getTextContent();
            text += content.items.map(s => s.str).join(" ") + " ";
        }
        
        cvText = text.trim();
        
        if (cvText.length < 50) {
            throw new Error("Resume seems too short. Please check the PDF.");
        }
        
        document.getElementById("startBtn").disabled = false;
        setStatus("‚úÖ Resume Ready - Click Start", "");
        document.getElementById("fileLabel").textContent = "‚úÖ " + file.name;
        log("Resume loaded successfully!", 'system');
        
    } catch (err) {
        setStatus("‚ùå Error loading PDF", "");
        log("Error: " + err.message, 'system');
        alert("Failed to load PDF: " + err.message);
    }
};

/* WAVEFORM VISUALIZATION */
function initWave(stream) {
    try {
        audioCtx = new (window.AudioContext || window.webkitAudioContext)();
        analyser = audioCtx.createAnalyser();
        analyser.fftSize = 256;
        
        const source = audioCtx.createMediaStreamSource(stream);
        source.connect(analyser);
        
        dataArray = new Uint8Array(analyser.frequencyBinCount);
        
        const canvas = document.getElementById("canvas");
        canvas.width = 400;
        canvas.height = 60;
        canvasCtx = canvas.getContext("2d");
        
        function draw() {
            if (!interviewActive) return;
            
            requestAnimationFrame(draw);
            analyser.getByteFrequencyData(dataArray);
            
            canvasCtx.clearRect(0, 0, 400, 60);
            canvasCtx.fillStyle = "#6366f1";
            
            for (let i = 0; i < 80; i++) {
                const h = dataArray[i] / 2.5 || 5;
                canvasCtx.fillRect(i * 5, 30 - h/2, 3, h);
            }
        }
        
        draw();
    } catch (err) {
        log("Waveform init error: " + err.message, 'system');
    }
}

/* TIMER */
function startTimer() {
    timerInterval = setInterval(() => {
        timeLeft--;
        const min = Math.floor(timeLeft / 60);
        const sec = timeLeft % 60;
        document.getElementById("timer").textContent = `${min}:${sec.toString().padStart(2, '0')}`;
        
        if (timeLeft <= 0) {
            finishInterview();
        }
    }, 1000);
}

/* SPEECH SYNTHESIS - INTERRUPTIBLE */
function speak(text) {
    if (aiMuted) {
        log(text, 'ai');
        return Promise.resolve();
    }
    
    return new Promise((resolve) => {
        // Cancel any existing speech
        window.speechSynthesis.cancel();
        
        const utterance = new SpeechSynthesisUtterance(text);
        currentUtterance = utterance;
        
        utterance.rate = 0.95;
        utterance.pitch = 1.0;
        utterance.volume = 1.0;
        
        utterance.onstart = () => {
            setStatus("üó£Ô∏è AI Speaking (you can interrupt)", "speaking");
            setMicStatus("üó£Ô∏è");
        };
        
        utterance.onend = () => {
            setStatus("üé§ Listening", "listening");
            setMicStatus("üéôÔ∏è");
            currentUtterance = null;
            resolve();
        };
        
        utterance.onerror = () => {
            currentUtterance = null;
            resolve();
        };
        
        window.speechSynthesis.speak(utterance);
        log(text, 'ai');
    });
}

function stopSpeaking() {
    window.speechSynthesis.cancel();
    currentUtterance = null;
}

/* CONTINUOUS SPEECH RECOGNITION */
function initRecognition() {
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    
    if (!SpeechRecognition) {
        alert("Speech recognition not supported. Please use Chrome, Edge, or Safari.");
        return false;
    }
    
    recognition = new SpeechRecognition();
    recognition.continuous = true;
    recognition.interimResults = true;
    recognition.lang = 'en-US';
    recognition.maxAlternatives = 1;
    
    recognition.onstart = () => {
        setStatus("üé§ Listening", "listening");
        setMicStatus("üéôÔ∏è");
    };
    
    recognition.onend = () => {
        // Auto-restart if interview is active
        if (interviewActive) {
            setTimeout(() => {
                try {
                    recognition.start();
                } catch (e) {
                    if (e.name !== 'InvalidStateError') {
                        log("Recognition restart failed: " + e.message, 'system');
                    }
                }
            }, 100);
        }
    };
    
    recognition.onerror = (event) => {
        if (event.error === 'no-speech') {
            // Ignore - this is normal
            return;
        }
        
        if (event.error === 'aborted') {
            // Normal when we stop/restart
            return;
        }
        
        if (event.error === 'network') {
            log("Network error in speech recognition", 'system');
        }
        
        // Don't log audio-capture errors as they're common on restart
        if (event.error !== 'audio-capture') {
            console.warn("Recognition error:", event.error);
        }
    };
    
    recognition.onresult = (event) => {
        const now = Date.now();
        
        // Get the latest result
        const result = event.results[event.results.length - 1];
        const transcript = result[0].transcript.trim();
        
        // Only process final results
        if (!result.isFinal) return;
        
        // Ignore very short or empty transcripts
        if (transcript.length < 3) return;
        
        // Prevent duplicate processing of same transcript
        if (now - lastTranscriptTime < 2000) {
            return;
        }
        
        lastTranscriptTime = now;
        
        // If user speaks, interrupt AI
        if (currentUtterance) {
            stopSpeaking();
            log("(AI interrupted)", 'system');
        }
        
        // Process the user's response
        handleUserInput(transcript);
    };
    
    return true;
}

/* HANDLE USER INPUT */
async function handleUserInput(transcript) {
    if (isProcessing) return;
    
    isProcessing = true;
    log(transcript, 'user');
    setStatus("üí≠ Thinking...", "thinking");
    setMicStatus("‚è≥");
    
    try {
        const fd = new FormData();
        fd.append("mode", "interview");
        fd.append("history", JSON.stringify(history));
        fd.append("text", transcript);
        fd.append("cvText", cvText);

        const res = await fetch(API, { 
            method: "POST", 
            body: fd,
        });
        
        if (!res.ok) {
            throw new Error(`API returned ${res.status}`);
        }
        
        const data = await res.json();
        
        if (!data || !data.reply) {
            throw new Error("Invalid API response");
        }
        
        history = data.history || history;
        
        // Speak the AI's response
        await speak(data.reply);
        
    } catch (err) {
        log("Error: " + err.message, 'system');
        console.error("API Error:", err);
        
        // Retry logic
        await speak("I apologize, I had a connection issue. Could you please repeat that?");
        
    } finally {
        isProcessing = false;
        setStatus("üé§ Listening", "listening");
        setMicStatus("üéôÔ∏è");
    }
}

/* FINISH INTERVIEW */
async function finishInterview() {
    interviewActive = false;
    
    clearInterval(timerInterval);
    
    if (recognition) {
        recognition.stop();
        recognition = null;
    }
    
    stopSpeaking();
    
    setStatus("Generating Final Report...", "thinking");
    log("Interview ended. Generating score report...", 'system');
    
    try {
        const fd = new FormData();
        fd.append("mode", "score");
        fd.append("history", JSON.stringify(history));

        const res = await fetch(API, { method: "POST", body: fd });
        
        if (!res.ok) {
            throw new Error(`API error: ${res.status}`);
        }
        
        const data = await res.json();
        
        // Display report
        document.body.innerHTML = `
            <div class="card" style="max-width:700px">
                <h2 style="color:var(--primary); margin-top:0;">üìä Final Score Report</h2>
                <div class="report-box">${data.reply || "Report generation failed"}</div>
                <button onclick="location.reload()" class="btn" style="margin-top:20px">üîÑ New Interview</button>
            </div>`;
            
    } catch (err) {
        log("Error generating report: " + err.message, 'system');
        alert("Failed to generate report. Please try again.");
    }
}

/* START INTERVIEW */
document.getElementById("startBtn").onclick = async () => {
    try {
        setStatus("Requesting microphone access...", "thinking");
        
        // Request mic permission
        const stream = await navigator.mediaDevices.getUserMedia({ 
            audio: {
                echoCancellation: true,
                noiseSuppression: true,
                autoGainControl: true
            } 
        });
        
        // Initialize speech recognition
        if (!initRecognition()) {
            return;
        }
        
        // Start recognition
        recognition.start();
        
        // Initialize waveform
        initWave(stream);
        
        // Start timer
        startTimer();
        
        // Update UI
        interviewActive = true;
        document.getElementById("fileLabel").style.display = "none";
        document.getElementById("startBtn").style.display = "none";
        document.getElementById("controls").style.display = "flex";
        
        setStatus("Starting interview...", "thinking");
        
        // Get first question from API
        const fd = new FormData();
        fd.append("mode", "start");
        fd.append("cvText", cvText);
        
        const res = await fetch(API, { method: "POST", body: fd });
        
        if (!res.ok) {
            throw new Error(`API error: ${res.status}`);
        }
        
        const data = await res.json();
        
        if (!data || !data.reply) {
            throw new Error("Invalid API response");
        }
        
        history = data.history || [];
        
        // Speak first question
        await speak(data.reply);
        
    } catch (err) {
        log("Failed to start: " + err.message, 'system');
        alert("Failed to start interview: " + err.message);
        interviewActive = false;
    }
};

/* MUTE TOGGLE */
document.getElementById("muteBtn").onclick = () => {
    aiMuted = !aiMuted;
    const btn = document.getElementById("muteBtn");
    
    if (aiMuted) {
        stopSpeaking();
        btn.textContent = "üîä Unmute AI";
        btn.style.background = "#10b981";
        log("AI audio muted (text only)", 'system');
    } else {
        btn.textContent = "üîá Mute AI";
        btn.style.background = "#334155";
        log("AI audio unmuted", 'system');
    }
};

/* END INTERVIEW */
document.getElementById("endBtn").onclick = finishInterview;

// Prevent page unload during interview
window.onbeforeunload = (e) => {
    if (interviewActive) {
        e.preventDefault();
        return "Interview in progress. Are you sure you want to leave?";
    }
};
</script>
</body>
</html>
