<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>Evalis AI Interview</title>
<script src="https://cdnjs.cloudflare.com/ajax/libs/pdf.js/3.11.174/pdf.min.js"></script>
<style>
body {
  background:#0f172a; color:white; font-family:sans-serif;
  display:flex; justify-content:center; align-items:center; height:100vh;
}
.card {
  width:420px; background:#1e293b; padding:25px;
  border-radius:20px; box-shadow:0 20px 40px rgba(0,0,0,.5);
}
button {
  width:100%; padding:14px; margin-top:10px;
  background:#4f46e5; border:none; color:white; font-weight:bold;
  border-radius:12px;
}
#log {
  margin-top:15px; background:#020617; padding:12px;
  height:200px; overflow:auto; border-radius:12px;
}
.ai { color:#a5b4fc; margin-bottom:10px; }
.user { color:#94a3b8; font-style:italic; margin-bottom:10px; }
</style>
</head>
<body>

<div class="card">
  <h3>Evalis AI Interview</h3>
  <input type="file" id="cv" accept=".pdf"><br>
  <button id="start" disabled>Start Interview</button>
  <div id="log"></div>
</div>

<script>
const WORKER = "https://evalis-ai.simpaticohrconsultancy.workers.dev";
let cvText = "", history = [], active = false;

/* ========= PDF ========= */
pdfjsLib.GlobalWorkerOptions.workerSrc =
  "https://cdnjs.cloudflare.com/ajax/libs/pdf.js/3.11.174/pdf.worker.min.js";

cv.onchange = async e => {
  const pdf = await pdfjsLib.getDocument(await e.target.files[0].arrayBuffer()).promise;
  let text = "";
  for (let i=1;i<=pdf.numPages;i++) {
    const p = await pdf.getPage(i);
    const c = await p.getTextContent();
    text += c.items.map(x=>x.str).join(" ")+" ";
  }
  cvText = text.trim();
  start.disabled = false;
};

/* ========= LOG ========= */
const log = (cls, txt) => {
  const d = document.createElement("div");
  d.className = cls;
  d.textContent = txt;
  document.getElementById("log").appendChild(d);
};

/* ========= TTS ========= */
function speak(text){
  log("ai","AI: "+text);
  const u = new SpeechSynthesisUtterance(text);
  u.onend = () => active && listen();
  speechSynthesis.cancel();
  speechSynthesis.speak(u);
}

/* ========= PCM RECORDING ========= */
async function recordPCM(seconds=5){
  const stream = await navigator.mediaDevices.getUserMedia({ audio:true });
  const ctx = new AudioContext({ sampleRate:16000 });
  const src = ctx.createMediaStreamSource(stream);
  const processor = ctx.createScriptProcessor(4096,1,1);

  let pcm = [];
  src.connect(processor);
  processor.connect(ctx.destination);

  processor.onaudioprocess = e => {
    const input = e.inputBuffer.getChannelData(0);
    for (let i=0;i<input.length;i++) {
      pcm.push(Math.max(-1,Math.min(1,input[i]))*32767);
    }
  };

  await new Promise(r=>setTimeout(r,seconds*1000));
  stream.getTracks().forEach(t=>t.stop());
  ctx.close();

  return new Int16Array(pcm);
}

/* ========= LISTEN ========= */
async function listen(){
  const pcm = await recordPCM(5);
  if (pcm.length < 8000) return listen();

  const fd = new FormData();
  fd.append("mode","interview");
  fd.append("audio", new Blob([pcm.buffer]));
  fd.append("history", JSON.stringify(history));

  const res = await fetch(WORKER,{ method:"POST", body:fd });
  const data = await res.json();

  if (data.transcript) log("user","You: "+data.transcript);
  history = data.history || history;
  speak(data.reply);
}

/* ========= START ========= */
start.onclick = async ()=>{
  active = true;
  const fd = new FormData();
  fd.append("mode","start");
  fd.append("cvText",cvText);

  const res = await fetch(WORKER,{ method:"POST", body:fd });
  const data = await res.json();
  history = data.history;
  speak(data.reply);
};
</script>
</body>
</html>
