<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Evalis AI - Elite Live</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/pdf.js/3.11.174/pdf.min.js"></script>
    <style>
        :root { --primary: #6366f1; --bg: #020617; }
        body { margin: 0; background: var(--bg); color: white; font-family: sans-serif; display: flex; align-items: center; justify-content: center; min-height: 100vh; }
        .card { width: 90%; max-width: 420px; background: rgba(255,255,255,0.05); backdrop-filter: blur(15px); border-radius: 24px; padding: 30px; text-align: center; border: 1px solid rgba(255,255,255,0.1); }
        .wave-box { height: 100px; margin: 20px 0; display: flex; align-items: center; justify-content: center; }
        canvas { width: 100%; height: 60px; }
        .btn { background: var(--primary); color: white; border: none; padding: 15px; border-radius: 12px; width: 100%; font-weight: bold; cursor: pointer; font-size: 16px; }
        #status { font-size: 12px; color: #94a3b8; margin-bottom: 15px; text-transform: uppercase; }
        #log { margin-top: 20px; height: 120px; overflow-y: auto; text-align: left; font-size: 13px; border-top: 1px solid #334155; padding-top: 10px; }
    </style>
</head>
<body>

<div class="card">
    <div id="status">Upload Resume to Start</div>
    <div class="wave-box"><canvas id="canvas"></canvas></div>
    
    <input type="file" id="cvInput" accept=".pdf" style="margin-bottom:10px">
    <button id="startBtn" class="btn" disabled>Start Interview</button>
    <button id="endBtn" class="btn" style="display:none; background:#ef4444">End Session</button>
    
    <div id="log"></div>
</div>

<script>
const API = "https://evalis-ai.simpaticohrconsultancy.workers.dev";
const pdfjsLib = window['pdfjs-dist/build/pdf'];
pdfjsLib.GlobalWorkerOptions.workerSrc = "https://cdnjs.cloudflare.com/ajax/libs/pdf.js/3.11.174/pdf.worker.min.js";

let cvText = "", history = [], interviewActive = false, isAISpeaking = false, recognition;
let audioCtx, analyser, dataArray, canvasCtx;

/* 1. PDF & INITIALIZATION */
document.getElementById("cvInput").onchange = async e => {
    const pdf = await pdfjsLib.getDocument(await e.target.files[0].arrayBuffer()).promise;
    let text = "";
    for (let i = 1; i <= pdf.numPages; i++) {
        const page = await pdf.getPage(i);
        text += (await page.getTextContent()).items.map(s => s.str).join(" ") + " ";
    }
    cvText = text;
    document.getElementById("startBtn").disabled = false;
    document.getElementById("status").textContent = "Resume Loaded";
};

/* 2. MERCOR WAVEFORM */
function startWave(stream) {
    audioCtx = new AudioContext();
    analyser = audioCtx.createAnalyser();
    audioCtx.createMediaStreamSource(stream).connect(analyser);
    dataArray = new Uint8Array(analyser.frequencyBinCount);
    canvasCtx = document.getElementById("canvas").getContext("2d");
    draw();
}

function draw() {
    requestAnimationFrame(draw);
    analyser.getByteFrequencyData(dataArray);
    canvasCtx.clearRect(0, 0, 400, 60);
    canvasCtx.fillStyle = "#6366f1";
    for (let i = 0; i < 100; i++) {
        let h = dataArray[i] / 2;
        canvasCtx.fillRect(i * 4, 30 - h/2, 2, h);
    }
}

/* 3. SPEECH ENGINE (Text-to-Speech) */
function speak(text) {
    window.speechSynthesis.cancel();
    const u = new SpeechSynthesisUtterance(text);
    u.onstart = () => { 
        isAISpeaking = true; 
        if(recognition) recognition.stop(); // ðŸ›‘ Stop mic so it doesn't hear itself
    };
    u.onend = () => { 
        isAISpeaking = false; 
        if(interviewActive) recognition.start(); // ðŸŸ¢ Listen again
    };
    window.speechSynthesis.speak(u);
    const div = document.createElement("div");
    div.innerHTML = `<b>AI:</b> ${text}`;
    document.getElementById("log").prepend(div);
}

/* 4. LIVE LISTENING (Speech-to-Text) */
function initRecognition() {
    const SR = window.SpeechRecognition || window.webkitSpeechRecognition;
    recognition = new SR();
    recognition.continuous = true;
    recognition.onresult = async e => {
        const transcript = e.results[e.results.length - 1][0].transcript.trim();
        
        // ðŸ”´ BARGE-IN: If you speak, AI stops talking immediately
        if (isAISpeaking) { window.speechSynthesis.cancel(); isAISpeaking = false; }
        
        document.getElementById("status").textContent = "AI Thinking...";
        const fd = new FormData();
        fd.append("mode", "interview");
        fd.append("history", JSON.stringify(history));
        fd.append("text", transcript);
        fd.append("cvText", cvText);

        const res = await fetch(API, { method: "POST", body: fd });
        const data = await res.json();
        history = data.history;
        speak(data.reply);
    };
    recognition.onstart = () => { document.getElementById("status").textContent = "ðŸ”´ Listening..."; };
}

/* 5. START BUTTON */
document.getElementById("startBtn").onclick = async () => {
    // ðŸŸ¢ CRITICAL: Unlock audio for mobile/Chrome
    window.speechSynthesis.speak(new SpeechSynthesisUtterance("")); 
    
    interviewActive = true;
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    startWave(stream);
    initRecognition();

    document.getElementById("startBtn").style.display = "none";
    document.getElementById("endBtn").style.display = "block";

    const fd = new FormData();
    fd.append("mode", "start");
    fd.append("cvText", cvText);
    const res = await fetch(API, { method: "POST", body: fd });
    const data = await res.json();
    history = data.history;
    speak(data.reply);
};
</script>
</body>
</html>
