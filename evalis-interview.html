<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Evalis AI - Technical Assessment</title>
<script src="https://cdnjs.cloudflare.com/ajax/libs/pdf.js/3.11.174/pdf.min.js"></script>
<style>
:root { --bg:#0f172a; --card:#1e293b; --accent:#4f46e5; --muted:#94a3b8; }
body { margin:0; background:var(--bg); color:white; font-family:Inter,system-ui,sans-serif; display:flex; justify-content:center; align-items:center; min-height:100vh; }
.container { width:92%; max-width:480px; background:var(--card); padding:28px; border-radius:22px; border:1px solid #334155; box-shadow:0 20px 40px rgba(0,0,0,.45); }
#status { font-size:11px; letter-spacing:2px; color:var(--muted); margin-bottom:10px; text-transform:uppercase; text-align:center; }
.timer { font-size:3.5rem; font-weight:800; color:var(--accent); text-align:center; font-family:monospace; margin:12px 0; }
/* Volume Visualizer */
#volume-bar { width: 100%; height: 6px; background: #020617; border-radius: 3px; margin-bottom: 20px; overflow: hidden; }
#volume-fill { height: 100%; width: 0%; background: var(--accent); transition: width 0.1s ease; }
button { width:100%; padding:16px; border:none; border-radius:12px; background:var(--accent); color:white; font-weight:700; cursor:pointer; }
button:disabled { opacity:.5; cursor:not-allowed; }
#transcript { margin-top:20px; height:180px; overflow-y:auto; background:#020617; padding:14px; border-radius:12px; border:1px solid #334155; font-size:13px; }
.ai { color:#a5b4fc; margin-bottom:10px; }
.user { color:#94a3b8; font-style:italic; margin-bottom:8px; }
</style>
</head>
<body>

<div class="container">
  <div id="status">Upload Resume to Start</div>
  <div class="timer" id="timer">15:00</div>
  <div id="volume-bar"><div id="volume-fill"></div></div>
  <input type="file" id="cvInput" accept=".pdf" style="width:100%; font-size:12px; margin-bottom:15px;">
  <button id="startBtn" disabled>Initialize Assessment</button>
  <div id="transcript"></div>
</div>

<script>
const WORKER_URL = "https://evalis-ai.simpaticohrconsultancy.workers.dev";
let cvText = "", history = [], active = false, busy = false, timeLeft = 900;

/* ================= PDF ENGINE ================= */
pdfjsLib.GlobalWorkerOptions.workerSrc = "https://cdnjs.cloudflare.com/ajax/libs/pdf.js/3.11.174/pdf.worker.min.js";
document.getElementById("cvInput").onchange = async e => {
  const file = e.target.files[0];
  const buffer = await file.arrayBuffer();
  const pdf = await pdfjsLib.getDocument(buffer).promise;
  let text = "";
  for(let i=1; i<=pdf.numPages; i++){
    const page = await pdf.getPage(i);
    const c = await page.getTextContent();
    text += c.items.map(x=>x.str).join(" ") + " ";
  }
  cvText = text.trim();
  document.getElementById("status").innerText = "Resume Ready";
  document.getElementById("startBtn").disabled = false;
};

/* ================= SPEECH ENGINE ================= */
function speak(text) {
  if(!text) return;
  document.getElementById("transcript").innerHTML += `<div class="ai">AI: ${text}</div>`;
  document.getElementById("transcript").scrollTop = document.getElementById("transcript").scrollHeight;
  document.getElementById("status").innerText = "Interviewer Speaking";

  const u = new SpeechSynthesisUtterance(text);
  u.onend = () => { 
    busy = false; 
    if(active) setTimeout(startTurn, 500); // Trigger next listen
  };
  speechSynthesis.cancel();
  speechSynthesis.speak(u);
}

/* ================= VOLUME SENSING LISTEN LOOP ================= */
async function startTurn() {
  if(!active || busy || timeLeft <= 0) return;
  busy = true;
  document.getElementById("status").innerText = "Listening...";

  try {
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    
    // Setup Audio Metering
    const audioCtx = new AudioContext();
    const source = audioCtx.createMediaStreamSource(stream);
    const analyzer = audioCtx.createAnalyser();
    source.connect(analyzer);
    const data = new Uint8Array(analyzer.frequencyBinCount);

    const rec = new MediaRecorder(stream);
    const chunks = [];
    rec.ondataavailable = e => chunks.push(e.data);

    // Visual feedback loop
    const checkVolume = () => {
      if(!busy) return;
      analyzer.getByteFrequencyData(data);
      const volume = Math.max(...data);
      document.getElementById("volume-fill").style.width = (volume / 2.5) + "%";
      requestAnimationFrame(checkVolume);
    };
    checkVolume();

    rec.onstop = async () => {
      stream.getTracks().forEach(t => t.stop());
      audioCtx.close();
      const audioBlob = new Blob(chunks, { type: "audio/webm" });

      // FIX: Silence Guard - prevents random "Please repeat"
      if (audioBlob.size < 7000) {
        busy = false;
        document.getElementById("status").innerText = "No Speech Detected";
        setTimeout(startTurn, 1000); // Restart listening without AI interruption
        return;
      }

      document.getElementById("status").innerText = "Analyzing Answer...";
      const fd = new FormData();
      fd.append("mode", "interview");
      fd.append("audio", audioBlob);
      fd.append("cvText", cvText);
      fd.append("history", JSON.stringify(history));

      const res = await fetch(WORKER_URL, { method: "POST", body: fd });
      const result = await res.json();
      
      history = result.history || history;
      if (result.transcript) {
        document.getElementById("transcript").innerHTML += `<div class="user">You: ${result.transcript}</div>`;
      }
      speak(result.reply);
    };

    rec.start();
    setTimeout(() => { if(rec.state === "recording") rec.stop(); }, 8000);
  } catch (err) {
    busy = false;
    alert("Microphone access denied.");
  }
}

/* ================= INITIALIZATION ================= */
document.getElementById("startBtn").onclick = async () => {
  active = true; busy = true;
  document.getElementById("startBtn").style.display = "none";
  setInterval(() => { if(active && timeLeft > 0) timeLeft--; }, 1000);
  
  const fd = new FormData();
  fd.append("mode", "start");
  fd.append("cvText", cvText);
  const res = await fetch(WORKER_URL, { method: "POST", body: fd });
  const data = await res.json();
  history = data.history;
  speak(data.reply);
};
</script>
</body>
</html>
