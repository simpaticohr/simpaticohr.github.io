let chatHistory = [];
let isInterviewActive = false;
const synth = window.speechSynthesis;

// ðŸ”Š Function: AI speaks and then triggers the mic
function aiSpeak(text) {
  const utterance = new SpeechSynthesisUtterance(text);
  utterance.onend = () => {
    if (isInterviewActive) startContinuousListen(); // ðŸŽ¤ Listen immediately after speaking
  };
  synth.speak(utterance);
}

// ðŸŽ¤ Function: Continuous recording cycle
async function startContinuousListen() {
  const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
  const recorder = new MediaRecorder(stream);
  const chunks = [];

  recorder.ondataavailable = e => chunks.push(e.data);
  recorder.onstop = async () => {
    const fd = new FormData();
    fd.append("audio", new Blob(chunks, { type: "audio/webm" }));
    fd.append("mode", "interview");
    fd.append("cvText", globalExtractedCVText); 
    fd.append("history", JSON.stringify(chatHistory));

    const res = await fetch(API_URL, { method: "POST", body: fd });
    const data = await res.json();
    
    chatHistory = data.newHistory;
    aiSpeak(data.nextQuestion); // ðŸ”„ Back to AI speaking
  };

  recorder.start();
  // Auto-stop recording after 8 seconds of user speaking
  setTimeout(() => { if (recorder.state === "recording") recorder.stop(); }, 8000);
}
