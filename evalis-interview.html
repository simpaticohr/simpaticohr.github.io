<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>simpaticoai | Elite Interviewer</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/pdf.js/3.11.174/pdf.min.js"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600&display=swap" rel="stylesheet">
    <style>
        :root {
            --bg: #030307;
            --surface: #0a0b10;
            --primary: #6366f1;
            --accent: #a855f7;
            --text: #f8fafc;
            --text-dim: #94a3b8;
            --success: #10b981;
            --danger: #ef4444;
        }

        body {
            margin: 0; background: var(--bg); color: var(--text);
            font-family: 'Inter', sans-serif;
            display: flex; flex-direction: column; align-items: center;
            justify-content: center; min-height: 100vh; overflow: hidden;
        }

        /* --- THE ELITE ORB --- */
        .orb-container { position: relative; width: 280px; height: 280px; display: flex; align-items: center; justify-content: center; margin-bottom: 20px; }
        
        .orb {
            width: 140px; height: 140px;
            background: #000;
            border-radius: 50%;
            position: relative; z-index: 2;
            transition: all 0.5s cubic-bezier(0.19, 1, 0.22, 1);
            display: flex; align-items: center; justify-content: center;
            border: 1px solid rgba(99, 102, 241, 0.2);
            box-shadow: 0 0 80px rgba(99, 102, 241, 0.1);
        }

        canvas { position: absolute; width: 100%; height: 100%; border-radius: 50%; }

        /* Status Glows */
        .orb.listening { border-color: var(--success); box-shadow: 0 0 100px rgba(16, 185, 129, 0.15); }
        .orb.speaking { border-color: var(--primary); box-shadow: 0 0 100px rgba(99, 102, 241, 0.2); }
        .orb.thinking { animation: pulse-thinking 2s infinite; border-color: var(--accent); }

        @keyframes pulse-thinking { 0% { transform: scale(1); opacity: 1; } 50% { transform: scale(1.05); opacity: 0.7; } 100% { transform: scale(1); opacity: 1; } }

        .interface { width: 90%; max-width: 450px; text-align: center; z-index: 10; }
        .status-pill { display: inline-block; padding: 8px 20px; background: rgba(255, 255, 255, 0.03); border: 1px solid rgba(255, 255, 255, 0.08); border-radius: 50px; font-size: 0.8rem; color: var(--text-dim); margin-bottom: 40px; text-transform: uppercase; letter-spacing: 2px; }

        .btn { background: var(--primary); color: white; border: none; padding: 16px 32px; border-radius: 12px; cursor: pointer; font-weight: 600; width: 100%; transition: 0.3s; }
        .btn:hover { transform: translateY(-2px); box-shadow: 0 10px 20px rgba(99, 102, 241, 0.2); }
        .btn-danger { background: rgba(239, 68, 68, 0.1); color: var(--danger); border: 1px solid rgba(239, 68, 68, 0.2); }

        .file-trigger { border: 2px dashed rgba(255, 255, 255, 0.1); padding: 50px 20px; border-radius: 24px; cursor: pointer; display:block; color: var(--text-dim); transition: 0.3s; }
        .file-trigger:hover { border-color: var(--primary); background: rgba(99, 102, 241, 0.02); color: var(--text); }
        input[type="file"] { display: none; }

        .timer { font-family: monospace; color: var(--text-dim); margin-top: 20px; font-size: 1.2rem; letter-spacing: 2px; }
        
        /* Modal for Report */
        .modal { position: fixed; inset: 0; background: rgba(0,0,0,0.9); display: none; align-items: center; justify-content: center; z-index: 100; backdrop-filter: blur(15px); }
        .modal-content { background: var(--surface); padding: 40px; border-radius: 30px; width: 85%; max-width: 600px; border: 1px solid rgba(255,255,255,0.05); }
    </style>
</head>
<body>

    <div class="orb-container">
        <div id="orb" class="orb">
            <canvas id="canvas"></canvas>
        </div>
    </div>

    <div class="interface">
        <div id="status" class="status-pill">System Standby</div>
        
        <div id="setupPanel">
            <label class="file-trigger">
                <span>ðŸ“‚ DROP RESUME (PDF)</span>
                <input type="file" id="cvInput" accept=".pdf">
            </label>
            <br>
            <button id="startBtn" class="btn" style="display:none;">INITIALIZE INTERVIEW</button>
        </div>

        <div id="activePanel" style="display:none;">
            <button id="endBtn" class="btn btn-danger">CONCLUDE SESSION</button>
            <div id="timer" class="timer">15:00</div>
        </div>
    </div>

    <div id="reportModal" class="modal">
        <div class="modal-content">
            <h2 style="color:var(--primary);">Evaluation Summary</h2>
            <div id="reportText" style="line-height: 1.8; color: var(--text-dim); white-space: pre-wrap; font-size: 0.95rem;"></div>
            <button onclick="location.reload()" class="btn" style="margin-top:30px;">RESTART SYSTEM</button>
        </div>
    </div>

<script>
    const API_URL = "https://evalis-ai.simpaticohrconsultancy.workers.dev";
    pdfjsLib.GlobalWorkerOptions.workerSrc = "https://cdnjs.cloudflare.com/ajax/libs/pdf.js/3.11.174/pdf.worker.min.js";

    let state = {
        cvText: "",
        history: [],
        timeLeft: 900,
        isSessionActive: false,
        isAiSpeaking: false
    };

    // --- ELITE AUDIO VISUALIZER (Whisper Style) ---
    let audioCtx, analyser, dataArray;
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');

    async function initAudio() {
        try {
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            audioCtx = new (window.AudioContext || window.webkitAudioContext)();
            analyser = audioCtx.createAnalyser();
            analyser.fftSize = 512;
            const source = audioCtx.createMediaStreamSource(stream);
            source.connect(analyser);
            dataArray = new Uint8Array(analyser.frequencyBinCount);
            renderFrame();
            return true;
        } catch (e) {
            alert("Mic access is required for elite mode.");
            return false;
        }
    }

    function renderFrame() {
        requestAnimationFrame(renderFrame);
        const width = canvas.width = canvas.offsetWidth;
        const height = canvas.height = canvas.offsetHeight;
        analyser.getByteFrequencyData(dataArray);
        
        ctx.clearRect(0, 0, width, height);
        
        // Calculate average volume for interruption logic
        let values = 0;
        for (let i = 0; i < dataArray.length; i++) values += dataArray[i];
        let average = values / dataArray.length;

        // TRUE HUMAN INTERRUPTION: If user speaks loudly while AI is talking
        if (state.isAiSpeaking && average > 45) { // Threshold for interruption
            console.log("User interrupted AI.");
            window.speechSynthesis.cancel();
            state.isAiSpeaking = false;
            setOrbState('listening');
        }

        // Visual design: Glowing particles / bars
        ctx.beginPath();
        ctx.strokeStyle = state.isAiSpeaking ? '#6366f1' : '#10b981';
        ctx.lineWidth = 2;
        
        for (let i = 0; i < dataArray.length; i++) {
            let v = dataArray[i] / 128.0;
            let y = v * height / 2;
            let x = (i / dataArray.length) * width;
            if (i === 0) ctx.moveTo(x, y); else ctx.lineTo(x, y);
        }
        ctx.stroke();
    }

    // --- SPEECH ENGINE ---
    const Recognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    const recognition = new Recognition();
    recognition.continuous = true;
    recognition.interimResults = true; // Essential for Whisper-style responsiveness
    recognition.lang = 'en-US';

    function setOrbState(mode) {
        const orb = document.getElementById('orb');
        const status = document.getElementById('status');
        orb.className = 'orb ' + mode;
        status.textContent = mode === 'listening' ? 'Analyzing Audio...' : 
                             mode === 'speaking' ? 'Interviewer Speaking' : 
                             mode === 'thinking' ? 'Processing Thought' : 'Ready';
    }

    recognition.onresult = (event) => {
        let interimTranscript = '';
        let finalTranscript = '';

        for (let i = event.resultIndex; i < event.results.length; ++i) {
            if (event.results[i].isFinal) finalTranscript += event.results[i][0].transcript;
            else interimTranscript += event.results[i][0].transcript;
        }

        // If the user has finished a sentence, wait a beat (Human Pacing) then send
        if (finalTranscript.trim() && !state.isAiSpeaking) {
            handleUserResponse(finalTranscript);
        }
    };

    // Keep recognition alive (Elite persistence)
    recognition.onend = () => { if (state.isSessionActive) recognition.start(); };

    async function handleUserResponse(text) {
        setOrbState('thinking');
        
        const fd = new FormData();
        fd.append("mode", "interview");
        fd.append("history", JSON.stringify(state.history));
        fd.append("text", text);
        fd.append("cvText", state.cvText);

        try {
            const res = await fetch(API_URL, { method: "POST", body: fd });
            const data = await res.json();
            state.history = data.history;
            
            // Artificial delay to simulate human "Thinking"
            setTimeout(() => {
                if (state.isSessionActive) speak(data.reply);
            }, 800);
            
        } catch (e) {
            setOrbState('listening');
        }
    }

    function speak(text) {
        state.isAiSpeaking = true;
        setOrbState('speaking');
        
        const utterance = new SpeechSynthesisUtterance(text);
        const voices = window.speechSynthesis.getVoices();
        // Look for elite voices
        utterance.voice = voices.find(v => v.name.includes('Google US English') || v.name.includes('Natural')) || voices[0];
        utterance.rate = 0.95; 
        utterance.pitch = 1.0;

        utterance.onend = () => {
            state.isAiSpeaking = false;
            if (state.isSessionActive) setOrbState('listening');
        };

        window.speechSynthesis.speak(utterance);
    }

    // --- LOGIC & UI ---
    document.getElementById('cvInput').onchange = async (e) => {
        const file = e.target.files[0];
        if(!file) return;
        document.getElementById('status').textContent = "Reading Credentials...";
        const buffer = await file.arrayBuffer();
        const pdf = await pdfjsLib.getDocument({ data: new Uint8Array(buffer) }).promise;
        let fullText = "";
        for (let i = 1; i <= pdf.numPages; i++) {
            const page = await pdf.getPage(i);
            const textContent = await page.getTextContent();
            fullText += textContent.items.map(s => s.str).join(" ");
        }
        state.cvText = fullText;
        document.getElementById('status').textContent = "Credentials Authenticated";
        document.getElementById('startBtn').style.display = "block";
    };

    document.getElementById('startBtn').onclick = async () => {
        const ok = await initAudio();
        if (!ok) return;

        state.isSessionActive = true;
        document.getElementById('setupPanel').style.display = 'none';
        document.getElementById('activePanel').style.display = 'block';
        recognition.start();

        // Initial Greeting
        setOrbState('thinking');
        const fd = new FormData();
        fd.append("mode", "start");
        fd.append("cvText", state.cvText);
        const res = await fetch(API_URL, { method: "POST", body: fd });
        const data = await res.json();
        state.history = data.history;
        speak(data.reply);

        // Timer
        setInterval(() => {
            if (state.timeLeft > 0 && state.isSessionActive) {
                state.timeLeft--;
                const m = Math.floor(state.timeLeft/60);
                const s = state.timeLeft%60;
                document.getElementById('timer').textContent = `${m}:${s < 10 ? '0'+s : s}`;
            }
        }, 1000);
    };

    document.getElementById('endBtn').onclick = async () => {
        state.isSessionActive = false;
        window.speechSynthesis.cancel();
        document.getElementById('activePanel').style.display = 'none';
        setOrbState('thinking');
        
        const fd = new FormData();
        fd.append("mode", "score");
        fd.append("history", JSON.stringify(state.history));
        const res = await fetch(API_URL, { method: "POST", body: fd });
        const data = await res.json();
        
        document.getElementById('reportText').textContent = data.reply;
        document.getElementById('reportModal').style.display = 'flex';
    };

    // Wake Lock to prevent mobile dimming
    if ('wakeLock' in navigator) {
        navigator.wakeLock.request('screen').catch(()=>{});
    }
</script>
</body>
</html>
