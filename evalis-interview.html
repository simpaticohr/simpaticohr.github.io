<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Evalis AI ‚Äì Intelligent Interview</title>

<style>
:root { 
  --primary: #6366f1; 
  --bg: #0f172a;
  --success: #10b981;
  --listening: #f59e0b;
  --error: #ef4444;
}

* { margin: 0; padding: 0; box-sizing: border-box; }

body {
  background: linear-gradient(135deg, #020617 0%, #0f172a 100%);
  color: #fff;
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', system-ui, sans-serif;
  min-height: 100vh;
  padding: 20px;
}

.container {
  max-width: 600px;
  margin: 0 auto;
}

.card {
  background: rgba(255,255,255,.06);
  backdrop-filter: blur(10px);
  border-radius: 24px;
  padding: 40px;
  border: 1px solid rgba(255,255,255,.08);
  box-shadow: 0 20px 60px rgba(0,0,0,.3);
}

h1 {
  font-size: 28px;
  margin-bottom: 8px;
  background: linear-gradient(135deg, #6366f1, #8b5cf6);
  -webkit-background-clip: text;
  -webkit-text-fill-color: transparent;
  text-align: center;
}

.subtitle {
  text-align: center;
  color: #94a3b8;
  margin-bottom: 32px;
  font-size: 14px;
}

/* CV Upload Section */
.upload-section {
  margin-bottom: 24px;
}

.upload-area {
  border: 2px dashed rgba(99,102,241,.4);
  border-radius: 16px;
  padding: 32px;
  text-align: center;
  cursor: pointer;
  transition: all 0.3s;
  background: rgba(99,102,241,.05);
}

.upload-area:hover {
  border-color: var(--primary);
  background: rgba(99,102,241,.1);
}

.upload-area.dragover {
  border-color: var(--success);
  background: rgba(16,185,129,.1);
}

.upload-icon {
  font-size: 48px;
  margin-bottom: 12px;
}

.upload-text {
  font-size: 16px;
  margin-bottom: 8px;
}

.upload-subtext {
  font-size: 13px;
  color: #94a3b8;
}

.file-input {
  display: none;
}

.file-info {
  display: none;
  background: rgba(16,185,129,.2);
  border-radius: 12px;
  padding: 16px;
  margin-top: 16px;
  border-left: 3px solid var(--success);
}

.file-info.show {
  display: block;
}

.file-name {
  font-weight: 600;
  margin-bottom: 4px;
}

.file-size {
  font-size: 13px;
  color: #94a3b8;
}

/* Voice Visualizer */
.voice-container {
  position: relative;
  width: 180px;
  height: 180px;
  margin: 24px auto;
  display: none;
}

.voice-container.show {
  display: block;
}

.voice-circle {
  position: absolute;
  top: 50%;
  left: 50%;
  transform: translate(-50%, -50%);
  width: 140px;
  height: 140px;
  border-radius: 50%;
  background: linear-gradient(135deg, var(--primary), #8b5cf6);
  display: flex;
  align-items: center;
  justify-content: center;
  font-size: 48px;
  transition: all 0.3s ease;
}

.voice-circle.listening {
  animation: pulse 2s infinite;
  background: linear-gradient(135deg, var(--listening), #f97316);
}

.voice-circle.speaking {
  background: linear-gradient(135deg, var(--success), #059669);
  animation: speaking 1s infinite;
}

.voice-circle.thinking {
  background: linear-gradient(135deg, #8b5cf6, #a855f7);
  animation: thinking 2s infinite;
}

@keyframes pulse {
  0%, 100% { box-shadow: 0 0 0 0 rgba(245, 158, 11, 0.7); }
  50% { box-shadow: 0 0 0 20px rgba(245, 158, 11, 0); }
}

@keyframes speaking {
  0%, 100% { transform: translate(-50%, -50%) scale(1); }
  50% { transform: translate(-50%, -50%) scale(1.05); }
}

@keyframes thinking {
  0%, 100% { transform: translate(-50%, -50%) rotate(0deg); }
  50% { transform: translate(-50%, -50%) rotate(10deg); }
}

.wave {
  position: absolute;
  top: 50%;
  left: 50%;
  transform: translate(-50%, -50%);
  width: 140px;
  height: 140px;
  border-radius: 50%;
  border: 2px solid var(--listening);
  opacity: 0;
}

.wave.active {
  animation: wave 2s infinite;
}

@keyframes wave {
  0% { width: 140px; height: 140px; opacity: 0.6; }
  100% { width: 200px; height: 200px; opacity: 0; }
}

.status-text {
  font-size: 18px;
  font-weight: 600;
  margin-bottom: 8px;
  text-align: center;
  min-height: 28px;
}

.status-subtext {
  color: #94a3b8;
  font-size: 14px;
  text-align: center;
  margin-bottom: 24px;
  min-height: 20px;
}

/* Buttons */
.btn {
  width: 100%;
  padding: 18px;
  margin-top: 12px;
  border: none;
  border-radius: 14px;
  font-size: 16px;
  font-weight: 700;
  background: linear-gradient(135deg, var(--primary), #8b5cf6);
  color: white;
  cursor: pointer;
  transition: all 0.3s ease;
  text-transform: uppercase;
  letter-spacing: 0.5px;
}

.btn:hover {
  transform: translateY(-2px);
  box-shadow: 0 10px 30px rgba(99, 102, 241, 0.4);
}

.btn:disabled {
  opacity: 0.5;
  cursor: not-allowed;
  transform: none;
}

.btn.stop {
  background: linear-gradient(135deg, #ef4444, #dc2626);
}

.btn.secondary {
  background: rgba(255,255,255,.1);
}

/* Conversation */
.conversation {
  margin-top: 32px;
  max-height: 400px;
  overflow-y: auto;
  display: none;
}

.conversation.show {
  display: block;
}

.conversation::-webkit-scrollbar {
  width: 6px;
}

.conversation::-webkit-scrollbar-thumb {
  background: rgba(99, 102, 241, 0.5);
  border-radius: 3px;
}

.message {
  margin-bottom: 16px;
  padding: 16px;
  border-radius: 12px;
  animation: slideIn 0.3s ease;
}

@keyframes slideIn {
  from { opacity: 0; transform: translateY(10px); }
  to { opacity: 1; transform: translateY(0); }
}

.message.user {
  background: rgba(99, 102, 241, 0.2);
  border-left: 3px solid var(--primary);
}

.message.ai {
  background: rgba(16, 185, 129, 0.2);
  border-left: 3px solid var(--success);
}

.message.system {
  background: rgba(139, 92, 246, 0.2);
  border-left: 3px solid #8b5cf6;
  font-style: italic;
}

.message .label {
  font-size: 12px;
  font-weight: 700;
  text-transform: uppercase;
  letter-spacing: 0.5px;
  margin-bottom: 8px;
  opacity: 0.7;
}

.message .text {
  font-size: 14px;
  line-height: 1.6;
}

.cv-summary {
  background: rgba(139, 92, 246, 0.1);
  border-radius: 12px;
  padding: 16px;
  margin-bottom: 20px;
  border-left: 3px solid #8b5cf6;
  display: none;
}

.cv-summary.show {
  display: block;
}

.cv-summary-title {
  font-size: 13px;
  font-weight: 700;
  text-transform: uppercase;
  margin-bottom: 8px;
  color: #a78bfa;
}

.cv-summary-content {
  font-size: 13px;
  line-height: 1.5;
  color: #c4b5fd;
}
</style>
</head>

<body>

<div class="container">
  <div class="card">
    <h1>üéôÔ∏è Evalis AI Interview</h1>
    <p class="subtitle">Intelligent CV-Based Voice Experience</p>

    <!-- CV Upload Section -->
    <div class="upload-section" id="uploadSection">
      <div class="upload-area" id="uploadArea">
        <div class="upload-icon">üìÑ</div>
        <div class="upload-text">Upload Your CV/Resume</div>
        <div class="upload-subtext">PDF, DOC, DOCX, or TXT ‚Ä¢ Max 5MB</div>
      </div>
      <input type="file" id="fileInput" class="file-input" accept=".pdf,.doc,.docx,.txt">
      
      <div class="file-info" id="fileInfo">
        <div class="file-name" id="fileName">üìÑ document.pdf</div>
        <div class="file-size" id="fileSize">250 KB</div>
      </div>
    </div>

    <!-- CV Summary -->
    <div class="cv-summary" id="cvSummary">
      <div class="cv-summary-title">üìã CV Analysis</div>
      <div class="cv-summary-content" id="cvSummaryContent"></div>
    </div>

    <!-- Voice Visualizer -->
    <div class="voice-container" id="voiceContainer">
      <div class="wave"></div>
      <div class="wave" style="animation-delay: 0.5s;"></div>
      <div class="voice-circle" id="voiceCircle">üé§</div>
    </div>

    <div class="status-text" id="statusText">Ready to Start</div>
    <div class="status-subtext" id="statusSubtext">Upload your CV to begin intelligent interview</div>

    <button id="startBtn" class="btn" disabled>üöÄ Start Interview</button>
    <button id="stopBtn" class="btn stop" style="display:none;">‚èπÔ∏è End Interview</button>
    <button id="skipCvBtn" class="btn secondary">Skip CV & Start General Interview</button>

    <!-- Conversation Log -->
    <div class="conversation" id="conversation"></div>
  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/pdf.js/3.11.174/pdf.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mammoth/1.6.0/mammoth.browser.min.js"></script>

<script>
/* ================= CONFIG ================= */
const API = "https://evalis-ai.simpaticohrconsultancy.workers.dev";

/* ================= STATE ================= */
let recognition;
let audioUnlocked = false;
let history = [];
let cvContent = "";
let cvAnalysis = "";
let isListening = false;
let isProcessing = false;
let isSpeaking = false;
let interviewActive = false;
let silenceTimer;
const silenceTimeout = 2000;

/* ================= UI ELEMENTS ================= */
const uploadArea = document.getElementById("uploadArea");
const fileInput = document.getElementById("fileInput");
const fileInfo = document.getElementById("fileInfo");
const fileName = document.getElementById("fileName");
const fileSize = document.getElementById("fileSize");
const uploadSection = document.getElementById("uploadSection");
const voiceContainer = document.getElementById("voiceContainer");
const voiceCircle = document.getElementById("voiceCircle");
const statusText = document.getElementById("statusText");
const statusSubtext = document.getElementById("statusSubtext");
const conversation = document.getElementById("conversation");
const startBtn = document.getElementById("startBtn");
const stopBtn = document.getElementById("stopBtn");
const skipCvBtn = document.getElementById("skipCvBtn");
const cvSummary = document.getElementById("cvSummary");
const cvSummaryContent = document.getElementById("cvSummaryContent");
const waves = document.querySelectorAll(".wave");

/* ================= PDF.js SETUP ================= */
pdfjsLib.GlobalWorkerOptions.workerSrc = 'https://cdnjs.cloudflare.com/ajax/libs/pdf.js/3.11.174/pdf.worker.min.js';

/* ================= FILE UPLOAD ================= */
uploadArea.onclick = () => fileInput.click();

uploadArea.ondragover = (e) => {
  e.preventDefault();
  uploadArea.classList.add("dragover");
};

uploadArea.ondragleave = () => {
  uploadArea.classList.remove("dragover");
};

uploadArea.ondrop = (e) => {
  e.preventDefault();
  uploadArea.classList.remove("dragover");
  const file = e.dataTransfer.files[0];
  if (file) handleFile(file);
};

fileInput.onchange = (e) => {
  const file = e.target.files[0];
  if (file) handleFile(file);
};

async function handleFile(file) {
  // Validate file
  const maxSize = 5 * 1024 * 1024; // 5MB
  if (file.size > maxSize) {
    alert("File too large! Maximum 5MB");
    return;
  }

  const validTypes = [
    'application/pdf',
    'application/msword',
    'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
    'text/plain'
  ];

  if (!validTypes.includes(file.type)) {
    alert("Invalid file type! Use PDF, DOC, DOCX, or TXT");
    return;
  }

  // Show file info
  fileName.textContent = `üìÑ ${file.name}`;
  fileSize.textContent = `${(file.size / 1024).toFixed(1)} KB`;
  fileInfo.classList.add("show");
  
  setStatus("Processing CV", "Extracting text from document...", "thinking");

  try {
    // Extract text based on file type
    if (file.type === 'application/pdf') {
      cvContent = await extractPDF(file);
    } else if (file.type.includes('word')) {
      cvContent = await extractDOCX(file);
    } else {
      cvContent = await extractText(file);
    }

    if (!cvContent || cvContent.length < 50) {
      throw new Error("Could not extract meaningful text from CV");
    }

    // Analyze CV with AI
    await analyzeCVWithAI();
    
    setStatus("CV Ready", "Review analysis below and start interview", "");
    startBtn.disabled = false;

  } catch (error) {
    console.error("CV processing error:", error);
    alert("Error processing CV: " + error.message);
    setStatus("Error", "Please try another file", "");
  }
}

async function extractPDF(file) {
  const arrayBuffer = await file.arrayBuffer();
  const pdf = await pdfjsLib.getDocument({ data: arrayBuffer }).promise;
  let text = "";
  
  for (let i = 1; i <= pdf.numPages; i++) {
    const page = await pdf.getPage(i);
    const content = await page.getTextContent();
    const pageText = content.items.map(item => item.str).join(" ");
    text += pageText + "\n\n";
  }
  
  return text.trim();
}

async function extractDOCX(file) {
  const arrayBuffer = await file.arrayBuffer();
  const result = await mammoth.extractRawText({ arrayBuffer });
  return result.value.trim();
}

async function extractText(file) {
  return await file.text();
}

async function analyzeCVWithAI() {
  setStatus("Analyzing CV", "AI is reviewing your experience...", "thinking");
  
  const analysisPrompt = `You are an expert recruiter. Analyze this CV and provide:
1. Key skills and expertise (3-5 points)
2. Years of experience
3. Notable achievements or projects
4. Areas to explore in interview

CV Content:
${cvContent.substring(0, 3000)}

Respond in JSON format:
{
  "summary": "Brief 2-sentence summary",
  "skills": ["skill1", "skill2", ...],
  "experience_years": "X years",
  "key_points": ["point1", "point2", ...],
  "interview_focus": ["area1", "area2", ...]
}`;

  try {
    const response = await fetch(API, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({
        messages: [
          { role: "user", content: analysisPrompt }
        ]
      })
    });

    const data = await response.json();
    const reply = data.reply;
    
    // Try to parse JSON from reply
    const jsonMatch = reply.match(/\{[\s\S]*\}/);
    if (jsonMatch) {
      const analysis = JSON.parse(jsonMatch[0]);
      cvAnalysis = analysis;
      
      // Display summary
      cvSummaryContent.innerHTML = `
        <strong>Summary:</strong> ${analysis.summary}<br><br>
        <strong>Skills:</strong> ${analysis.skills.join(", ")}<br>
        <strong>Experience:</strong> ${analysis.experience_years}<br>
        <strong>Interview Focus:</strong> ${analysis.interview_focus.join(", ")}
      `;
      cvSummary.classList.add("show");
    } else {
      // Fallback
      cvAnalysis = { summary: reply };
      cvSummaryContent.textContent = reply;
      cvSummary.classList.add("show");
    }
    
  } catch (error) {
    console.error("CV analysis error:", error);
    cvAnalysis = { summary: "CV uploaded successfully" };
  }
}

/* ================= SKIP CV ================= */
skipCvBtn.onclick = () => {
  cvContent = "";
  cvAnalysis = "";
  uploadSection.style.display = "none";
  skipCvBtn.style.display = "none";
  startBtn.disabled = false;
  setStatus("Ready", "General interview mode - Click to start", "");
};

/* ================= UI UPDATES ================= */
function setStatus(main, sub, state) {
  statusText.textContent = main;
  statusSubtext.textContent = sub;
  
  voiceCircle.className = "voice-circle";
  waves.forEach(w => w.classList.remove("active"));
  
  if (state === "listening") {
    voiceCircle.classList.add("listening");
    voiceCircle.textContent = "üëÇ";
    waves.forEach(w => w.classList.add("active"));
  } else if (state === "speaking") {
    voiceCircle.classList.add("speaking");
    voiceCircle.textContent = "üó£Ô∏è";
  } else if (state === "thinking") {
    voiceCircle.classList.add("thinking");
    voiceCircle.textContent = "ü§î";
  } else {
    voiceCircle.textContent = "üé§";
  }
}

function addMessage(type, text) {
  conversation.classList.add("show");
  const msg = document.createElement("div");
  msg.className = `message ${type}`;
  msg.innerHTML = `
    <div class="label">${type === "user" ? "You" : type === "system" ? "System" : "AI Interviewer"}</div>
    <div class="text">${text}</div>
  `;
  conversation.insertBefore(msg, conversation.firstChild);
}

/* ================= AUDIO ================= */
function unlockAudio() {
  if (audioUnlocked) return;
  audioUnlocked = true;
  const u = new SpeechSynthesisUtterance(" ");
  speechSynthesis.speak(u);
}

function speakAI(text) {
  return new Promise((resolve) => {
    unlockAudio();
    speechSynthesis.cancel();
    
    isSpeaking = true;
    setStatus("AI Speaking", text.substring(0, 60) + "...", "speaking");

    const utterance = new SpeechSynthesisUtterance(text);
    utterance.lang = "en-US";
    utterance.rate = 1.0;

    const voices = speechSynthesis.getVoices();
    const voice = voices.find(v => v.lang.startsWith("en") && v.name.includes("Female")) || voices.find(v => v.lang.startsWith("en"));
    utterance.voice = voice;

    utterance.onend = () => {
      isSpeaking = false;
      if (interviewActive) {
        setTimeout(() => startListening(), 500);
      }
      resolve();
    };

    utterance.onerror = () => {
      isSpeaking = false;
      resolve();
    };

    speechSynthesis.speak(utterance);
  });
}

/* ================= SPEECH RECOGNITION ================= */
function initRecognition() {
  if (!("webkitSpeechRecognition" in window)) {
    alert("‚ùå Voice not supported. Use Chrome or Edge.");
    return false;
  }

  recognition = new webkitSpeechRecognition();
  recognition.lang = "en-US";
  recognition.continuous = true;
  recognition.interimResults = true;

  let finalTranscript = "";

  recognition.onresult = (event) => {
    let interimTranscript = "";
    
    for (let i = event.resultIndex; i < event.results.length; i++) {
      const transcript = event.results[i][0].transcript;
      
      if (event.results[i].isFinal) {
        finalTranscript += transcript + " ";
        
        clearTimeout(silenceTimer);
        silenceTimer = setTimeout(() => {
          if (finalTranscript.trim()) {
            sendUserMessage(finalTranscript.trim());
            finalTranscript = "";
          }
        }, silenceTimeout);
      } else {
        interimTranscript += transcript;
      }
    }

    const currentText = (finalTranscript + interimTranscript).trim();
    if (currentText) {
      setStatus("Listening...", `"${currentText}"`, "listening");
    }
  };

  recognition.onstart = () => {
    isListening = true;
    setStatus("Listening", "Speak naturally...", "listening");
  };

  recognition.onend = () => {
    isListening = false;
    if (interviewActive && !isProcessing && !isSpeaking) {
      setTimeout(() => recognition.start(), 300);
    }
  };

  recognition.onerror = (event) => {
    if (event.error === "no-speech" && interviewActive && !isProcessing && !isSpeaking) {
      setTimeout(() => recognition.start(), 300);
    }
  };

  return true;
}

function startListening() {
  if (isListening || isProcessing || isSpeaking) return;
  try {
    recognition.start();
  } catch (e) {
    console.log("Already listening");
  }
}

/* ================= SEND MESSAGE ================= */
async function sendUserMessage(text) {
  if (!text.trim() || isProcessing) return;
  
  recognition.stop();
  isProcessing = true;
  clearTimeout(silenceTimer);

  addMessage("user", text);
  setStatus("Processing", "AI is thinking...", "thinking");

  try {
    // Build contextual prompt
    let systemPrompt = `You are an expert job interviewer conducting a professional interview. 

Interview Style:
- Ask ONE clear, focused question at a time
- Keep questions concise (1-2 sentences max)
- Listen carefully and ask natural follow-up questions based on the candidate's answers
- Show genuine interest and engagement
- Probe deeper into interesting points they mention
- Mix behavioral, technical, and situational questions
- Be conversational and human-like, not robotic`;

    if (cvContent) {
      systemPrompt += `\n\nCandidate's CV Summary:
${JSON.stringify(cvAnalysis, null, 2)}

Key areas to explore based on CV:
${cvAnalysis.interview_focus ? cvAnalysis.interview_focus.join(", ") : "General experience"}

Ask questions that relate to their specific experience and achievements mentioned in their CV.`;
    }

    const response = await fetch(API, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({
        messages: [
          { role: "system", content: systemPrompt },
          ...history,
          { role: "user", content: text }
        ]
      })
    });

    const data = await response.json();
    const aiReply = data.reply;
    
    history.push({ role: "user", content: text });
    history.push({ role: "assistant", content: aiReply });

    addMessage("ai", aiReply);
    await speakAI(aiReply);

  } catch (error) {
    console.error("API Error:", error);
    const errorMsg = "Interesting. Can you tell me more about that?";
    addMessage("ai", errorMsg);
    await speakAI(errorMsg);
  } finally {
    isProcessing = false;
  }
}

/* ================= START INTERVIEW ================= */
startBtn.onclick = async () => {
  unlockAudio();
  
  if (!initRecognition()) return;

  interviewActive = true;
  startBtn.style.display = "none";
  stopBtn.style.display = "block";
  uploadSection.style.display = "none";
  skipCvBtn.style.display = "none";
  voiceContainer.classList.add("show");
  
  setStatus("Starting Interview", "Please wait...", "thinking");
  isProcessing = true;

  try {
    let systemPrompt = `You are an expert job interviewer. Start the interview with a warm greeting and then ask your FIRST question based on their CV.

Keep your opening brief (2-3 sentences max) and immediately ask ONE specific question.`;

    if (cvContent) {
      systemPrompt += `\n\nCV Analysis:\n${JSON.stringify(cvAnalysis, null, 2)}\n\nStart by asking about something specific from their CV.`;
    } else {
      systemPrompt += `\n\nNo CV provided. Start with: "What position are you interested in?"`;
    }

    const response = await fetch(API, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({
        messages: [
          { role: "system", content: systemPrompt },
          { role: "user", content: "Begin the interview." }
        ]
      })
    });

    const data = await response.json();
    const greeting = data.reply;
    
    history = [];
    history.push({ role: "assistant", content: greeting });
    
    addMessage("ai", greeting);
    await speakAI(greeting);

  } catch (error) {
    console.error("Start error:", error);
    const msg = cvContent 
      ? `Hello! I've reviewed your CV and I'm impressed. Let me start by asking: ${cvAnalysis.interview_focus ? cvAnalysis.interview_focus[0] : "Tell me about your experience."}`
      : "Hello! Let's begin. What position are you applying for?";
    
    addMessage("ai", msg);
    await speakAI(msg);
  } finally {
    isProcessing = false;
  }
};

/* ================= STOP INTERVIEW ================= */
stopBtn.onclick = () => {
  interviewActive = false;
  if (recognition) recognition.stop();
  speechSynthesis.cancel();
  clearTimeout(silenceTimer);
  
  setStatus("Interview Ended", "Thank you for your time!", "");
  
  const summary = `Thank you for interviewing! We'll review your responses and get back to you soon.`;
  addMessage("system", summary);
  
  stopBtn.style.display = "none";
};

speechSynthesis.onvoiceschanged = () => speechSynthesis.getVoices();
</script>

</body>
</html>
