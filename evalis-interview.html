<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<title>Evalis AI â€“ Voice Interview</title>

<!-- VAD -->
<script src="https://cdn.jsdelivr.net/npm/@ricky0123/vad-web@0.0.7/dist/bundle.standard.js"></script>

<style>
body {
  margin: 0;
  background: #0f172a;
  font-family: system-ui;
  color: #e5e7eb;
  display: flex;
  justify-content: center;
  align-items: center;
  height: 100vh;
}

.card {
  background: #020617;
  padding: 26px;
  width: 94%;
  max-width: 420px;
  border-radius: 16px;
  text-align: center;
  box-shadow: 0 0 40px rgba(0,0,0,.6);
}

h3 { margin: 0 0 6px; }

#question {
  font-size: 18px;
  margin: 18px 0;
  min-height: 64px;
}

#status {
  font-size: 14px;
  color: #22c55e;
  min-height: 22px;
}

button {
  width: 100%;
  padding: 14px;
  border-radius: 12px;
  border: none;
  background: #2563eb;
  color: white;
  font-size: 16px;
  margin-top: 18px;
}

/* Mic animation */
.mic {
  width: 16px;
  height: 16px;
  background: #22c55e;
  border-radius: 50%;
  margin: 14px auto 0;
  opacity: 0;
}

.mic.active {
  animation: pulse 1.2s infinite;
  opacity: 1;
}

@keyframes pulse {
  0% { transform: scale(1); opacity: 0.7; }
  50% { transform: scale(1.6); opacity: 1; }
  100% { transform: scale(1); opacity: 0.7; }
}
</style>
</head>

<body>
<div class="card">
  <h3>Evalis AI Interview</h3>
  <div id="question">Ready to begin</div>
  <div id="status">Tap Start</div>
  <div id="mic" class="mic"></div>
  <button id="startBtn">Start Interview</button>
</div>

<script>
/* ================= STATE ================= */
let audioContext;
let myvad;
let isAISpeaking = false;
let interviewStarted = false;
let silenceTimer;

/* ================= UI ================= */
const qEl = document.getElementById("question");
const sEl = document.getElementById("status");
const micEl = document.getElementById("mic");

function setStatus(t) { sEl.innerText = t; }

/* ================= SPEECH SYNTH ================= */
const synth = window.speechSynthesis;

function speak(text) {
  synth.cancel();
  const u = new SpeechSynthesisUtterance(text);
  u.lang = "en-US";
  u.rate = 0.95;

  u.onstart = () => {
    isAISpeaking = true;
    micEl.classList.remove("active");
    setStatus("AI speakingâ€¦");
  };

  u.onend = () => {
    isAISpeaking = false;
    setStatus("Listeningâ€¦");
  };

  qEl.innerText = text;
  synth.speak(u);
}

/* ================= SPEECH RECOGNITION ================= */
const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
recognition.lang = "en-US";
recognition.interimResults = false;
recognition.continuous = false;

recognition.onresult = (e) => {
  const answer = e.results[0][0].transcript;
  processAnswer(answer);
};

/* ================= INTERVIEW LOGIC ================= */
let depth = 0;

function processAnswer(answer) {
  clearTimeout(silenceTimer);
  setStatus("Thinkingâ€¦");

  let next;

  const words = answer.split(" ").length;

  if (words < 15) {
    next = "Can you explain that in more detail?";
  } else if (!/i | my | me /.test(answer.toLowerCase())) {
    next = "What was your personal role there?";
  } else if (!/result|impact|outcome|improve|increase/.test(answer.toLowerCase())) {
    next = "What was the outcome of that?";
  } else if (depth < 1) {
    depth++;
    next = "What challenges did you face?";
  } else {
    depth = 0;
    next = "Tell me about a project you are proud of.";
  }

  speak(next);
}

/* ================= VAD ================= */
async function initVAD() {
  myvad = await vad.MicVAD.new({
    audioContext,
    onSpeechStart: () => {
      clearTimeout(silenceTimer);
      micEl.classList.add("active");

      if (isAISpeaking) synth.cancel();
      setStatus("Listeningâ€¦");
    },
    onSpeechEnd: () => {
      micEl.classList.remove("active");
      recognition.start();

      silenceTimer = setTimeout(() => {
        setStatus("Waiting for youâ€¦");
      }, 4000);
    }
  });

  myvad.start();
}

/* ================= START ================= */
document.getElementById("startBtn").onclick = async () => {
  if (interviewStarted) return;
  interviewStarted = true;

  try {
    // ðŸ”´ REQUIRED FOR MOBILE
    audioContext = new (window.AudioContext || window.webkitAudioContext)();
    await audioContext.resume();

    setStatus("Initializing microphoneâ€¦");
    await initVAD();

    speak("Tell me about yourself.");
    document.getElementById("startBtn").style.display = "none";
  } catch (e) {
    console.error(e);
    setStatus("Microphone permission required");
  }
};
</script>
</body>
</html>
