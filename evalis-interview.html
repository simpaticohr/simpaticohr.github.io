<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Evalis AI - Elite Live Interview</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/pdf.js/3.11.174/pdf.min.js"></script>
    <style>
        :root { --primary: #6366f1; --bg: #020617; }
        body { margin: 0; background: var(--bg); color: white; font-family: system-ui, sans-serif; display: flex; align-items: center; justify-content: center; min-height: 100vh; overflow-x: hidden; }
        .card { width: 90%; max-width: 440px; background: rgba(255,255,255,0.05); backdrop-filter: blur(15px); border-radius: 24px; padding: 30px; text-align: center; border: 1px solid rgba(255,255,255,0.1); box-shadow: 0 25px 50px rgba(0,0,0,0.5); }
        .wave-box { height: 80px; margin: 15px 0; }
        canvas { width: 100%; height: 60px; filter: drop-shadow(0 0 5px var(--primary)); }
        #timer { font-size: 24px; font-weight: 700; color: var(--primary); margin-bottom: 5px; font-variant-numeric: tabular-nums; }
        #status { font-size: 12px; color: #94a3b8; text-transform: uppercase; letter-spacing: 1px; margin-bottom: 20px; }
        .btn { background: var(--primary); color: white; border: none; padding: 16px; border-radius: 14px; width: 100%; font-weight: bold; cursor: pointer; font-size: 16px; transition: 0.3s; }
        .btn:disabled { opacity: 0.3; }
        #log { margin-top: 20px; max-height: 200px; overflow-y: auto; text-align: left; font-size: 14px; border-top: 1px solid #334155; padding-top: 15px; }
        .report-box { background: rgba(99, 102, 241, 0.1); padding: 20px; border-radius: 15px; text-align: left; line-height: 1.6; border: 1px solid var(--primary); }
    </style>
</head>
<body>

<div class="card">
    <div id="timer">15:00</div>
    <div id="status">Upload Resume to Start</div>
    <div class="wave-box"><canvas id="canvas"></canvas></div>
    
    <input type="file" id="cvInput" accept=".pdf" style="margin-bottom:15px; font-size: 12px;">
    <button id="startBtn" class="btn" disabled>Start Interview</button>
    <button id="endBtn" class="btn" style="display:none; background:#ef4444">End Interview</button>
    
    <div id="log"></div>
</div>

<script>
const API = "https://evalis-ai.simpaticohrconsultancy.workers.dev";
const pdfjsLib = window['pdfjs-dist/build/pdf'];
pdfjsLib.GlobalWorkerOptions.workerSrc = "https://cdnjs.cloudflare.com/ajax/libs/pdf.js/3.11.174/pdf.worker.min.js";

let cvText = "", history = [], interviewActive = false, isAISpeaking = false, recognition;
let audioCtx, analyser, dataArray, canvasCtx, timerInterval, timeLeft = 15 * 60;

/* 1. PDF LOADING */
document.getElementById("cvInput").onchange = async e => {
    const file = e.target.files[0];
    if (!file) return;
    const pdf = await pdfjsLib.getDocument(await file.arrayBuffer()).promise;
    let text = "";
    for (let i = 1; i <= pdf.numPages; i++) {
        const page = await pdf.getPage(i);
        text += (await page.getTextContent()).items.map(s => s.str).join(" ") + " ";
    }
    cvText = text;
    document.getElementById("startBtn").disabled = false;
    document.getElementById("status").textContent = "Resume Ready";
};

/* 2. WAVEFORM */
function initWave(stream) {
    if (!audioCtx) audioCtx = new (window.AudioContext || window.webkitAudioContext)();
    if (audioCtx.state === 'suspended') audioCtx.resume();
    analyser = audioCtx.createAnalyser();
    audioCtx.createMediaStreamSource(stream).connect(analyser);
    dataArray = new Uint8Array(analyser.frequencyBinCount);
    canvasCtx = document.getElementById("canvas").getContext("2d");
    const draw = () => {
        if (!interviewActive) return;
        requestAnimationFrame(draw);
        analyser.getByteFrequencyData(dataArray);
        canvasCtx.clearRect(0, 0, 400, 60);
        canvasCtx.fillStyle = "#6366f1";
        for (let i = 0; i < 80; i++) {
            let h = dataArray[i] / 2.5;
            canvasCtx.fillRect(i * 5, 30 - h/2, 3, h);
        }
    };
    draw();
}

/* 3. SPEECH (ANDROID FIX) */
function speak(text) {
    return new Promise((resolve) => {
        const voices = window.speechSynthesis.getVoices();
        window.speechSynthesis.cancel();
        const u = new SpeechSynthesisUtterance(text);
        u.lang = "en-US";
        if (voices.length > 0) u.voice = voices.find(v => v.lang.includes('en')) || voices[0];

        u.onstart = () => { isAISpeaking = true; if(recognition) recognition.stop(); };
        u.onend = () => { 
            isAISpeaking = false; 
            if(interviewActive) setTimeout(() => { if(!isAISpeaking && recognition) recognition.start(); }, 500);
            resolve();
        };
        u.onerror = () => { isAISpeaking = false; resolve(); };

        window.speechSynthesis.speak(u);
        const d = document.createElement("div");
        d.innerHTML = `<p style="color:#a5b4fc; margin:5px 0;"><b>AI:</b> ${text}</p>`;
        document.getElementById("log").prepend(d);
    });
}

function initRecognition() {
    const SR = window.SpeechRecognition || window.webkitSpeechRecognition;
    if (!SR) return;
    recognition = new SR();
    recognition.continuous = true;
    recognition.onresult = async e => {
        const transcript = e.results[e.results.length - 1][0].transcript.trim();
        if (isAISpeaking || !transcript) return;
        
        document.getElementById("status").textContent = "Thinking...";
        const fd = new FormData();
        fd.append("mode", "interview");
        fd.append("history", JSON.stringify(history));
        fd.append("text", transcript);
        fd.append("cvText", cvText);

        const res = await fetch(API, { method: "POST", body: fd });
        const data = await res.json();
        history = data.history;
        await speak(data.reply);
        document.getElementById("status").textContent = "Listening...";
    };
}

/* 4. START SESSION */
document.getElementById("startBtn").onclick = async () => {
    if (!audioCtx) audioCtx = new (window.AudioContext || window.webkitAudioContext)();
    await audioCtx.resume();
    window.speechSynthesis.speak(new SpeechSynthesisUtterance("")); // Vital for Android

    interviewActive = true;
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    initWave(stream);
    initRecognition();
    
    document.getElementById("cvInput").style.display = "none";
    document.getElementById("startBtn").style.display = "none";
    document.getElementById("endBtn").style.display = "block";
    
    speak("Please wait while I read your resume..."); // Holds the audio channel open

    const fd = new FormData();
    fd.append("mode", "start");
    fd.append("cvText", cvText);
    const res = await fetch(API, { method: "POST", body: fd });
    const data = await res.json();
    history = data.history;
    speak(data.reply);
};

document.getElementById("endBtn").onclick = async () => {
    interviewActive = false;
    if(recognition) recognition.stop();
    window.speechSynthesis.cancel();
    document.getElementById("status").textContent = "Generating Report...";
    
    const fd = new FormData();
    fd.append("mode", "score");
    fd.append("history", JSON.stringify(history));
    const res = await fetch(API, { method: "POST", body: fd });
    const data = await res.json();
    
    document.body.innerHTML = `
        <div class="card" style="max-width:600px">
            <h2 style="color:var(--primary)">Interview Complete</h2>
            <div class="report-box" style="white-space:pre-wrap">${data.reply}</div>
            <button onclick="location.reload()" class="btn" style="margin-top:20px">New Interview</button>
        </div>`;
};
</script>
</body>
</html>
