<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />
<title>Evalis AI | Intelligent Interview</title>

<script src="https://cdnjs.cloudflare.com/ajax/libs/pdf.js/3.11.174/pdf.min.js"></script>
<link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600&display=swap" rel="stylesheet">

<style>
:root{
--bg:#05050a;--surface:#0f1016;--primary:#6366f1;--accent:#a855f7;
--text:#f8fafc;--text-dim:#64748b;--danger:#ef4444;
}
body{
margin:0;background:var(--bg);color:var(--text);font-family:Inter;
display:flex;flex-direction:column;align-items:center;justify-content:center;
min-height:100vh;overflow:hidden;
}
.orb-wrapper{position:relative;width:280px;height:280px;margin-bottom:24px}
.orb{width:130px;height:130px;border-radius:50%;background:linear-gradient(135deg,var(--primary),var(--accent));
box-shadow:0 0 60px rgba(99,102,241,.4);transition:.3s}
.orb.idle{opacity:.6;animation:breathe 4s infinite}
.orb.listening{background:linear-gradient(135deg,#34d399,#10b981)}
.orb.speaking{animation:pulse 1.2s infinite}
.orb.thinking{background:#f59e0b;animation:spin 2s linear infinite;border-radius:40%}
.interface{text-align:center;width:85%;max-width:420px}
#timer{font-family:monospace;color:var(--text-dim);margin-bottom:10px}
.transcript{min-height:40px;opacity:.6;transition:.3s}
.transcript.fade{opacity:0}
.btn{padding:14px;border-radius:12px;border:1px solid rgba(255,255,255,.1);
background:rgba(255,255,255,.05);color:var(--text);cursor:pointer}
.btn-primary{background:#fff;color:#000}
.btn-danger{border-color:#ef4444;color:#ef4444}
.hidden{display:none}
@keyframes breathe{50%{transform:scale(1.05)}}
@keyframes pulse{50%{transform:scale(1.12)}}
@keyframes spin{100%{transform:rotate(360deg)}}
</style>
</head>

<body>

<div class="orb-wrapper">
<div id="orb" class="orb idle"></div>
</div>

<div class="interface">
<h3 id="status">AI INTERVIEWER</h3>
<div id="timer">15:00</div>
<div id="transcript" class="transcript">Upload resume to begin</div>

<input type="file" id="cvInput" accept=".pdf" />
<br><br>
<button id="startBtn" class="btn btn-primary hidden">Start Interview</button>
<button id="endBtn" class="btn btn-danger hidden">End Interview</button>
</div>

<script>
const API_URL="https://evalis-ai.simpaticohrconsultancy.workers.dev";

const state={
active:false,aiSpeaking:false,history:[],cvText:"",
timeLeft:900,timer:null,recognition:null,synth:window.speechSynthesis,
silence:null
};

const orb=document.getElementById("orb");
const status=document.getElementById("status");
const transcript=document.getElementById("transcript");
const timerEl=document.getElementById("timer");

function setOrb(mode){
orb.className="orb "+mode;
status.textContent=
mode==="listening"?"Listening…":
mode==="speaking"?"AI Speaking":
mode==="thinking"?"Processing…":"AI INTERVIEWER";
}

function startTimer(){
state.timer=setInterval(()=>{
if(!state.active)return;
if(state.timeLeft<=0){endSession();return;}
state.timeLeft--;
const m=Math.floor(state.timeLeft/60);
const s=state.timeLeft%60;
timerEl.textContent=`${m}:${s<10?"0"+s:s}`;
},1000);
}

function hideTranscript(){
setTimeout(()=>{transcript.textContent="";transcript.classList.add("fade")},1200);
}

function speak(text){
state.synth.cancel();
const u=new SpeechSynthesisUtterance(text.replace(/[*#]/g,""));
u.rate=1.1;
u.onstart=()=>{state.aiSpeaking=true;setOrb("speaking");transcript.classList.add("fade")};
u.onend=()=>{state.aiSpeaking=false;setOrb("listening")};
state.synth.speak(u);
}

async function sendToAI(text){
setOrb("thinking");
state.history.push({role:"user",content:text});
hideTranscript();

const fd=new FormData();
fd.append("mode","interview");
fd.append("history",JSON.stringify(state.history));
fd.append("text",text);
fd.append("cvText",state.cvText);

try{
const r=await fetch(API_URL,{method:"POST",body:fd});
const d=await r.json();
state.history=d.history;
speak(d.reply);
}catch{ speak("Could you repeat that?") }
}

function initSpeech(){
const R=window.SpeechRecognition||window.webkitSpeechRecognition;
const rec=new R();
rec.continuous=true;
rec.interimResults=true;
rec.lang="en-US";

rec.onresult=e=>{
let final="",interim="";
for(let i=e.resultIndex;i<e.results.length;i++){
if(e.results[i].isFinal)final+=e.results[i][0].transcript;
else interim+=e.results[i][0].transcript;
}
if(state.aiSpeaking && (interim.length>5||final)){
state.synth.cancel();
state.aiSpeaking=false;
setOrb("listening");
}
if(interim){transcript.textContent=interim;transcript.classList.remove("fade")}
if(final){
clearTimeout(state.silence);
state.silence=setTimeout(()=>sendToAI(final),800);
}
};

rec.onend=()=>{if(state.active)rec.start()};
rec.start();
return rec;
}

async function startSession(){
state.active=true;
document.getElementById("startBtn").classList.add("hidden");
document.getElementById("endBtn").classList.remove("hidden");
state.recognition=initSpeech();
startTimer();

try{await navigator.wakeLock?.request("screen")}catch{}

const fd=new FormData();
fd.append("mode","start");
fd.append("cvText",state.cvText);
const r=await fetch(API_URL,{method:"POST",body:fd});
const d=await r.json();
state.history=d.history;
speak(d.reply);
}

function endSession(){
state.active=false;
clearInterval(state.timer);
state.synth.cancel();
state.recognition?.stop();
location.reload();
}

document.getElementById("cvInput").onchange=async e=>{
const f=e.target.files[0];
if(!f)return;
const b=await f.arrayBuffer();
const pdf=await pdfjsLib.getDocument(b).promise;
let t="";
for(let i=1;i<=pdf.numPages;i++){
const p=await pdf.getPage(i);
const c=await p.getTextContent();
t+=c.items.map(x=>x.str).join(" ");
}
state.cvText=t;
document.getElementById("startBtn").classList.remove("hidden");
transcript.textContent="Resume loaded ✓";
};

document.getElementById("startBtn").onclick=startSession;
document.getElementById("endBtn").onclick=endSession;
</script>
</body>
</html>
