<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Evalis AI â€“ Live Interview</title>

<script src="https://cdnjs.cloudflare.com/ajax/libs/pdf.js/3.11.174/pdf.min.js"></script>

<style>
:root { --primary:#6366f1; --bg:#020617; }
body {
  margin:0;
  background:var(--bg);
  color:white;
  font-family:system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif;
  display:flex;
  align-items:center;
  justify-content:center;
  min-height:100vh;
}
.card {
  width:90%;
  max-width:440px;
  background:rgba(255,255,255,.05);
  border-radius:22px;
  padding:28px;
  text-align:center;
  border:1px solid rgba(255,255,255,.12);
}
button {
  background:var(--primary);
  color:white;
  border:none;
  padding:14px;
  border-radius:14px;
  width:100%;
  font-size:16px;
  font-weight:700;
  margin-top:10px;
}
button:disabled { opacity:.35; }
#log {
  margin-top:20px;
  max-height:220px;
  overflow-y:auto;
  text-align:left;
  font-size:14px;
}
.msg { margin-bottom: 8px; }
.msg b { color: var(--primary); }
small { color:#94a3b8; }
</style>
</head>

<body>

<div class="card">
  <h2 id="timer">15:00</h2>
  <p id="status">Upload resume to begin</p>

  <input type="file" id="cvInput" accept="application/pdf">
  <small id="uploadStatus"></small>

  <button id="startBtn" disabled>Start Interview</button>
  <button id="endBtn" style="display:none;background:#ef4444">End Interview</button>

  <div id="log"></div>
</div>

<script>
/* ======================================================
   CONFIG
====================================================== */
const API = "https://evalis-ai.simpaticohrconsultancy.workers.dev";
pdfjsLib.GlobalWorkerOptions.workerSrc =
  "https://cdnjs.cloudflare.com/ajax/libs/pdf.js/3.11.174/pdf.worker.min.js";

/* ======================================================
   STATE
====================================================== */
let cvText = "";
let history = [];
let interviewActive = false;
let recognition = null;
let isAISpeaking = false;

/* ======================================================
   UI
====================================================== */
function addMsg(who, text) {
  const div = document.createElement("div");
  div.className = "msg";
  div.innerHTML = `<b>${who}:</b> ${text}`;
  document.getElementById("log").prepend(div);
}

/* ======================================================
   TEXT TO SPEECH (ANDROID + SAFE FALLBACK)
====================================================== */
function speak(text) {
  console.log("SPEAK:", text);

  isAISpeaking = true;
  if (recognition) recognition.stop();

  // 1ï¸âƒ£ ANDROID NATIVE TTS
  if (typeof Android !== "undefined" && Android.speak) {
    Android.speak(text);

    // SAFETY RELEASE (Android TTS has no JS callbacks)
    setTimeout(() => {
      isAISpeaking = false;
      if (interviewActive && recognition) {
        try { recognition.start(); } catch(e) {}
      }
    }, Math.min(4000 + text.length * 30, 8000));

    return;
  }

  // 2ï¸âƒ£ BROWSER FALLBACK
  if (!window.speechSynthesis) {
    isAISpeaking = false;
    return;
  }

  speechSynthesis.cancel();
  const u = new SpeechSynthesisUtterance(text);
  u.lang = "en-US";

  u.onend = () => {
    isAISpeaking = false;
    if (interviewActive && recognition) {
      try { recognition.start(); } catch(e) {}
    }
  };

  speechSynthesis.speak(u);
}

/* ======================================================
   SPEECH RECOGNITION (BROWSER ONLY)
====================================================== */
function initRecognition() {
  if (typeof Android !== "undefined") return;

  const SR = window.SpeechRecognition || window.webkitSpeechRecognition;
  if (!SR) return;

  recognition = new SR();
  recognition.lang = "en-US";
  recognition.interimResults = false;

  recognition.onresult = e => {
    if (isAISpeaking) return;
    const text = e.results[0][0].transcript.trim();
    if (text) sendUserText(text);
  };

  recognition.onend = () => {
    if (interviewActive && !isAISpeaking) {
      try { recognition.start(); } catch(e) {}
    }
  };
}

/* ======================================================
   FILE UPLOAD
====================================================== */
document.getElementById("cvInput").onchange = async e => {
  const file = e.target.files[0];
  if (!file) return;

  document.getElementById("uploadStatus").textContent = "Reading resumeâ€¦";
  document.getElementById("startBtn").disabled = true;

  try {
    const buffer = await file.arrayBuffer();
    const pdf = await pdfjsLib.getDocument({ data: buffer }).promise;

    let text = "";
    for (let i = 1; i <= pdf.numPages; i++) {
      const page = await pdf.getPage(i);
      const c = await page.getTextContent();
      text += c.items.map(it => it.str).join(" ") + " ";
    }

    if (text.length < 50) throw "Resume too short";

    cvText = text;
    document.getElementById("uploadStatus").textContent = "Resume ready âœ“";
    document.getElementById("startBtn").disabled = false;

  } catch {
    document.getElementById("uploadStatus").textContent = "Error reading PDF";
  }
};

/* ======================================================
   START INTERVIEW
====================================================== */
document.getElementById("startBtn").onclick = async () => {

  // ðŸ”“ Unlock audio (mobile requirement)
  if (window.speechSynthesis) {
    speechSynthesis.speak(new SpeechSynthesisUtterance(""));
  }

  interviewActive = true;
  document.getElementById("startBtn").style.display = "none";
  document.getElementById("endBtn").style.display = "block";
  document.getElementById("status").textContent = "Connecting to AIâ€¦";

  initRecognition();

  const fd = new FormData();
  fd.append("mode", "start");
  fd.append("cvText", cvText);

  try {
    const r = await fetch(API, { method: "POST", body: fd });
    const d = await r.json();

    history = d.history || [];
    addMsg("AI", d.reply);
    speak(d.reply);

    document.getElementById("status").textContent = "Listeningâ€¦";

  } catch {
    alert("Failed to start interview");
  }
};

/* ======================================================
   SEND USER ANSWER
====================================================== */
async function sendUserText(text) {
  addMsg("You", text);
  document.getElementById("status").textContent = "AI is thinkingâ€¦";

  const fd = new FormData();
  fd.append("mode", "interview");
  fd.append("text", text);
  fd.append("history", JSON.stringify(history));
  fd.append("cvText", cvText);

  try {
    const r = await fetch(API, { method: "POST", body: fd });
    const d = await r.json();

    history = d.history || history;
    addMsg("AI", d.reply);
    speak(d.reply);
    document.getElementById("status").textContent = "Listeningâ€¦";

  } catch {
    addMsg("System", "Connection error");
  }
}

/* ======================================================
   ANDROID SPEECH INPUT (Vosk / Native)
====================================================== */
window.receiveVoskText = text => {
  if (interviewActive && text) sendUserText(text);
};

/* ======================================================
   END INTERVIEW
====================================================== */
document.getElementById("endBtn").onclick = async () => {
  interviewActive = false;
  if (recognition) recognition.stop();
  if (window.speechSynthesis) speechSynthesis.cancel();

  document.getElementById("status").textContent = "Generating feedbackâ€¦";

  const fd = new FormData();
  fd.append("mode", "score");
  fd.append("history", JSON.stringify(history));

  try {
    const r = await fetch(API, { method: "POST", body: fd });
    const d = await r.json();

    document.body.innerHTML = `
      <div class="card">
        <h2>Interview Complete</h2>
        <pre style="white-space:pre-wrap">${d.reply}</pre>
        <button onclick="location.reload()">New Interview</button>
      </div>`;
  } catch {
    location.reload();
  }
};
</script>
</body>
</html>
