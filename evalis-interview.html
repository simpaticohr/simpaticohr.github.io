<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Evalis AI – Live Interview</title>

<script src="https://cdnjs.cloudflare.com/ajax/libs/pdf.js/3.11.174/pdf.min.js"></script>

<style>
:root{
  --primary:#6366f1;
  --bg:#020617;
  --card:rgba(255,255,255,.05);
  --border:rgba(255,255,255,.1);
  --ok:#10b981;
  --bad:#ef4444;
  --warn:#f59e0b;
}
*{box-sizing:border-box}
body{
  margin:0;background:var(--bg);color:#fff;
  font-family:system-ui,sans-serif;
  display:flex;justify-content:center;align-items:center;
  min-height:100vh
}
.back-btn{
  position:fixed;top:16px;left:16px;
  background:rgba(255,255,255,.08);
  border:1px solid var(--border);
  padding:10px 16px;border-radius:12px;
  color:#fff;cursor:pointer;z-index:9
}
.container{
  width:95%;max-width:1100px;
  display:grid;grid-template-columns:1fr 1fr;gap:24px
}
@media(max-width:900px){.container{grid-template-columns:1fr}}
.card{
  background:var(--card);
  border:1px solid var(--border);
  border-radius:24px;padding:28px;
  box-shadow:0 25px 50px rgba(0,0,0,.5)
}
h1,h2{margin:0 0 6px}
p{margin:0;color:#94a3b8;font-size:14px}
#timer{
  font-size:42px;font-weight:800;
  color:var(--primary);text-align:center;margin:16px 0
}
#status{text-align:center;font-size:14px;color:#94a3b8;margin-bottom:16px}
input[type=file]{
  width:100%;padding:14px;border-radius:12px;
  background:transparent;color:#fff;
  border:2px dashed var(--border)
}
button{
  width:100%;padding:16px;border-radius:14px;
  font-size:16px;font-weight:700;border:none;cursor:pointer
}
.btn-primary{background:var(--primary);color:#fff}
.btn-danger{background:var(--bad);color:#fff}
button:disabled{opacity:.4}
.log{max-height:460px;overflow-y:auto}
.msg{
  margin-bottom:14px;padding:12px 16px;border-radius:12px
}
.msg.user{background:rgba(103,232,249,.1);border-left:3px solid #67e8f9}
.msg.ai{background:rgba(165,180,252,.1);border-left:3px solid #a5b4fc}
.vosk{
  margin-top:16px;padding:12px 16px;
  border-radius:12px;border:1px solid var(--border);
  background:rgba(255,255,255,.03);font-size:13px
}
.ok{color:var(--ok)}
.bad{color:var(--bad)}
.warn{color:var(--warn)}
.pulse{
  animation:pulse 2s infinite;
}
@keyframes pulse{
  0%{opacity:1}
  50%{opacity:.5}
  100%{opacity:1}
}
</style>
</head>

<body>

<button class="back-btn" id="backBtn">← Back</button>

<div class="container">

<!-- LEFT -->
<div class="card">
  <h1>Evalis AI Interview</h1>
  <p>Vosk powered live interview</p>

  <div id="timer">15:00</div>
  <div id="status">Upload resume to begin</div>

  <input type="file" id="cvInput" accept=".pdf"><br><br>

  <button id="startBtn" class="btn-primary" disabled>Start Interview</button>
  <button id="endBtn" class="btn-danger" style="display:none">End Interview</button>

  <div class="vosk" id="voskBox" style="display:none">
    <div>Vosk Engine: <span id="voskStatus" class="warn">Connecting...</span></div>
    <div>Microphone: <span id="micStatus" class="warn">Waiting...</span></div>
    <div>Mode: <span class="ok">Continuous + Interrupt</span></div>
    <div style="margin-top:8px;font-size:11px;color:#64748b">
      Say "stop" or tap button to interrupt AI
    </div>
  </div>
</div>

<!-- RIGHT -->
<div class="card">
  <h2>Conversation</h2>
  <p>Live transcript</p>
  <div class="log" id="log"></div>
</div>

</div>

<script>
/* ================== CONFIG ================== */
const API = "https://evalis-ai.simpaticohrconsultancy.workers.dev";

/* ================== ELEMENTS ================== */
const cvInput = document.getElementById("cvInput");
const startBtn = document.getElementById("startBtn");
const endBtn = document.getElementById("endBtn");
const status = document.getElementById("status");
const timer = document.getElementById("timer");
const logBox = document.getElementById("log");
const voskBox = document.getElementById("voskBox");
const backBtn = document.getElementById("backBtn");
const voskStatus = document.getElementById("voskStatus");
const micStatus = document.getElementById("micStatus");

/* ================== STATE ================== */
let cvText = "";
let history = [];
let interviewActive = false;
let isAISpeaking = false;
let isProcessing = false;
let timeLeft = 15 * 60;
let timerInt = null;
let currentUtterance = null;
let silenceTimeout = null;

/* ================== PDF ================== */
const pdfjsLib = window['pdfjs-dist/build/pdf'];
pdfjsLib.GlobalWorkerOptions.workerSrc =
  "https://cdnjs.cloudflare.com/ajax/libs/pdf.js/3.11.174/pdf.worker.min.js";

cvInput.addEventListener("change", async (e) => {
  try {
    const file = e.target.files[0];
    if (!file) return;

    status.textContent = "Loading resume...";

    const pdf = await pdfjsLib.getDocument(
      await file.arrayBuffer()
    ).promise;

    let text = "";
    for (let i = 1; i <= pdf.numPages; i++) {
      const page = await pdf.getPage(i);
      const content = await page.getTextContent();
      text += content.items.map(x => x.str).join(" ") + " ";
    }

    cvText = text.trim() || "[Resume uploaded]";
    startBtn.disabled = false;
    status.textContent = "Resume ready ✓ Click Start Interview";

  } catch (err) {
    console.error(err);
    status.textContent = "Resume load failed";
  }
});

/* ================== TIMER ================== */
function startTimer(){
  timerInt = setInterval(()=>{
    timeLeft--;
    timer.textContent =
      `${Math.floor(timeLeft/60)}:${String(timeLeft%60).padStart(2,"0")}`;
    if(timeLeft<=0) finishInterview();
  },1000);
}

/* ================== TTS with INTERRUPTION ================== */
function speak(text){
  return new Promise(res=>{
    // Cancel any current speech
    speechSynthesis.cancel();
    
    isAISpeaking = true;
    status.textContent = "AI is speaking... (Say 'stop' to interrupt)";
    status.className = "pulse";
    
    const u = new SpeechSynthesisUtterance(text);
    currentUtterance = u;
    u.rate = .95;
    u.pitch = 1;
    
    u.onend = () => { 
      isAISpeaking = false;
      currentUtterance = null;
      status.className = "";
      if(interviewActive) {
        status.textContent = "Listening...";
        // Notify Android to resume/start listening
        if(window.Android && window.Android.resumeListening){
          window.Android.resumeListening();
        }
      }
      res(); 
    };
    
    u.onerror = (e) => {
      console.error("TTS Error:", e);
      isAISpeaking = false;
      currentUtterance = null;
      status.className = "";
      if(interviewActive) {
        status.textContent = "Listening...";
        if(window.Android && window.Android.resumeListening){
          window.Android.resumeListening();
        }
      }
      res();
    };
    
    addMsg("ai", text);
    speechSynthesis.speak(u);
  });
}

/* Force stop TTS for interruption */
function stopSpeaking(){
  if(isAISpeaking){
    speechSynthesis.cancel();
    isAISpeaking = false;
    currentUtterance = null;
    status.className = "";
    status.textContent = "Interrupted. Listening...";
    addMsg("system", "[Interrupted by user]");
    
    // Notify Android that interruption happened
    if(window.Android && window.Android.onInterrupted){
      window.Android.onInterrupted();
    }
    return true;
  }
  return false;
}

/* ================== VOSK BRIDGE (Called from Android) ================== */

/**
 * Called by Android Vosk when speech is recognized
 * This is the main entry point from native Vosk
 */
window.receiveVoskText = (text) => {
  console.log("Vosk received:", text);
  
  if(!interviewActive) return;
  
  // Interrupt if user speaks while AI is talking
  if(isAISpeaking){
    const wasInterrupted = stopSpeaking();
    // Small delay to let interruption settle, then process
    setTimeout(() => {
      processUser(text, true);
    }, wasInterrupted ? 300 : 0);
    return;
  }
  
  if(isProcessing) return;
  if(!text || text.length < 2) return;
  
  processUser(text, false);
};

/**
 * Called by Android when Vosk is ready
 */
window.onVoskReady = () => {
  console.log("Vosk ready");
  voskStatus.textContent = "Active";
  voskStatus.className = "ok";
  micStatus.textContent = "Listening";
  micStatus.className = "ok pulse";
};

/**
 * Called by Android when Vosk error occurs
 */
window.onVoskError = (error) => {
  console.error("Vosk error:", error);
  voskStatus.textContent = "Error: " + error;
  voskStatus.className = "bad";
  micStatus.textContent = "Disconnected";
  micStatus.className = "bad";
  status.textContent = "Speech recognition error. Please restart.";
};

/**
 * Called by Android when microphone state changes
 */
window.onMicStateChange = (state) => {
  // state: 'listening', 'processing', 'error'
  if(state === 'listening'){
    micStatus.textContent = "Listening";
    micStatus.className = "ok pulse";
  } else if(state === 'processing'){
    micStatus.textContent = "Hearing...";
    micStatus.className = "warn";
  }
};

/* ================== USER INPUT ================== */
async function processUser(text, wasInterrupted){
  isProcessing = true;
  status.textContent = "Thinking...";
  micStatus.textContent = "Processing";
  micStatus.className = "warn";
  
  // Pause Vosk listening while processing (Android should pause)
  if(window.Android && window.Android.pauseListening){
    window.Android.pauseListening();
  }
  
  addMsg("user", text + (wasInterrupted ? " [interrupted]" : ""));

  try{
    const fd = new FormData();
    fd.append("mode","interview");
    fd.append("history",JSON.stringify(history));
    fd.append("text",text);
    fd.append("cvText",cvText);
    fd.append("interrupted", wasInterrupted ? "true" : "false");

    const r = await fetch(API,{method:"POST",body:fd});
    const d = await r.json();
    history = d.history || history;

    if(d.reply) await speak(d.reply);
    else await speak("Can you explain that further?");
  }catch(err){
    console.error(err);
    await speak("I didn't catch that. Could you repeat?");
  }

  isProcessing = false;
  if(!isAISpeaking && interviewActive){
    status.textContent = "Listening...";
    micStatus.textContent = "Listening";
    micStatus.className = "ok pulse";
  }
}

/* ================== START ================== */
startBtn.onclick = async () => {
  if(!cvText){
    status.textContent = "Please upload resume first";
    return;
  }
  
  interviewActive = true;
  startBtn.style.display = "none";
  endBtn.style.display = "block";
  cvInput.style.display = "none";
  voskBox.style.display = "block";

  status.textContent = "Initializing Vosk...";
  
  // Notify Android to start Vosk
  if(window.Android && window.Android.startInterview){
    window.Android.startInterview();
  } else {
    console.warn("Android interface not found - running in browser mode");
    voskStatus.textContent = "Browser Mode";
    micStatus.textContent = "Not available";
  }

  startTimer();

  try{
    const fd = new FormData();
    fd.append("mode","start");
    fd.append("cvText",cvText);
    const r = await fetch(API,{method:"POST",body:fd});
    const d = await r.json();
    history = d.history || [];
    
    // Small delay to ensure Vosk is ready
    setTimeout(async () => {
      await speak(d.reply || "Welcome. Tell me about yourself.");
    }, 500);
    
  }catch(err){
    console.error(err);
    setTimeout(async () => {
      await speak("Welcome. Tell me about yourself.");
    }, 500);
  }
};

/* ================== END ================== */
endBtn.onclick = () => {
  if(confirm("End interview?")){
    finishInterview();
  }
};

async function finishInterview(){
  interviewActive = false;
  clearInterval(timerInt);
  speechSynthesis.cancel();
  
  // Notify Android to stop Vosk
  if(window.Android && window.Android.endInterview){
    window.Android.endInterview();
  }

  status.textContent = "Generating report...";
  voskStatus.textContent = "Stopped";
  micStatus.textContent = "Disconnected";

  try {
    const fd = new FormData();
    fd.append("mode","score");
    fd.append("history",JSON.stringify(history));
    fd.append("cvText",cvText);

    const r = await fetch(API,{method:"POST",body:fd});
    const d = await r.json();

    document.body.innerHTML = `
      <div class="card" style="max-width:800px;margin:20px auto">
        <h1>Interview Complete</h1>
        <pre style="white-space:pre-wrap">${d.reply || "Report coming soon"}</pre>
        <button class="btn-primary" onclick="location.reload()">New Interview</button>
      </div>`;
  } catch(err) {
    document.body.innerHTML = `
      <div class="card" style="max-width:800px;margin:20px auto">
        <h1>Interview Complete</h1>
        <p>Thank you for completing the interview.</p>
        <button class="btn-primary" onclick="location.reload()">New Interview</button>
      </div>`;
  }
}

/* ================== UI ================== */
function addMsg(role,text){
  const d = document.createElement("div");
  d.className = "msg " + role;
  d.innerHTML = `<b>${role==="ai"?"AI":role==="user"?"You":"System"}:</b> ${text}`;
  logBox.appendChild(d);
  logBox.scrollTop = logBox.scrollHeight;
}

/* ================== NAV ================== */
backBtn.onclick = () => {
  if(interviewActive && !confirm("End interview and go back?")) return;
  finishInterview();
};

// Prevent accidental back button during interview
history.pushState(null,"",location.href);
window.onpopstate = () => {
  if(interviewActive){
    history.pushState(null,"",location.href);
    if(confirm("End interview?")){
      finishInterview();
    }
  } else {
    location.href = "career-lab.html";
  }
};

/* ================== KEYBOARD INTERRUPT (for testing) ================== */
document.addEventListener('keydown', (e) => {
  if(e.code === 'Space' && interviewActive && isAISpeaking){
    e.preventDefault();
    stopSpeaking();
  }
});
</script>

</body>
</html>
