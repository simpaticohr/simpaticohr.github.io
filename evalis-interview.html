<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Evalis AI – Premium Live Interview with Vosk</title>

<script src="https://cdnjs.cloudflare.com/ajax/libs/pdf.js/3.11.174/pdf.min.js"></script>

<style>
:root {
  --primary: #6366f1;
  --primary-dark: #4f46e5;
  --success: #10b981;
  --danger: #ef4444;
  --warning: #f59e0b;
  --bg: #020617;
  --card-bg: rgba(255, 255, 255, 0.05);
  --border: rgba(255, 255, 255, 0.1);
}

* {
  box-sizing: border-box;
}

body {
  margin: 0;
  background: var(--bg);
  color: #fff;
  font-family: 'Inter', system-ui, -apple-system, sans-serif;
  display: flex;
  align-items: center;
  justify-content: center;
  min-height: 100vh;
  overflow-x: hidden;
}

.back-btn {
  position: fixed;
  top: 20px;
  left: 20px;
  background: rgba(255, 255, 255, 0.08);
  color: #fff;
  border: 1px solid var(--border);
  backdrop-filter: blur(10px);
  padding: 12px 20px;
  border-radius: 12px;
  font-weight: 600;
  font-size: 14px;
  cursor: pointer;
  z-index: 999;
  transition: all 0.3s ease;
}

.back-btn:hover {
  background: rgba(255, 255, 255, 0.15);
  transform: translateX(-2px);
}

.container {
  width: 95%;
  max-width: 1200px;
  display: grid;
  grid-template-columns: 1fr 1fr;
  gap: 24px;
  padding: 20px;
}

@media (max-width: 968px) {
  .container {
    grid-template-columns: 1fr;
  }
}

.card {
  background: var(--card-bg);
  backdrop-filter: blur(15px);
  border-radius: 24px;
  padding: 32px;
  border: 1px solid var(--border);
  box-shadow: 0 25px 50px rgba(0, 0, 0, 0.5);
}

.card-header {
  margin-bottom: 24px;
}

.card-title {
  font-size: 24px;
  font-weight: 700;
  margin: 0 0 8px 0;
  color: #fff;
}

.card-subtitle {
  font-size: 14px;
  color: #94a3b8;
  margin: 0;
}

/* Timer Section */
#timer {
  font-size: 48px;
  font-weight: 800;
  color: var(--primary);
  text-align: center;
  margin: 24px 0;
  font-variant-numeric: tabular-nums;
  letter-spacing: 2px;
}

#status {
  font-size: 14px;
  color: #94a3b8;
  text-align: center;
  margin-bottom: 20px;
  min-height: 20px;
  display: flex;
  align-items: center;
  justify-content: center;
  gap: 8px;
}

.status-indicator {
  width: 8px;
  height: 8px;
  border-radius: 50%;
  display: inline-block;
  animation: pulse 2s infinite;
}

.status-indicator.listening {
  background: var(--success);
}

.status-indicator.speaking {
  background: var(--warning);
}

.status-indicator.processing {
  background: var(--primary);
}

@keyframes pulse {
  0%, 100% { opacity: 1; }
  50% { opacity: 0.5; }
}

/* Voice Visualizer */
.voice-visualizer {
  display: flex;
  align-items: center;
  justify-content: center;
  gap: 4px;
  height: 80px;
  margin: 20px 0;
  opacity: 0;
  transition: opacity 0.3s ease;
}

.voice-visualizer.active {
  opacity: 1;
}

.voice-bar {
  width: 6px;
  background: linear-gradient(180deg, var(--primary), var(--primary-dark));
  border-radius: 3px;
  transition: height 0.1s ease;
}

/* Upload Section */
.upload-section {
  margin-bottom: 24px;
}

.file-input-wrapper {
  position: relative;
  display: block;
  margin-bottom: 16px;
}

#cvInput {
  width: 100%;
  padding: 14px;
  border: 2px dashed var(--border);
  border-radius: 12px;
  background: rgba(255, 255, 255, 0.03);
  color: #fff;
  font-size: 14px;
  cursor: pointer;
  transition: all 0.3s ease;
}

#cvInput:hover {
  border-color: var(--primary);
  background: rgba(99, 102, 241, 0.1);
}

.file-status {
  font-size: 13px;
  color: var(--success);
  margin-top: 8px;
  display: none;
}

.file-status.show {
  display: block;
}

/* Buttons */
.btn {
  background: var(--primary);
  color: #fff;
  border: none;
  padding: 16px 24px;
  border-radius: 14px;
  width: 100%;
  font-weight: 700;
  font-size: 16px;
  cursor: pointer;
  transition: all 0.3s ease;
  position: relative;
  overflow: hidden;
}

.btn:hover:not(:disabled) {
  background: var(--primary-dark);
  transform: translateY(-2px);
  box-shadow: 0 10px 25px rgba(99, 102, 241, 0.3);
}

.btn:disabled {
  opacity: 0.4;
  cursor: not-allowed;
  transform: none;
}

.btn.danger {
  background: var(--danger);
}

.btn.danger:hover:not(:disabled) {
  background: #dc2626;
  box-shadow: 0 10px 25px rgba(239, 68, 68, 0.3);
}

/* Conversation Log */
.conversation-log {
  max-height: 500px;
  overflow-y: auto;
  margin-top: 20px;
  padding-right: 8px;
}

.conversation-log::-webkit-scrollbar {
  width: 6px;
}

.conversation-log::-webkit-scrollbar-track {
  background: rgba(255, 255, 255, 0.05);
  border-radius: 3px;
}

.conversation-log::-webkit-scrollbar-thumb {
  background: rgba(255, 255, 255, 0.2);
  border-radius: 3px;
}

.message {
  margin-bottom: 16px;
  padding: 14px 18px;
  border-radius: 12px;
  animation: slideIn 0.3s ease;
}

@keyframes slideIn {
  from {
    opacity: 0;
    transform: translateY(10px);
  }
  to {
    opacity: 1;
    transform: translateY(0);
  }
}

.message.user {
  background: rgba(103, 232, 249, 0.1);
  border-left: 3px solid #67e8f9;
}

.message.ai {
  background: rgba(165, 180, 252, 0.1);
  border-left: 3px solid #a5b4fc;
}

.message-header {
  font-weight: 700;
  font-size: 12px;
  text-transform: uppercase;
  letter-spacing: 0.5px;
  margin-bottom: 6px;
  opacity: 0.8;
}

.message.user .message-header {
  color: #67e8f9;
}

.message.ai .message-header {
  color: #a5b4fc;
}

.message-content {
  font-size: 14px;
  line-height: 1.6;
  color: #e2e8f0;
}

.message-time {
  font-size: 11px;
  color: #64748b;
  margin-top: 6px;
}

/* Vosk Status */
.vosk-status {
  padding: 12px 16px;
  border-radius: 10px;
  background: rgba(255, 255, 255, 0.03);
  border: 1px solid var(--border);
  margin-bottom: 20px;
  font-size: 13px;
}

.vosk-status-item {
  display: flex;
  justify-content: space-between;
  margin-bottom: 8px;
}

.vosk-status-item:last-child {
  margin-bottom: 0;
}

.vosk-status-label {
  color: #94a3b8;
}

.vosk-status-value {
  color: #fff;
  font-weight: 600;
}

.vosk-status-value.active {
  color: var(--success);
}

.vosk-status-value.inactive {
  color: var(--danger);
}

/* Error Message */
.error-msg {
  color: var(--danger);
  font-size: 13px;
  margin-top: 12px;
  padding: 10px 14px;
  background: rgba(239, 68, 68, 0.1);
  border-radius: 8px;
  border-left: 3px solid var(--danger);
  display: none;
}

.error-msg.show {
  display: block;
  animation: slideIn 0.3s ease;
}

/* Audio Level Meter */
.audio-level {
  height: 6px;
  background: rgba(255, 255, 255, 0.1);
  border-radius: 3px;
  overflow: hidden;
  margin-top: 12px;
}

.audio-level-bar {
  height: 100%;
  background: linear-gradient(90deg, var(--success), var(--warning));
  width: 0%;
  transition: width 0.1s ease;
  border-radius: 3px;
}

/* Loading Spinner */
.spinner {
  display: inline-block;
  width: 12px;
  height: 12px;
  border: 2px solid rgba(255, 255, 255, 0.3);
  border-top-color: #fff;
  border-radius: 50%;
  animation: spin 0.8s linear infinite;
}

@keyframes spin {
  to { transform: rotate(360deg); }
}
</style>
</head>

<body>

<button id="backBtn" class="back-btn">← Back</button>

<div class="container">
  <!-- Left Panel: Controls -->
  <div class="card">
    <div class="card-header">
      <h1 class="card-title">Evalis AI Interview</h1>
      <p class="card-subtitle">Premium Voice-Powered Experience</p>
    </div>

    <div id="timer">15:00</div>
    <div id="status">Upload your resume to begin</div>

    <div class="voice-visualizer" id="visualizer">
      <div class="voice-bar" style="height: 20px;"></div>
      <div class="voice-bar" style="height: 40px;"></div>
      <div class="voice-bar" style="height: 30px;"></div>
      <div class="voice-bar" style="height: 50px;"></div>
      <div class="voice-bar" style="height: 35px;"></div>
      <div class="voice-bar" style="height: 45px;"></div>
      <div class="voice-bar" style="height: 25px;"></div>
    </div>

    <div class="upload-section">
      <div class="file-input-wrapper">
        <input type="file" id="cvInput" accept=".pdf">
        <div class="file-status" id="fileStatus">✓ Resume loaded successfully</div>
      </div>
    </div>

    <button id="startBtn" class="btn" disabled>
      <span>Start Interview</span>
    </button>
    
    <button id="endBtn" class="btn danger" style="display: none;">
      <span>End Interview</span>
    </button>

    <div class="vosk-status" id="voskStatus" style="display: none;">
      <div class="vosk-status-item">
        <span class="vosk-status-label">Vosk Engine:</span>
        <span class="vosk-status-value" id="voskEngineStatus">Initializing...</span>
      </div>
      <div class="vosk-status-item">
        <span class="vosk-status-label">Microphone:</span>
        <span class="vosk-status-value" id="micStatus">Not Connected</span>
      </div>
      <div class="vosk-status-item">
        <span class="vosk-status-label">Listening Mode:</span>
        <span class="vosk-status-value active" id="listeningMode">Continuous</span>
      </div>
    </div>

    <div class="audio-level">
      <div class="audio-level-bar" id="audioLevelBar"></div>
    </div>

    <div class="error-msg" id="errorMsg"></div>
  </div>

  <!-- Right Panel: Conversation -->
  <div class="card">
    <div class="card-header">
      <h2 class="card-title">Conversation</h2>
      <p class="card-subtitle">Real-time transcript</p>
    </div>

    <div class="conversation-log" id="conversationLog">
      <div style="text-align: center; color: #64748b; padding: 40px 20px;">
        <p>Your conversation will appear here</p>
      </div>
    </div>
  </div>
</div>

<script>
const API = "https://evalis-ai.simpaticohrconsultancy.workers.dev";
const pdfjsLib = window['pdfjs-dist/build/pdf'];
pdfjsLib.GlobalWorkerOptions.workerSrc =
  "https://cdnjs.cloudflare.com/ajax/libs/pdf.js/3.11.174/pdf.worker.min.js";

// State Management
let cvText = "";
let history = [];
let interviewActive = false;
let isAISpeaking = false;
let isProcessing = false;
let timerInterval;
let timeLeft = 15 * 60;

// Vosk Integration Variables
let voskRecognizer = null;
let audioContext = null;
let mediaStream = null;
let processor = null;
let isVoskReady = false;
let partialTranscript = "";
let silenceTimer = null;
const SILENCE_THRESHOLD = 1500; // ms before processing speech

// DOM Elements
const elements = {
  timer: document.getElementById('timer'),
  status: document.getElementById('status'),
  cvInput: document.getElementById('cvInput'),
  fileStatus: document.getElementById('fileStatus'),
  startBtn: document.getElementById('startBtn'),
  endBtn: document.getElementById('endBtn'),
  voskStatus: document.getElementById('voskStatus'),
  voskEngineStatus: document.getElementById('voskEngineStatus'),
  micStatus: document.getElementById('micStatus'),
  listeningMode: document.getElementById('listeningMode'),
  audioLevelBar: document.getElementById('audioLevelBar'),
  errorMsg: document.getElementById('errorMsg'),
  conversationLog: document.getElementById('conversationLog'),
  visualizer: document.getElementById('visualizer'),
  backBtn: document.getElementById('backBtn')
};

/* ============================================
   PDF UPLOAD & PROCESSING
============================================ */
elements.cvInput.onchange = async (e) => {
  try {
    const file = e.target.files[0];
    if (!file) return;

    updateStatus("Loading resume...", "processing");
    
    const pdf = await pdfjsLib.getDocument(await file.arrayBuffer()).promise;
    let text = "";
    
    for (let i = 1; i <= pdf.numPages; i++) {
      const page = await pdf.getPage(i);
      const content = await page.getTextContent();
      text += content.items.map(item => item.str).join(" ") + " ";
    }
    
    cvText = text.trim() || "[Resume uploaded]";
    elements.startBtn.disabled = false;
    elements.fileStatus.classList.add('show');
    updateStatus("Resume ready • Click Start Interview", "success");
  } catch (error) {
    showError("Failed to load PDF. Please try again.");
    console.error("PDF Error:", error);
  }
};

/* ============================================
   VOSK SPEECH RECOGNITION SETUP
============================================ */
async function initializeVosk() {
  try {
    updateStatus("Initializing Vosk engine...", "processing");
    elements.voskEngineStatus.textContent = "Loading...";
    
    // Request microphone permission
    mediaStream = await navigator.mediaDevices.getUserMedia({
      audio: {
        echoCancellation: true,
        noiseSuppression: true,
        autoGainControl: true,
        sampleRate: 16000
      }
    });
    
    elements.micStatus.textContent = "Connected";
    elements.micStatus.classList.add('active');
    
    // Create Audio Context
    audioContext = new (window.AudioContext || window.webkitAudioContext)({
      sampleRate: 16000
    });
    
    const source = audioContext.createMediaStreamSource(mediaStream);
    
    // Create ScriptProcessor for audio processing
    processor = audioContext.createScriptProcessor(4096, 1, 1);
    
    // Load Vosk model (you'll need to host this or use a CDN)
    // For now, we'll simulate Vosk with Web Speech API as fallback
    // In production, integrate actual Vosk WASM model
    
    await initializeWebSpeechFallback();
    
    elements.voskEngineStatus.textContent = "Active";
    elements.voskEngineStatus.classList.add('active');
    isVoskReady = true;
    elements.voskStatus.style.display = "block";
    
    updateStatus("Voice recognition ready", "success");
    return true;
    
  } catch (error) {
    showError("Microphone access denied. Please enable microphone permissions.");
    console.error("Vosk Init Error:", error);
    elements.micStatus.textContent = "Access Denied";
    elements.micStatus.classList.add('inactive');
    return false;
  }
}

/* ============================================
   WEB SPEECH API (FALLBACK FOR CONTINUOUS LISTENING)
============================================ */
let recognition = null;

function initializeWebSpeechFallback() {
  const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
  
  if (!SpeechRecognition) {
    throw new Error("Speech recognition not supported");
  }
  
  recognition = new SpeechRecognition();
  recognition.continuous = true; // CONTINUOUS LISTENING
  recognition.interimResults = true;
  recognition.lang = 'en-US';
  recognition.maxAlternatives = 1;
  
  let finalTranscript = '';
  let interimTranscript = '';
  
  recognition.onstart = () => {
    console.log("Voice recognition started - CONTINUOUS MODE");
    updateStatus("Listening continuously...", "listening");
    elements.visualizer.classList.add('active');
  };
  
  recognition.onresult = (event) => {
    interimTranscript = '';
    
    for (let i = event.resultIndex; i < event.results.length; i++) {
      const transcript = event.results[i][0].transcript;
      
      if (event.results[i].isFinal) {
        finalTranscript += transcript + ' ';
        
        // Clear silence timer
        if (silenceTimer) {
          clearTimeout(silenceTimer);
        }
        
        // Set new silence timer to process after pause
        silenceTimer = setTimeout(() => {
          if (finalTranscript.trim().length > 0) {
            processUserSpeech(finalTranscript.trim());
            finalTranscript = '';
          }
        }, SILENCE_THRESHOLD);
        
      } else {
        interimTranscript += transcript;
      }
    }
    
    // Update visualizer based on speech activity
    animateVisualizer(interimTranscript.length > 0 || finalTranscript.length > 0);
  };
  
  recognition.onerror = (event) => {
    console.error("Recognition error:", event.error);
    
    if (event.error === 'no-speech') {
      // This is normal in continuous mode, just continue
      return;
    }
    
    if (event.error === 'aborted') {
      // Restart if aborted during interview
      if (interviewActive && !isAISpeaking) {
        setTimeout(() => recognition.start(), 100);
      }
      return;
    }
    
    showError(`Voice recognition error: ${event.error}`);
  };
  
  recognition.onend = () => {
    console.log("Recognition ended");
    
    // Auto-restart if interview is still active and AI is not speaking
    if (interviewActive && !isAISpeaking && !isProcessing) {
      console.log("Restarting recognition for continuous listening...");
      setTimeout(() => {
        try {
          recognition.start();
        } catch (e) {
          console.error("Restart error:", e);
        }
      }, 100);
    } else {
      elements.visualizer.classList.remove('active');
    }
  };
}

/* ============================================
   PROCESS USER SPEECH
============================================ */
async function processUserSpeech(text) {
  if (!interviewActive || isProcessing || isAISpeaking) return;
  if (!text || text.length < 3) return;
  
  console.log("Processing user speech:", text);
  
  isProcessing = true;
  updateStatus("Processing your response...", "processing");
  
  // Add to conversation log
  addMessage('user', text);
  
  try {
    const formData = new FormData();
    formData.append("mode", "interview");
    formData.append("history", JSON.stringify(history));
    formData.append("text", text);
    formData.append("cvText", cvText);
    
    const response = await fetch(API, {
      method: "POST",
      body: formData
    });
    
    const data = await response.json();
    history = data.history || history;
    
    if (data.reply) {
      await speakResponse(data.reply);
    }
    
  } catch (error) {
    showError("Connection error. Please check your internet.");
    console.error("API Error:", error);
  }
  
  isProcessing = false;
  
  if (interviewActive && !isAISpeaking) {
    updateStatus("Listening...", "listening");
  }
}

/* ============================================
   TEXT-TO-SPEECH
============================================ */
function speakResponse(text) {
  return new Promise((resolve) => {
    // Stop listening while AI speaks
    if (recognition) {
      recognition.stop();
    }
    
    speechSynthesis.cancel();
    
    const utterance = new SpeechSynthesisUtterance(text);
    utterance.rate = 0.95;
    utterance.pitch = 1.0;
    utterance.volume = 1.0;
    
    // Select best voice
    const voices = speechSynthesis.getVoices();
    const preferredVoice = voices.find(v => v.lang.startsWith('en') && v.name.includes('Google')) ||
                          voices.find(v => v.lang.startsWith('en'));
    if (preferredVoice) utterance.voice = preferredVoice;
    
    utterance.onstart = () => {
      isAISpeaking = true;
      updateStatus("AI speaking...", "speaking");
      elements.visualizer.classList.add('active');
    };
    
    utterance.onend = () => {
      isAISpeaking = false;
      elements.visualizer.classList.remove('active');
      
      // Resume listening
      if (interviewActive && !isProcessing) {
        updateStatus("Listening...", "listening");
        setTimeout(() => {
          if (recognition) {
            recognition.start();
          }
        }, 500);
      }
      
      resolve();
    };
    
    utterance.onerror = () => {
      isAISpeaking = false;
      resolve();
    };
    
    addMessage('ai', text);
    speechSynthesis.speak(utterance);
  });
}

/* ============================================
   INTERVIEW CONTROL
============================================ */
elements.startBtn.onclick = async () => {
  if (interviewActive) return;
  
  // Initialize voice recognition
  const voskReady = await initializeVosk();
  if (!voskReady) {
    showError("Cannot start without microphone access");
    return;
  }
  
  interviewActive = true;
  startTimer();
  
  // Update UI
  elements.cvInput.style.display = "none";
  elements.fileStatus.style.display = "none";
  elements.startBtn.style.display = "none";
  elements.endBtn.style.display = "block";
  
  updateStatus("Starting interview...", "processing");
  elements.conversationLog.innerHTML = "";
  
  try {
    // Get initial AI greeting
    const formData = new FormData();
    formData.append("mode", "start");
    formData.append("cvText", cvText);
    
    const response = await fetch(API, {
      method: "POST",
      body: formData
    });
    
    const data = await response.json();
    history = data.history || [];
    
    if (data.reply) {
      await speakResponse(data.reply);
    }
    
    // Start continuous listening
    if (recognition) {
      recognition.start();
    }
    
  } catch (error) {
    showError("Failed to start interview. Please try again.");
    console.error("Start Error:", error);
  }
};

elements.endBtn.onclick = () => {
  if (confirm("Are you sure you want to end the interview?")) {
    finishInterview();
  }
};

/* ============================================
   TIMER
============================================ */
function startTimer() {
  timerInterval = setInterval(() => {
    timeLeft--;
    const mins = Math.floor(timeLeft / 60);
    const secs = timeLeft % 60;
    elements.timer.textContent = `${mins}:${String(secs).padStart(2, '0')}`;
    
    if (timeLeft <= 0) {
      finishInterview();
    }
  }, 1000);
}

/* ============================================
   FINISH INTERVIEW
============================================ */
async function finishInterview() {
  interviewActive = false;
  clearInterval(timerInterval);
  
  // Stop recognition
  if (recognition) {
    recognition.stop();
  }
  
  // Stop audio
  speechSynthesis.cancel();
  
  if (mediaStream) {
    mediaStream.getTracks().forEach(track => track.stop());
  }
  
  updateStatus("Generating your performance report...", "processing");
  
  try {
    const formData = new FormData();
    formData.append("mode", "score");
    formData.append("history", JSON.stringify(history));
    formData.append("cvText", cvText);
    
    const response = await fetch(API, {
      method: "POST",
      body: formData
    });
    
    const data = await response.json();
    
    // Display final report
    document.body.innerHTML = `
      <div style="display: flex; align-items: center; justify-content: center; min-height: 100vh; padding: 20px;">
        <div class="card" style="max-width: 800px;">
          <div class="card-header">
            <h1 class="card-title">Interview Complete</h1>
            <p class="card-subtitle">Your Performance Report</p>
          </div>
          <div style="background: rgba(255,255,255,0.03); padding: 24px; border-radius: 12px; margin: 20px 0;">
            <pre style="white-space: pre-wrap; font-family: system-ui; line-height: 1.8; color: #e2e8f0;">${data.reply || "Report generation in progress..."}</pre>
          </div>
          <button onclick="location.reload()" class="btn">Start New Interview</button>
        </div>
      </div>
    `;
    
  } catch (error) {
    showError("Failed to generate report");
    console.error("Score Error:", error);
  }
}

/* ============================================
   UI HELPERS
============================================ */
function updateStatus(message, type = "default") {
  let indicator = "";
  
  if (type === "listening") {
    indicator = '<span class="status-indicator listening"></span>';
  } else if (type === "speaking") {
    indicator = '<span class="status-indicator speaking"></span>';
  } else if (type === "processing") {
    indicator = '<span class="spinner"></span>';
  }
  
  elements.status.innerHTML = indicator + message;
}

function addMessage(role, content) {
  const messageDiv = document.createElement('div');
  messageDiv.className = `message ${role}`;
  
  const now = new Date();
  const timeStr = now.toLocaleTimeString('en-US', { 
    hour: '2-digit', 
    minute: '2-digit' 
  });
  
  messageDiv.innerHTML = `
    <div class="message-header">${role === 'user' ? 'You' : 'AI Interviewer'}</div>
    <div class="message-content">${content}</div>
    <div class="message-time">${timeStr}</div>
  `;
  
  elements.conversationLog.appendChild(messageDiv);
  elements.conversationLog.scrollTop = elements.conversationLog.scrollHeight;
}

function showError(message) {
  elements.errorMsg.textContent = message;
  elements.errorMsg.classList.add('show');
  
  setTimeout(() => {
    elements.errorMsg.classList.remove('show');
  }, 5000);
}

function animateVisualizer(active) {
  const bars = elements.visualizer.querySelectorAll('.voice-bar');
  
  bars.forEach((bar, index) => {
    if (active) {
      const randomHeight = Math.random() * 50 + 10;
      bar.style.height = randomHeight + 'px';
    } else {
      bar.style.height = '20px';
    }
  });
  
  // Update audio level bar
  if (active) {
    const level = Math.random() * 100;
    elements.audioLevelBar.style.width = level + '%';
  } else {
    elements.audioLevelBar.style.width = '0%';
  }
}

// Continuous visualizer animation
setInterval(() => {
  if (interviewActive && (isAISpeaking || !isProcessing)) {
    animateVisualizer(isAISpeaking);
  }
}, 100);

/* ============================================
   NAVIGATION
============================================ */
elements.backBtn.onclick = () => {
  if (interviewActive) {
    if (!confirm("Interview is in progress. Are you sure you want to leave?")) {
      return;
    }
  }
  
  speechSynthesis.cancel();
  if (recognition) recognition.stop();
  if (mediaStream) mediaStream.getTracks().forEach(track => track.stop());
  
  location.href = "career-lab.html";
};

// Prevent accidental back navigation
history.pushState(null, "", location.href);
window.onpopstate = () => {
  history.pushState(null, "", location.href);
  elements.backBtn.click();
};

// Ensure speech synthesis voices are loaded
window.speechSynthesis.onvoiceschanged = () => {
  console.log("Voices loaded:", speechSynthesis.getVoices().length);
};

console.log("Evalis AI Interview System - Premium Edition");
console.log("Continuous Voice Recognition: ENABLED");
</script>

</body>
</html>
