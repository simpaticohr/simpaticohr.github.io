<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Career Lab AI | Interview Session</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/pdf.js/3.11.174/pdf.min.js"></script>
    <style>
        :root { --accent: #2563eb; --bg: #0f172a; --card: #1e293b; }
        body { font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; background: var(--bg); color: white; display: flex; justify-content: center; align-items: center; min-height: 100vh; margin: 0; }
        .container { width: 100%; max-width: 450px; background: var(--card); padding: 30px; border-radius: 20px; box-shadow: 0 10px 25px rgba(0,0,0,0.3); text-align: center; border: 1px solid rgba(255,255,255,0.1); }
        .pulse { width: 80px; height: 80px; background: var(--accent); border-radius: 50%; margin: 20px auto; display: none; animation: ring 1.5s infinite; }
        @keyframes ring { 0% { box-shadow: 0 0 0 0 rgba(37, 99, 235, 0.7); } 100% { box-shadow: 0 0 0 30px rgba(37, 99, 235, 0); } }
        #status { font-weight: bold; color: #94a3b8; margin-bottom: 10px; font-size: 14px; text-transform: uppercase; }
        #log { background: rgba(0,0,0,0.2); border-radius: 12px; height: 200px; overflow-y: auto; padding: 15px; text-align: left; font-size: 14px; border: 1px solid rgba(255,255,255,0.05); margin-top: 20px; }
        button { width: 100%; padding: 15px; border-radius: 12px; border: none; background: var(--accent); color: white; font-size: 16px; font-weight: bold; cursor: pointer; transition: 0.2s; }
        button:disabled { background: #475569; cursor: not-allowed; opacity: 0.6; }
        #mainBtn.stop { background: #dc2626; }
        input[type="file"] { margin: 15px 0; font-size: 12px; color: #94a3b8; }
        .ai-text { color: #60a5fa; margin-bottom: 10px; }
        .user-text { color: #94a3b8; margin-bottom: 10px; border-left: 2px solid #334155; padding-left: 8px; }
    </style>
</head>
<body>

<div class="container">
    <h2>Career Lab AI</h2>
    <div id="status">Waiting for Resume...</div>
    
    <input type="file" id="cvInput" accept=".pdf,.txt">
    <div id="visualizer" class="pulse"></div>
    
    <button id="mainBtn" disabled>Start Interview</button>
    
    <div id="log">
        <p class="ai-text">Welcome. Please upload your resume to begin the voice session.</p>
    </div>
</div>

<script>
    const WORKER_URL = "https://evalis-ai.simpaticohrconsultancy.workers.dev";
    let chatHistory = [];
    let resumeContent = "";
    let isInterviewActive = false;
    let isProcessing = false;

    const mainBtn = document.getElementById('mainBtn');
    const statusLabel = document.getElementById('status');
    const logContainer = document.getElementById('log');
    const visualizer = document.getElementById('visualizer');

    // 1. PDF/Resume Extraction
    document.getElementById('cvInput').onchange = async (e) => {
        const file = e.target.files[0];
        if (!file) return;
        
        statusLabel.innerText = "Processing Resume...";
        try {
            if (file.type === "application/pdf") {
                const pdfjsLib = window['pdfjs-dist/build/pdf'];
                pdfjsLib.GlobalWorkerOptions.workerSrc = 'https://cdnjs.cloudflare.com/ajax/libs/pdf.js/3.11.174/pdf.worker.min.js';
                const pdf = await pdfjsLib.getDocument(new Uint8Array(await file.arrayBuffer())).promise;
                let text = "";
                for (let i = 1; i <= pdf.numPages; i++) {
                    const page = await pdf.getPage(i);
                    const content = await page.getTextContent();
                    text += content.items.map(s => s.str).join(" ") + " ";
                }
                resumeContent = text;
            } else {
                resumeContent = await file.text();
            }
            statusLabel.innerText = "System Ready";
            mainBtn.disabled = false;
        } catch (err) {
            statusLabel.innerText = "Error Loading PDF";
            console.error(err);
        }
    };

    // 2. Speech Synthesis (Text-to-Speech)
    function aiSpeak(text) {
        if (!text || text === "undefined") {
            isProcessing = false;
            return;
        }

        const utterance = new SpeechSynthesisUtterance(text);
        
        // Add to UI log
        logContainer.innerHTML += `<div class="ai-text"><b>AI:</b> ${text}</div>`;
        logContainer.scrollTop = logContainer.scrollHeight;

        utterance.onend = () => {
            isProcessing = false;
            if (isInterviewActive) {
                // Short delay before listening again to avoid AI hearing its own echo
                setTimeout(startVoiceCapture, 600);
            }
        };

        window.speechSynthesis.cancel(); // Clear any queued speech
        window.speechSynthesis.speak(utterance);
    }

    // 3. Audio Recording & Sending
    async function startVoiceCapture() {
        if (isProcessing || !isInterviewActive) return;

        try {
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            const recorder = new MediaRecorder(stream);
            const audioChunks = [];

            statusLabel.innerText = "Listening...";
            visualizer.style.display = "block";

            recorder.ondataavailable = (e) => audioChunks.push(e.data);
            
            recorder.onstop = async () => {
                visualizer.style.display = "none";
                stream.getTracks().forEach(track => track.stop());

                if (audioChunks.length === 0 || !isInterviewActive) return;

                isProcessing = true;
                statusLabel.innerText = "Analyzing Answer...";

                const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                const formData = new FormData();
                
                // IMPORTANT: Use 'audio' name and include a filename to ensure binary transfer
                formData.append("audio", audioBlob, "recording.webm");
                formData.append("cvText", resumeContent);
                formData.append("history", JSON.stringify(chatHistory));
                formData.append("mode", "interview");

                try {
                    // DO NOT set headers manually; browser handles FormData boundary
                    const response = await fetch(WORKER_URL, {
                        method: "POST",
                        body: formData
                    });

                    const data = await response.json();

                    if (data.reply) {
                        chatHistory = data.history || chatHistory;
                        aiSpeak(data.reply);
                    } else if (data.error) {
                        logContainer.innerHTML += `<div style="color:red">System Error: ${data.error}</div>`;
                        isProcessing = false;
                    }
                } catch (err) {
                    statusLabel.innerText = "Network Error. Retrying...";
                    isProcessing = false;
                    setTimeout(startVoiceCapture, 3000);
                }
            };

            recorder.start();
            // Automatically stop after 6 seconds of speaking
            setTimeout(() => { if (recorder.state === "recording") recorder.stop(); }, 6000);

        } catch (err) {
            statusLabel.innerText = "Mic Access Required";
            console.error(err);
        }
    }

    // 4. Main Button Control
    mainBtn.onclick = () => {
        if (!isInterviewActive) {
            // Start
            isInterviewActive = true;
            mainBtn.innerText = "Stop & Generate Report";
            mainBtn.classList.add('stop');
            aiSpeak("I have analyzed your resume. Let's begin the interview. Can you tell me a bit about your professional background?");
        } else {
            // Stop
            isInterviewActive = false;
            window.speechSynthesis.cancel();
            location.reload(); // Quickest way to reset the session
        }
    };
</script>

</body>
</html>
