<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Evalis AI | Intelligent Interviewer</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/pdf.js/3.11.174/pdf.min.js"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600&display=swap" rel="stylesheet">
    <style>
        :root {
            --bg: #05050a;
            --surface: #0f1016;
            --primary: #6366f1;
            --accent: #a855f7;
            --text: #e2e8f0;
            --text-dim: #64748b;
        }

        body {
            margin: 0;
            background: var(--bg);
            color: var(--text);
            font-family: 'Inter', sans-serif;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            min-height: 100vh;
            overflow: hidden;
        }

        /* --- THE ORB (Core Animation) --- */
        .orb-container {
            position: relative;
            width: 200px;
            height: 200px;
            display: flex;
            align-items: center;
            justify-content: center;
            margin-bottom: 40px;
        }

        .orb {
            width: 120px;
            height: 120px;
            background: linear-gradient(135deg, var(--primary), var(--accent));
            border-radius: 50%;
            box-shadow: 0 0 60px rgba(99, 102, 241, 0.4), inset 0 0 20px rgba(255, 255, 255, 0.2);
            position: relative;
            z-index: 2;
            transition: all 0.2s cubic-bezier(0.25, 0.46, 0.45, 0.94);
            animation: breathe 4s ease-in-out infinite;
        }

        /* State: Listening (Active) */
        .orb.listening {
            background: linear-gradient(135deg, #22c55e, #10b981);
            box-shadow: 0 0 60px rgba(34, 197, 94, 0.4);
            animation: pulse-green 2s infinite;
        }

        /* State: Thinking (Processing) */
        .orb.thinking {
            background: linear-gradient(135deg, #f59e0b, #d97706);
            box-shadow: 0 0 60px rgba(245, 158, 11, 0.4);
            animation: spin 1.5s linear infinite;
            border-radius: 40%;
        }

        /* Rings */
        .ring {
            position: absolute;
            border-radius: 50%;
            border: 1px solid rgba(255, 255, 255, 0.05);
            top: 50%; left: 50%;
            transform: translate(-50%, -50%);
            z-index: 1;
        }
        .ring:nth-child(1) { width: 200px; height: 200px; animation: spin 10s linear infinite; border-color: rgba(99, 102, 241, 0.1); }
        .ring:nth-child(2) { width: 300px; height: 300px; animation: spin-rev 15s linear infinite; border-style: dashed; }
        .ring:nth-child(3) { width: 450px; height: 450px; opacity: 0.3; }

        /* --- UI ELEMENTS --- */
        .interface {
            width: 100%;
            max-width: 500px;
            text-align: center;
            z-index: 10;
        }

        h1 { font-weight: 300; letter-spacing: -1px; margin-bottom: 5px; font-size: 1.5rem; }
        .status-pill {
            display: inline-block;
            padding: 6px 16px;
            background: rgba(255, 255, 255, 0.05);
            border: 1px solid rgba(255, 255, 255, 0.1);
            border-radius: 50px;
            font-size: 0.85rem;
            color: var(--text-dim);
            margin-bottom: 30px;
            backdrop-filter: blur(5px);
            transition: 0.3s;
        }
        
        .timer { font-family: monospace; color: var(--text-dim); margin-top: 10px; font-size: 0.9rem; opacity: 0; transition: opacity 0.5s; }
        .timer.active { opacity: 1; }

        /* Controls */
        .controls { display: flex; gap: 15px; justify-content: center; margin-top: 20px; }
        
        .btn {
            background: var(--surface);
            color: var(--text);
            border: 1px solid rgba(255, 255, 255, 0.1);
            padding: 12px 24px;
            border-radius: 12px;
            cursor: pointer;
            font-weight: 600;
            transition: 0.2s;
            display: flex;
            align-items: center;
            gap: 8px;
        }
        .btn:hover { background: rgba(255, 255, 255, 0.1); transform: translateY(-2px); }
        .btn-primary { background: var(--primary); border-color: var(--primary); }
        .btn-primary:hover { background: #4f46e5; }
        .btn-danger { background: rgba(239, 68, 68, 0.1); color: #ef4444; border-color: rgba(239, 68, 68, 0.2); }
        .btn-danger:hover { background: rgba(239, 68, 68, 0.2); }

        input[type="file"] { display: none; }
        .file-trigger {
            border: 2px dashed rgba(255, 255, 255, 0.2);
            padding: 30px;
            border-radius: 16px;
            cursor: pointer;
            color: var(--text-dim);
            transition: 0.2s;
            display: block; /* Fixes alignment on some browsers */
        }
        .file-trigger:hover { border-color: var(--primary); color: var(--text); background: rgba(99, 102, 241, 0.05); }

        /* Animations */
        @keyframes breathe { 0%, 100% { transform: scale(1); } 50% { transform: scale(1.05); } }
        @keyframes pulse-green { 0% { box-shadow: 0 0 0 0 rgba(34, 197, 94, 0.7); } 70% { box-shadow: 0 0 0 20px rgba(34, 197, 94, 0); } 100% { box-shadow: 0 0 0 0 rgba(34, 197, 94, 0); } }
        @keyframes spin { 0% { transform: rotate(0deg); } 100% { transform: rotate(360deg); } }
        @keyframes spin-rev { 0% { transform: rotate(360deg); } 100% { transform: rotate(0deg); } }

        /* Report Modal */
        .modal {
            position: fixed; top:0; left:0; width:100%; height:100%;
            background: rgba(0,0,0,0.8); backdrop-filter: blur(10px);
            display: none; align-items: center; justify-content: center; z-index: 100;
        }
        .modal-content {
            background: var(--surface); border: 1px solid rgba(255,255,255,0.1);
            padding: 40px; border-radius: 24px; max-width: 600px; width: 90%;
            max-height: 80vh; overflow-y: auto; text-align: left;
        }
    </style>
</head>
<body>

    <div class="orb-container">
        <div class="ring"></div>
        <div class="ring"></div>
        <div class="ring"></div>
        <div id="orb" class="orb"></div>
    </div>

    <div class="interface">
        <h1 id="mainTitle">Evalis AI</h1>
        <div id="status" class="status-pill">Waiting for Resume</div>
        
        <div id="setupPanel">
            <label class="file-trigger">
                <span>ðŸ“‚ Upload PDF Resume</span>
                <input type="file" id="cvInput" accept=".pdf">
            </label>
            <br><br>
            <button id="startBtn" class="btn btn-primary" style="width:100%; justify-content:center; display:none;">
                Start Interview
            </button>
        </div>

        <div id="activePanel" style="display:none;">
            <div class="controls">
                <button id="micToggle" class="btn">ðŸŽ¤ Mute</button>
                <button id="endBtn" class="btn btn-danger">End Session</button>
            </div>
            <div id="timer" class="timer">15:00</div>
        </div>
    </div>

    <div id="reportModal" class="modal">
        <div class="modal-content">
            <h2 style="color:var(--primary); margin-top:0;">Evaluation Report</h2>
            <div id="reportText" style="line-height: 1.6; color: var(--text-dim); white-space: pre-wrap;"></div>
            <button onclick="location.reload()" class="btn btn-primary" style="margin-top:20px; width:100%; justify-content:center;">Start New Session</button>
        </div>
    </div>

<script>
// --- CONFIGURATION ---
const API_URL = "https://evalis-ai.simpaticohrconsultancy.workers.dev";
pdfjsLib.GlobalWorkerOptions.workerSrc = "https://cdnjs.cloudflare.com/ajax/libs/pdf.js/3.11.174/pdf.worker.min.js";

// --- STATE ---
let state = {
    cvText: "",
    history: [],
    isListening: false,
    isSpeaking: false,
    isMuted: false, 
    timeLeft: 900 // 15 mins
};

let timerInterval = null; // To store and clear the timer safely
let currentUtterance = null; // Stored globally to prevent Chrome garbage collection bug

// Load voices proactively
window.speechSynthesis.onvoiceschanged = () => {
    window.speechSynthesis.getVoices();
};

// --- DOM ELEMENTS ---
const orb = document.getElementById('orb');
const status = document.getElementById('status');
const timerDisplay = document.getElementById('timer');
const micToggleBtn = document.getElementById('micToggle');

// --- AUDIO VISUALIZATION ---
let audioCtx, analyser, dataArray;
async function initAudio() {
    try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        audioCtx = new (window.AudioContext || window.webkitAudioContext)();
        analyser = audioCtx.createAnalyser();
        analyser.fftSize = 64; 
        const source = audioCtx.createMediaStreamSource(stream);
        source.connect(analyser);
        dataArray = new Uint8Array(analyser.frequencyBinCount);
        animateOrb();
        return true;
    } catch (e) {
        alert("Microphone access denied. Please enable permissions.");
        return false;
    }
}

function animateOrb() {
    requestAnimationFrame(animateOrb);
    if (!state.isListening || state.isMuted) {
        if (!state.isSpeaking) orb.style.transform = `scale(1)`;
        return;
    }
    
    analyser.getByteFrequencyData(dataArray);
    
    // Calculate volume
    let sum = 0;
    for (let i = 0; i < dataArray.length; i++) sum += dataArray[i];
    let avg = sum / dataArray.length;
    
    // Map volume to scale (1.0 to 1.5)
    let scale = 1 + (avg / 255) * 0.8; 
    orb.style.transform = `scale(${scale})`;
}

// --- SPEECH RECOGNITION (The "Ears") ---
const Recognition = window.SpeechRecognition || window.webkitSpeechRecognition;
const recognition = new Recognition();
recognition.continuous = false; 
recognition.interimResults = false;
recognition.lang = 'en-US';

recognition.onstart = () => {
    if (state.isMuted) {
        recognition.stop();
        return;
    }
    state.isListening = true;
    orb.classList.add('listening');
    orb.classList.remove('thinking');
    status.textContent = "Listening...";
};

recognition.onend = () => {
    state.isListening = false;
    orb.classList.remove('listening');
    // Safely restart if not speaking, not muted, and session has started
    if (!state.isSpeaking && !state.isMuted && state.history.length > 0) {
        setTimeout(() => { 
            if(!state.isSpeaking && !state.isMuted) {
                try { recognition.start(); } catch(e){}
            }
        }, 500);
    }
};

recognition.onresult = async (event) => {
    const transcript = event.results[0][0].transcript;
    if (!transcript.trim()) return;

    // Transition to Thinking
    state.isListening = false; 
    orb.classList.remove('listening');
    orb.classList.add('thinking');
    status.textContent = "Analysing response...";
    
    await processAIInteraction(transcript);
};

// --- SPEECH SYNTHESIS (The "Voice") ---
function speak(text) {
    state.isSpeaking = true;
    try { recognition.stop(); } catch(e){} 
    orb.classList.remove('listening', 'thinking');
    status.textContent = "AI Speaking...";

    // Use global variable to prevent Chrome from abruptly stopping speech
    currentUtterance = new SpeechSynthesisUtterance(text);
    
    const voices = window.speechSynthesis.getVoices();
    const preferred = voices.find(v => v.name.includes('Google US English') || v.name.includes('Natural')) || voices[0];
    if(preferred) currentUtterance.voice = preferred;
    
    // FIXED AI SPEED: Lowered from 1.1 to 0.95 for a more natural, pacing interviewer feel.
    currentUtterance.rate = 0.95; 
    currentUtterance.pitch = 1.0;

    currentUtterance.onend = () => {
        state.isSpeaking = false;
        orb.classList.remove('listening', 'thinking');
        
        if (!state.isMuted) {
            orb.classList.add('listening'); 
            status.textContent = "Listening...";
            try { recognition.start(); } catch(e){} 
        } else {
            status.textContent = "Microphone Muted";
        }
    };

    window.speechSynthesis.speak(currentUtterance);
    
    let speechInterval = setInterval(() => {
        if(!state.isSpeaking) clearInterval(speechInterval);
        else {
            const randomScale = 1 + Math.random() * 0.15;
            orb.style.transform = `scale(${randomScale})`;
        }
    }, 100);
}

// --- CORE LOGIC ---
async function processAIInteraction(userText) {
    const fd = new FormData();
    fd.append("mode", "interview");
    fd.append("history", JSON.stringify(state.history));
    fd.append("text", userText);
    fd.append("cvText", state.cvText);

    try {
        const res = await fetch(API_URL, { method: "POST", body: fd });
        const data = await res.json();
        
        state.history = data.history;
        speak(data.reply);
    } catch (e) {
        console.error(e);
        status.textContent = "Connection Error. Retrying...";
        setTimeout(() => {
            if(!state.isMuted) recognition.start();
        }, 2000);
    }
}

// --- SETUP & HANDLERS ---

// NEW: Mute Button Logic
micToggleBtn.onclick = () => {
    state.isMuted = !state.isMuted;
    if (state.isMuted) {
        try { recognition.stop(); } catch(e){}
        micToggleBtn.textContent = "ðŸŽ™ï¸ Unmute";
        micToggleBtn.style.color = "#ef4444"; 
        status.textContent = "Microphone Muted";
        orb.classList.remove('listening');
    } else {
        micToggleBtn.textContent = "ðŸŽ¤ Mute";
        micToggleBtn.style.color = "var(--text)";
        if (!state.isSpeaking) {
            try { recognition.start(); } catch(e){}
        }
    }
};

document.getElementById('cvInput').onchange = async (e) => {
    const file = e.target.files[0];
    if(!file) return;
    
    status.textContent = "Reading Resume...";
    const buffer = await file.arrayBuffer();
    
    // FIXED PDF LOADING: Passing Uint8Array is safer across different pdf.js versions
    const pdf = await pdfjsLib.getDocument({ data: new Uint8Array(buffer) }).promise;
    
    let fullText = "";
    for (let i = 1; i <= pdf.numPages; i++) {
        const page = await pdf.getPage(i);
        const textContent = await page.getTextContent();
        fullText += textContent.items.map(s => s.str).join(" ");
    }
    
    state.cvText = fullText;
    status.textContent = "Ready to Begin";
    status.style.borderColor = "var(--primary)";
    status.style.color = "white";
    document.getElementById('startBtn').style.display = "flex";
};

document.getElementById('startBtn').onclick = async () => {
    const success = await initAudio();
    if(!success) return;

    document.getElementById('setupPanel').style.display = 'none';
    document.getElementById('activePanel').style.display = 'block';
    document.getElementById('timer').classList.add('active');
    
    // FIXED TIMER: Assigned to variable so it can be cleared later
    timerInterval = setInterval(() => {
        if(state.timeLeft <= 0) finishSession();
        state.timeLeft--;
        const m = Math.floor(state.timeLeft / 60);
        const s = state.timeLeft % 60;
        timerDisplay.textContent = `${m}:${s < 10 ? '0'+s : s}`;
    }, 1000);

    // Initial AI Handshake
    orb.classList.add('thinking');
    status.textContent = "Reviewing Profile...";
    
    const fd = new FormData();
    fd.append("mode", "start");
    fd.append("cvText", state.cvText);
    
    try {
        const res = await fetch(API_URL, { method: "POST", body: fd });
        const data = await res.json();
        state.history = data.history;
        speak(data.reply);
    } catch (e) {
        alert("Could not connect to AI Server.");
        status.textContent = "Server Offline.";
    }
};

document.getElementById('endBtn').onclick = finishSession;

async function finishSession() {
    // Clean up timer and listening states properly
    clearInterval(timerInterval); 
    try { recognition.stop(); } catch(e){}
    window.speechSynthesis.cancel();
    
    document.getElementById('activePanel').style.display = 'none';
    orb.classList.remove('listening');
    orb.classList.add('thinking');
    status.textContent = "Generating Final Score...";
    
    const fd = new FormData();
    fd.append("mode", "score");
    fd.append("history", JSON.stringify(state.history));
    
    try {
        const res = await fetch(API_URL, { method: "POST", body: fd });
        const data = await res.json();
        document.getElementById('reportText').textContent = data.reply;
    } catch(e) {
        document.getElementById('reportText').textContent = "Could not generate score due to a server error.";
    }
    
    document.getElementById('reportModal').style.display = 'flex';
}
</script>
</body>
</html>
