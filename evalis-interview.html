let chatHistory = [];
let isInterviewActive = false;
const synth = window.speechSynthesis;

// 1. AI SPEAKS & THEN LISTENS
function aiSpeak(text) {
  const utter = new SpeechSynthesisUtterance(text);
  utter.onend = () => {
    if (isInterviewActive) startRecordingCycle(); // Start listening only AFTER AI finishes
  };
  synth.speak(utter);
}

// 2. CONTINUOUS CYCLE
async function startRecordingCycle() {
  const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
  const recorder = new MediaRecorder(stream);
  const chunks = [];

  recorder.ondataavailable = e => chunks.push(e.data);
  recorder.onstop = async () => {
    const fd = new FormData();
    fd.append("audio", new Blob(chunks));
    fd.append("mode", "interview");
    fd.append("cvText", extractedCVText);
    fd.append("history", JSON.stringify(chatHistory));

    const res = await fetch(API_URL, { method: "POST", body: fd });
    const data = await res.json();
    
    chatHistory = data.newHistory;
    aiSpeak(data.nextQuestion); // AI talks, then trigger next cycle
  };

  recorder.start();
  // Automatically "Submit" after 7 seconds of speaking
  setTimeout(() => { if(recorder.state === "recording") recorder.stop(); }, 7000);
}
