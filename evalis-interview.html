<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0"/>
<title>Evalis AI Interview</title>

<!-- Voice Activity Detection -->
<script src="https://unpkg.com/@ricky0123/vad-web@0.0.7/dist/bundle.standard.js"></script>

<style>
body {
  margin: 0;
  background: #020617;
  font-family: system-ui, sans-serif;
  height: 100vh;
  display: flex;
  justify-content: center;
  align-items: center;
  color: #e5e7eb;
}

.card {
  background: #0f172a;
  width: 340px;
  padding: 32px;
  border-radius: 20px;
  border: 1px solid #1e293b;
  text-align: center;
}

#status {
  font-size: 11px;
  color: #3b82f6;
  text-transform: uppercase;
  margin-bottom: 14px;
}

#question {
  font-size: 15px;
  color: #cbd5f5;
  min-height: 70px;
  margin-bottom: 20px;
}

button {
  width: 100%;
  padding: 14px;
  border-radius: 12px;
  border: none;
  background: #2563eb;
  color: white;
  font-weight: 700;
  cursor: pointer;
}

button:disabled {
  background: #1e293b;
  color: #64748b;
}

.pulse {
  width: 12px;
  height: 12px;
  background: #22c55e;
  border-radius: 50%;
  margin: 0 auto 14px;
  display: none;
  animation: pulse 1.2s infinite;
}

@keyframes pulse {
  0% { transform: scale(1); opacity: 1; }
  50% { transform: scale(1.4); opacity: 0.6; }
  100% { transform: scale(1); opacity: 1; }
}
</style>
</head>

<body>

<div class="card">
  <div class="pulse" id="pulse"></div>
  <div id="status">Evalis AI Ready</div>
  <div id="question">Tap start and speak to begin</div>
  <button id="startBtn">Start Interview</button>
</div>

<script>
const startBtn   = document.getElementById("startBtn");
const statusEl   = document.getElementById("status");
const questionEl = document.getElementById("question");
const pulse      = document.getElementById("pulse");

const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
const synth = window.speechSynthesis;

if (!SpeechRecognition) {
  statusEl.innerText = "Browser not supported";
  questionEl.innerText = "Please use Chrome browser.";
  startBtn.disabled = true;
}

const questions = [
  "Tell me about yourself.",
  "What experience do you have related to this role?",
  "Describe a challenge you handled well.",
  "Why should we hire you?"
];

let qIndex = 0;
let recognition;
let vadInstance;
let interviewStarted = false;

function speak(text) {
  synth.cancel();
  questionEl.innerText = text;
  statusEl.innerText = "Evalis AI Speaking";
  const u = new SpeechSynthesisUtterance(text);
  u.rate = 0.95;
  u.onend = () => statusEl.innerText = "Listeningâ€¦";
  synth.speak(u);
}

startBtn.onclick = async () => {
  startBtn.style.display = "none";
  statusEl.innerText = "Requesting microphoneâ€¦";

  try {
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });

    recognition = new SpeechRecognition();
    recognition.lang = "en-US";
    recognition.continuous = false;

    recognition.onresult = () => {
      recognition.stop();

      // ðŸ”“ First speech unlocks interview (mobile fix)
      if (!interviewStarted) {
        interviewStarted = true;
        speak(questions[0]);
        return;
      }

      qIndex++;
      if (qIndex < questions.length) {
        speak(questions[qIndex]);
      } else {
        statusEl.innerText = "Interview Completed";
        questionEl.innerText = "Thank you. Interview complete.";
        pulse.style.display = "none";
      }
    };

    vadInstance = await vad.MicVAD.new({
      stream,
      onSpeechStart: () => {
        pulse.style.display = "block";
        if (synth.speaking) synth.cancel();
      },
      onSpeechEnd: () => {
        pulse.style.display = "none";
        try { recognition.start(); } catch(e){}
      }
    });

    vadInstance.start();
    statusEl.innerText = "Listeningâ€¦ Speak now";

  } catch (err) {
    statusEl.innerText = "Microphone blocked";
    questionEl.innerText = "Allow mic access and refresh.";
    startBtn.style.display = "block";
  }
};
</script>

</body>
</html>
