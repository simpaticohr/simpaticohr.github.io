<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Evalis AI – Live Interview</title>

<script src="https://cdnjs.cloudflare.com/ajax/libs/pdf.js/3.11.174/pdf.min.js"></script>

<style>
:root{
  --primary:#6366f1;
  --bg:#020617;
  --card:rgba(255,255,255,.05);
  --border:rgba(255,255,255,.1);
  --ok:#10b981;
  --bad:#ef4444;
  --warn:#f59e0b;
}
*{box-sizing:border-box}
body{
  margin:0;background:var(--bg);color:#fff;
  font-family:system-ui,sans-serif;
  display:flex;justify-content:center;align-items:center;
  min-height:100vh
}
.back-btn{
  position:fixed;top:16px;left:16px;
  background:rgba(255,255,255,.08);
  border:1px solid var(--border);
  padding:10px 16px;border-radius:12px;
  color:#fff;cursor:pointer;z-index:9
}
.container{
  width:95%;max-width:1100px;
  display:grid;grid-template-columns:1fr 1fr;gap:24px
}
@media(max-width:900px){.container{grid-template-columns:1fr}}
.card{
  background:var(--card);
  border:1px solid var(--border);
  border-radius:24px;padding:28px;
  box-shadow:0 25px 50px rgba(0,0,0,.5)
}
h1,h2{margin:0 0 6px}
p{margin:0;color:#94a3b8;font-size:14px}
#timer{
  font-size:42px;font-weight:800;
  color:var(--primary);text-align:center;margin:16px 0
}
#status{text-align:center;font-size:14px;color:#94a3b8;margin-bottom:16px}
input[type=file]{
  width:100%;padding:14px;border-radius:12px;
  background:transparent;color:#fff;
  border:2px dashed var(--border)
}
button{
  width:100%;padding:16px;border-radius:14px;
  font-size:16px;font-weight:700;border:none;cursor:pointer
}
.btn-primary{background:var(--primary);color:#fff}
.btn-danger{background:var(--bad);color:#fff}
.btn-secondary{background:rgba(255,255,255,.1);color:#fff;margin-top:8px}
button:disabled{opacity:.4}
.log{max-height:460px;overflow-y:auto}
.msg{
  margin-bottom:14px;padding:12px 16px;border-radius:12px
}
.msg.user{background:rgba(103,232,249,.1);border-left:3px solid #67e8f9}
.msg.ai{background:rgba(165,180,252,.1);border-left:3px solid #a5b4fc}
.vosk{
  margin-top:16px;padding:12px 16px;
  border-radius:12px;border:1px solid var(--border);
  background:rgba(255,255,255,.03);font-size:13px
}
.ok{color:var(--ok)}
.bad{color:var(--bad)}
.warn{color:var(--warn)}
.manual-input{
  margin-top:12px;
  display:flex;gap:8px;
}
.manual-input input{
  flex:1;
  padding:12px;
  border-radius:10px;
  border:1px solid var(--border);
  background:rgba(255,255,255,.05);
  color:#fff;
}
</style>
</head>

<body>

<button class="back-btn" id="backBtn">← Back</button>

<div class="container">

<!-- LEFT -->
<div class="card">
  <h1>Evalis AI Interview</h1>
  <p>Vosk powered live interview</p>

  <div id="timer">15:00</div>
  <div id="status">Upload resume to begin</div>

  <input type="file" id="cvInput" accept=".pdf"><br><br>

  <button id="startBtn" class="btn-primary" disabled>Start Interview</button>
  <button id="endBtn" class="btn-danger" style="display:none">End Interview</button>

  <div class="vosk" id="voskBox" style="display:none">
    <div>Vosk Engine: <span id="voskStatus" class="ok">Active</span></div>
    <div>Microphone: <span id="micStatus" class="warn">Initializing...</span></div>
    <div>Mode: <span id="modeStatus">Continuous</span></div>
  </div>
</div>

<!-- RIGHT -->
<div class="card">
  <h2>Conversation</h2>
  <p>Live transcript</p>
  <div class="log" id="log"></div>
  
  <!-- Manual input fallback -->
  <div class="manual-input" id="manualInput" style="display:none">
    <input type="text" id="textInput" placeholder="Type your answer and press Enter...">
    <button id="sendBtn" class="btn-secondary" style="width:auto;padding:12px 20px">Send</button>
  </div>
</div>

</div>

<script>
/* ================== CONFIG ================== */
const API = "https://evalis-ai.simpaticohrconsultancy.workers.dev";

/* ================== ELEMENTS ================== */
const cvInput = document.getElementById("cvInput");
const startBtn = document.getElementById("startBtn");
const endBtn = document.getElementById("endBtn");
const status = document.getElementById("status");
const timer = document.getElementById("timer");
const logBox = document.getElementById("log");
const voskBox = document.getElementById("voskBox");
const backBtn = document.getElementById("backBtn");
const manualInput = document.getElementById("manualInput");
const textInput = document.getElementById("textInput");
const sendBtn = document.getElementById("sendBtn");
const micStatus = document.getElementById("micStatus");
const modeStatus = document.getElementById("modeStatus");

/* ================== STATE ================== */
let cvText = "";
let history = [];
let interviewActive = false;
let isAISpeaking = false;
let isProcessing = false;
let timeLeft = 15 * 60;
let timerInt = null;
let recognition = null;
let useManualInput = false;

/* ================== PDF ================== */
const pdfjsLib = window['pdfjs-dist/build/pdf'];
pdfjsLib.GlobalWorkerOptions.workerSrc =
  "https://cdnjs.cloudflare.com/ajax/libs/pdf.js/3.11.174/pdf.worker.min.js";

cvInput.addEventListener("change", async (e) => {
  try {
    const file = e.target.files[0];
    if (!file) return;

    status.textContent = "Loading resume...";

    const pdf = await pdfjsLib.getDocument(
      await file.arrayBuffer()
    ).promise;

    let text = "";
    for (let i = 1; i <= pdf.numPages; i++) {
      const page = await pdf.getPage(i);
      const content = await page.getTextContent();
      text += content.items.map(x => x.str).join(" ") + " ";
    }

    cvText = text.trim() || "[Resume uploaded]";
    startBtn.disabled = false;
    status.textContent = "Resume ready ✓ Click Start Interview";

  } catch (err) {
    console.error(err);
    status.textContent = "Resume load failed. Try again.";
  }
});

/* ================== TIMER ================== */
function startTimer(){
  timerInt = setInterval(()=>{
    timeLeft--;
    timer.textContent =
      `${Math.floor(timeLeft/60)}:${String(timeLeft%60).padStart(2,"0")}`;
    if(timeLeft<=0) finishInterview();
  },1000);
}

/* ================== TTS ================== */
function speak(text){
  return new Promise(res=>{
    isAISpeaking = true;
    status.textContent = "AI is speaking...";
    const u = new SpeechSynthesisUtterance(text);
    u.rate = .95;
    u.onend = () => { 
      isAISpeaking = false; 
      if(interviewActive) status.textContent = useManualInput ? "Type your response..." : "Listening... Speak now";
      res(); 
    };
    addMsg("ai", text);
    speechSynthesis.speak(u);
  });
}

/* ================== SPEECH RECOGNITION ================== */
function initSpeechRecognition() {
  const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
  
  if (!SpeechRecognition) {
    console.warn("Speech recognition not supported, falling back to manual input");
    enableManualInput();
    return false;
  }

  recognition = new SpeechRecognition();
  recognition.continuous = true;
  recognition.interimResults = false;
  recognition.lang = 'en-US';

  recognition.onstart = () => {
    micStatus.textContent = "Connected";
    micStatus.className = "ok";
    status.textContent = "Listening... Speak now";
  };

  recognition.onresult = (event) => {
    const last = event.results.length - 1;
    const text = event.results[last][0].transcript;
    
    if (event.results[last].isFinal && !isProcessing && !isAISpeaking) {
      processUser(text);
    }
  };

  recognition.onerror = (event) => {
    console.error("Speech recognition error:", event.error);
    if (event.error === 'not-allowed') {
      status.textContent = "Microphone blocked. Switching to text input...";
      enableManualInput();
    } else {
      // Restart on other errors
      if (interviewActive && !useManualInput) {
        setTimeout(() => {
          try { recognition.start(); } catch(e) {}
        }, 1000);
      }
    }
  };

  recognition.onend = () => {
    // Restart if interview still active and not using manual input
    if (interviewActive && !useManualInput) {
      try { recognition.start(); } catch(e) {}
    }
  };

  return true;
}

function enableManualInput() {
  useManualInput = true;
  manualInput.style.display = "flex";
  micStatus.textContent = "Disabled";
  micStatus.className = "bad";
  modeStatus.textContent = "Text Input";
  status.textContent = "Type your response...";
}

/* ================== MANUAL INPUT ================== */
textInput.addEventListener("keypress", (e) => {
  if (e.key === "Enter") sendManualInput();
});

sendBtn.addEventListener("click", sendManualInput);

function sendManualInput() {
  const text = textInput.value.trim();
  if (!text || isProcessing || isAISpeaking) return;
  
  processUser(text);
  textInput.value = "";
}

/* ================== USER INPUT ================== */
async function processUser(text){
  if (!text || text.length < 2) return;
  
  isProcessing = true;
  status.textContent = "Thinking...";
  addMsg("user", text);

  try{
    const fd = new FormData();
    fd.append("mode","interview");
    fd.append("history",JSON.stringify(history));
    fd.append("text",text);
    fd.append("cvText",cvText);

    const r = await fetch(API,{method:"POST",body:fd});
    const d = await r.json();
    history = d.history || history;

    if(d.reply) await speak(d.reply);
    else await speak("Can you explain that further?");
  }catch(err){
    console.error(err);
    await speak("I'm having trouble connecting. Please try again.");
  }

  isProcessing = false;
}

/* ================== START ================== */
startBtn.onclick = async () => {
  interviewActive = true;
  startBtn.style.display = "none";
  endBtn.style.display = "block";
  cvInput.style.display = "none";
  voskBox.style.display = "block";

  status.textContent = "Starting interview...";
  startTimer();

  // Initialize speech recognition
  const speechSupported = initSpeechRecognition();
  if (speechSupported) {
    try {
      recognition.start();
    } catch(e) {
      enableManualInput();
    }
  }

  try{
    const fd = new FormData();
    fd.append("mode","start");
    fd.append("cvText",cvText);
    const r = await fetch(API,{method:"POST",body:fd});
    const d = await r.json();
    history = d.history || [];
    await speak(d.reply || "Welcome. Tell me about yourself.");
  }catch(err){
    console.error(err);
    await speak("Welcome. Tell me about yourself.");
  }
};

/* ================== END ================== */
endBtn.onclick = () => confirm("End interview?") && finishInterview();

async function finishInterview(){
  interviewActive = false;
  clearInterval(timerInt);
  speechSynthesis.cancel();
  
  if (recognition) {
    try { recognition.stop(); } catch(e) {}
  }

  status.textContent = "Generating report...";

  try {
    const fd = new FormData();
    fd.append("mode","score");
    fd.append("history",JSON.stringify(history));
    fd.append("cvText",cvText);

    const r = await fetch(API,{method:"POST",body:fd});
    const d = await r.json();

    document.body.innerHTML = `
      <div class="card" style="max-width:800px;margin:20px auto">
        <h1>Interview Complete</h1>
        <pre style="white-space:pre-wrap">${d.reply || "Report coming soon"}</pre>
        <button class="btn-primary" onclick="location.reload()">New Interview</button>
      </div>`;
  } catch(err) {
    document.body.innerHTML = `
      <div class="card" style="max-width:800px;margin:20px auto">
        <h1>Interview Complete</h1>
        <p>Thank you for completing the interview.</p>
        <button class="btn-primary" onclick="location.reload()">New Interview</button>
      </div>`;
  }
}

/* ================== UI ================== */
function addMsg(role,text){
  const d = document.createElement("div");
  d.className = "msg " + role;
  d.innerHTML = `<b>${role==="ai"?"AI":"You"}:</b> ${text}`;
  logBox.appendChild(d);
  logBox.scrollTop = logBox.scrollHeight;
}

/* ================== NAV ================== */
backBtn.onclick = () => {
  if (interviewActive && !confirm("End interview and go back?")) return;
  finishInterview();
  location.href = "career-lab.html";
};
history.pushState(null,"",location.href);
window.onpopstate = () => backBtn.click();
</script>

</body>
</html>
