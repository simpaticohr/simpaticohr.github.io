<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Evalis AI – Live Interview</title>

<script src="https://cdnjs.cloudflare.com/ajax/libs/pdf.js/3.11.174/pdf.min.js"></script>

<style>
:root{--primary:#6366f1;--bg:#020617}
body{
  margin:0;background:var(--bg);color:#fff;
  font-family:system-ui,sans-serif;
  display:flex;justify-content:center;align-items:center;
  min-height:100vh
}
.card{
  width:90%;max-width:460px;
  background:rgba(255,255,255,.05);
  border-radius:24px;padding:28px;
  border:1px solid rgba(255,255,255,.1);
  box-shadow:0 25px 50px rgba(0,0,0,.5);
  text-align:center
}
#timer{font-size:26px;color:var(--primary);font-weight:700}
#status{font-size:12px;color:#94a3b8;margin:10px 0 20px}
button{
  width:100%;padding:16px;border-radius:14px;
  border:none;font-weight:700;font-size:16px;
  cursor:pointer
}
.start{background:var(--primary);color:#fff}
.end{background:#ef4444;color:#fff}
button:disabled{opacity:.4}
#log{margin-top:20px;text-align:left;max-height:220px;overflow:auto}
.msg{margin-bottom:12px;padding:10px 14px;border-radius:12px}
.ai{background:rgba(165,180,252,.1)}
.user{background:rgba(103,232,249,.1)}
</style>
</head>

<body>

<div class="card">
  <div id="timer">15:00</div>
  <div id="status">Upload resume to start</div>

  <input type="file" id="cvInput" accept=".pdf"><br><br>
  <button id="startBtn" class="start" disabled>Start Interview</button>
  <button id="endBtn" class="end" style="display:none">End Interview</button>

  <div id="log"></div>
</div>

<script>
/* ================= CONFIG ================= */
const API="https://evalis-ai.simpaticohrconsultancy.workers.dev";

/* ================= STATE ================= */
let cvText="",history=[];
let interviewActive=false,isAISpeaking=false,isProcessing=false;
let recognition=null;
let timer=15*60,timerInt;

/* ================= PDF ================= */
const pdfjsLib=window['pdfjs-dist/build/pdf'];
pdfjsLib.GlobalWorkerOptions.workerSrc=
"https://cdnjs.cloudflare.com/ajax/libs/pdf.js/3.11.174/pdf.worker.min.js";

cvInput.onchange=async e=>{
  const pdf=await pdfjsLib.getDocument(await e.target.files[0].arrayBuffer()).promise;
  let t="";
  for(let i=1;i<=pdf.numPages;i++){
    const p=await pdf.getPage(i);
    const c=await p.getTextContent();
    t+=c.items.map(x=>x.str).join(" ")+" ";
  }
  cvText=t.trim()||"[Resume]";
  startBtn.disabled=false;
  status.textContent="Resume ready ✓";
};

/* ================= TIMER ================= */
function startTimer(){
  timerInt=setInterval(()=>{
    timer--;
    timerEl.textContent=`${Math.floor(timer/60)}:${String(timer%60).padStart(2,"0")}`;
    if(timer<=0) finish();
  },1000);
}

/* ================= TTS ================= */
function speak(text){
  return new Promise(res=>{
    isAISpeaking=true;
    status.textContent="AI speaking…";
    add("ai",text);

    const u=new SpeechSynthesisUtterance(text);
    u.rate=0.95;

    u.onend=()=>{
      isAISpeaking=false;
      status.textContent="Listening…";
      if(interviewActive) restartRecognition();
      res();
    };

    speechSynthesis.cancel();
    speechSynthesis.speak(u);
  });
}

/* ================= SPEECH RECOGNITION ================= */
function initRecognition(){
  const SR=window.SpeechRecognition||window.webkitSpeechRecognition;
  recognition=new SR();
  recognition.lang="en-US";
  recognition.continuous=true;
  recognition.interimResults=false;

  recognition.onresult=e=>{
    const text=e.results[e.results.length-1][0].transcript.trim();
    if(!text||isAISpeaking||isProcessing) return;
    processUser(text);
  };

  recognition.onerror=()=>restartRecognition();
  recognition.onend=()=>restartRecognition();
}

function restartRecognition(){
  if(!interviewActive||isAISpeaking) return;
  try{ recognition.start(); }catch{}
}

/* ================= USER ================= */
async function processUser(text){
  isProcessing=true;
  status.textContent="Thinking…";
  add("user",text);

  try{
    const fd=new FormData();
    fd.append("mode","interview");
    fd.append("text",text);
    fd.append("cvText",cvText);
    fd.append("history",JSON.stringify(history));
    const r=await fetch(API,{method:"POST",body:fd});
    const d=await r.json();
    history=d.history||history;
    await speak(d.reply||"Please continue.");
  }catch{
    await speak("Could you explain that further?");
  }
  isProcessing=false;
}

/* ================= START ================= */
startBtn.onclick=async()=>{
  speechSynthesis.speak(new SpeechSynthesisUtterance("")); // unlock
  interviewActive=true;
  startTimer();
  initRecognition();
  restartRecognition();

  startBtn.style.display="none";
  cvInput.style.display="none";
  endBtn.style.display="block";

  const fd=new FormData();
  fd.append("mode","start");
  fd.append("cvText",cvText);
  const r=await fetch(API,{method:"POST",body:fd});
  const d=await r.json();
  history=d.history||[];
  await speak(d.reply||"Tell me about yourself.");
};

/* ================= END ================= */
endBtn.onclick=finish;

async function finish(){
  interviewActive=false;
  clearInterval(timerInt);
  if(recognition) recognition.stop();
  speechSynthesis.cancel();
  status.textContent="Generating report…";

  const fd=new FormData();
  fd.append("mode","score");
  fd.append("history",JSON.stringify(history));
  fd.append("cvText",cvText);
  const r=await fetch(API,{method:"POST",body:fd});
  const d=await r.json();

  document.body.innerHTML=`
    <div class="card">
      <h2>Interview Complete</h2>
      <pre style="white-space:pre-wrap">${d.reply}</pre>
      <button class="start" onclick="location.reload()">New Interview</button>
    </div>`;
}

/* ================= UI ================= */
const timerEl=document.getElementById("timer");
function add(role,text){
  const d=document.createElement("div");
  d.className="msg "+role;
  d.innerHTML=`<b>${role==="ai"?"AI":"You"}:</b> ${text}`;
  log.appendChild(d);
  log.scrollTop=log.scrollHeight;
}
</script>
</body>
</html>
