<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<title>AI Mock Interview | Simpatico HR</title>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<script src="https://cdnjs.cloudflare.com/ajax/libs/pdf.js/3.11.174/pdf.min.js"></script>
<style>
  :root { --accent: #2563eb; --bg: #0b1d3a; --danger: #dc2626; }
  body { font-family: 'Inter', sans-serif; background: var(--bg); color: white; display: flex; align-items: center; justify-content: center; min-height: 100vh; margin: 0; }
  .card { width: 90%; max-width: 450px; background: rgba(255,255,255,0.05); padding: 30px; border-radius: 24px; border: 1px solid rgba(255,255,255,0.1); text-align: center; }
  .pulse { width: 80px; height: 80px; background: var(--accent); border-radius: 50%; margin: 20px auto; display: none; animation: pulse-animation 1.5s infinite; }
  @keyframes pulse-animation { 0% { box-shadow: 0 0 0 0px rgba(37, 99, 235, 0.7); } 100% { box-shadow: 0 0 0 20px rgba(37, 99, 235, 0); } }
  button { width: 100%; padding: 15px; border-radius: 12px; border: none; background: var(--accent); color: white; font-weight: 700; cursor: pointer; margin-top: 15px; }
  button:disabled { background: #475569; cursor: not-allowed; }
  #endBtn { background: var(--danger); display: none; }
  #log { background: rgba(0,0,0,0.3); padding: 15px; border-radius: 12px; height: 220px; overflow-y: auto; font-size: 13px; text-align: left; margin-top: 20px; color: #cbd5e1; border: 1px solid rgba(255,255,255,0.05); }
  .report-box { background: #1e293b; padding: 15px; border-radius: 10px; border-left: 4px solid var(--accent); margin-top: 10px; }
</style>
</head>
<body>

<div class="card">
  <h2>AI Interviewer</h2>
  <p id="status">Upload CV to begin</p>
  <input type="file" id="cvFile" accept=".pdf,.txt" style="margin-bottom: 10px; font-size: 12px; width: 100%;">
  <div id="micVisual" class="pulse"></div>
  <button id="startBtn" disabled>ðŸŽ¤ Start Interview</button>
  <button id="endBtn">ðŸ›‘ End & Generate Report</button>
  <div id="log">Welcome. Upload your resume to start.</div>
</div>

<script>
/* ===== CONFIG ===== */
const API_URL = "https://evalis-ai.simpaticohrconsultancy.workers.dev";
const pdfjsLib = window['pdfjs-dist/build/pdf'];
pdfjsLib.GlobalWorkerOptions.workerSrc = 'https://cdnjs.cloudflare.com/ajax/libs/pdf.js/3.11.174/pdf.worker.min.js';

/* ===== STATE ===== */
let chatHistory = [];
let isInterviewActive = false;
let isProcessing = false; // The critical lock
let globalCVText = "";
const synth = window.speechSynthesis;

const statusEl = document.getElementById("status");
const logEl = document.getElementById("log");
const micVisual = document.getElementById("micVisual");
const startBtn = document.getElementById("startBtn");
const endBtn = document.getElementById("endBtn");

/* ===== 1. PDF PARSER ===== */
document.getElementById("cvFile").onchange = async (e) => {
  const file = e.target.files[0];
  statusEl.innerText = "Reading CV...";
  try {
    if (file.type === "application/pdf") {
      const reader = new FileReader();
      reader.onload = async function() {
        const pdf = await pdfjsLib.getDocument(new Uint8Array(this.result)).promise;
        let text = "";
        for (let i = 1; i <= pdf.numPages; i++) {
          const page = await pdf.getPage(i);
          const content = await page.getTextContent();
          text += content.items.map(s => s.str).join(" ");
        }
        globalCVText = text;
        statusEl.innerText = "Resume Ready";
        startBtn.disabled = false;
      };
      reader.readAsArrayBuffer(file);
    } else {
      globalCVText = await file.text();
      statusEl.innerText = "Resume Ready";
      startBtn.disabled = false;
    }
  } catch (err) { statusEl.innerText = "Error loading CV."; }
};

/* ===== 2. VOICE OUTPUT ===== */
function aiSpeak(text) {
  if (!text || text === "undefined") {
    isProcessing = false;
    return;
  }
  
  logEl.innerHTML += `<br><b>AI:</b> ${text}`;
  logEl.scrollTop = logEl.scrollHeight;

  const utterance = new SpeechSynthesisUtterance(text);
  utterance.onend = () => { 
    isProcessing = false; // Release lock only after speaking finishes
    if (isInterviewActive) startRecording(); 
  };
  synth.speak(utterance);
}

/* ===== 3. VOICE INPUT (MERCOR-STYLE) ===== */

async function startRecording() {
  if (isProcessing || !isInterviewActive) return;
  
  try {
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    const recorder = new MediaRecorder(stream);
    const chunks = [];

    micVisual.style.display = "block";
    statusEl.innerText = "Listening...";

    recorder.ondataavailable = e => chunks.push(e.data);
    
    recorder.onstop = async () => {
      isProcessing = true; // Lock state
      micVisual.style.display = "none";
      statusEl.innerText = "Analyzing your answer...";
      stream.getTracks().forEach(t => t.stop());

      const fd = new FormData();
      fd.append("audio", new Blob(chunks, { type: "audio/webm" }));
      fd.append("mode", "interview");
      fd.append("cvText", globalCVText);
      fd.append("history", JSON.stringify(chatHistory));

      try {
        // High-speed transcription via Whisper Large v3 Turbo
        const res = await fetch(API_URL, { method: "POST", body: fd });
        const data = await res.json();
        
        if (data.nextQuestion) {
          chatHistory = data.newHistory || chatHistory;
          aiSpeak(data.nextQuestion);
        } else {
          throw new Error("Invalid response");
        }
      } catch (err) {
        statusEl.innerText = "Network Error. Retrying...";
        isProcessing = false;
        setTimeout(() => { if(isInterviewActive) startRecording(); }, 3000);
      }
    };

    recorder.start();
    setTimeout(() => { if(recorder.state === "recording") recorder.stop(); }, 8000);
    
  } catch (err) {
    statusEl.innerText = "Mic Error.";
    isInterviewActive = false;
  }
}

/* ===== 4. HANDLERS ===== */
startBtn.onclick = () => {
  isInterviewActive = true;
  startBtn.style.display = "none";
  endBtn.style.display = "block";
  document.getElementById("cvFile").style.display = "none";
  // Initial prompt uses Llama 3.3 70B for deep CV context
  aiSpeak("I've reviewed your background. Based on your resume, can you walk me through your most significant technical achievement?");
};

endBtn.onclick = async () => {
  isInterviewActive = false;
  synth.cancel();
  statusEl.innerText = "Generating Final Report...";
  endBtn.disabled = true;

  const fd = new FormData();
  fd.append("mode", "evaluate");
  fd.append("history", JSON.stringify(chatHistory));

  try {
    const res = await fetch(API_URL, { method: "POST", body: fd });
    const data = await res.json();
    
    logEl.innerHTML = `<div class="report-box">
      <h3>Interview Performance Report</h3>
      <p style="white-space: pre-wrap;">${data.report}</p>
    </div>`;
    statusEl.innerText = "Interview Complete";
  } catch (err) { statusEl.innerText = "Report failed."; }
};
</script>
</body>
</html>
