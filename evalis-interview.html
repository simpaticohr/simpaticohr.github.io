// --- Continuous Listening Loop ---
async function startTurn() {
    if(!active || busy || timeLeft <= 0) return;
    
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    const rec = new MediaRecorder(stream);
    const chunks = [];
    
    document.getElementById('status').innerText = "INTERVIEWER LISTENING...";

    rec.ondataavailable = e => chunks.push(e.data);
    rec.onstop = async () => {
        busy = true;
        document.getElementById('status').innerText = "THINKING...";
        
        const fd = new FormData();
        fd.append("mode", "interview");
        fd.append("audio", new Blob(chunks, {type: 'audio/webm'}), "a.webm");
        fd.append("cvText", cvText);
        fd.append("history", JSON.stringify(history));

        try {
            const res = await fetch(WORKER_URL, { method: "POST", body: fd });
            const data = await res.json();
            
            if (data.reply) {
                history = data.history;
                updateTranscript(data.transcript, data.reply);
                speak(data.reply); // Next question starts the loop again
            }
        } catch (e) { busy = false; startTurn(); }
        stream.getTracks().forEach(t => t.stop());
    };

    rec.start();
    // VAD Simulation: AI listens for technical depth
    setTimeout(() => { if(rec.state === "recording") rec.stop(); }, 8000); 
}

function speak(text) {
    window.speechSynthesis.cancel();
    const ut = new SpeechSynthesisUtterance(text);
    ut.onend = () => { 
        busy = false; 
        if(active) setTimeout(startTurn, 300); // RE-OPEN MIC IMMEDIATELY
    };
    window.speechSynthesis.speak(ut);
}
