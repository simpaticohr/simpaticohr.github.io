<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<title>Spoken English Practice | Simpatico HR</title>
<meta name="viewport" content="width=device-width, initial-scale=1" />

<style>
body {
  margin: 0;
  background: #020617;
  font-family: system-ui, -apple-system, BlinkMacSystemFont;
  color: #e5e7eb;
  display: flex;
  justify-content: center;
  align-items: center;
  min-height: 100vh;
}
.card {
  width: 380px;
  background: #0f172a;
  border-radius: 16px;
  padding: 24px;
  border: 1px solid #1e293b;
}
h2 {
  text-align: center;
  margin: 0;
}
#status {
  text-align: center;
  font-size: 13px;
  color: #38bdf8;
  margin: 10px 0 16px;
}
button {
  width: 100%;
  padding: 14px;
  border-radius: 12px;
  border: none;
  font-weight: 600;
  cursor: pointer;
}
#startBtn {
  background: #2563eb;
  color: #fff;
}
#stopBtn {
  background: #1e293b;
  color: #fff;
  margin-top: 10px;
}
.result {
  margin-top: 16px;
  font-size: 14px;
  line-height: 1.5;
}
.score {
  text-align: center;
  font-size: 32px;
  font-weight: 700;
  margin-top: 12px;
}
</style>
</head>

<body>
<div class="card">
  <h2>Spoken English Practice</h2>
  <div id="status">Tap start and speak for 5 seconds</div>

  <button id="startBtn">ðŸŽ¤ Start Speaking</button>
  <button id="stopBtn" disabled>Stop</button>

  <div id="output" class="result"></div>
</div>

<script>
const WORKER_URL = "https://evalis-ai.simpaticohrconsultancy.workers.dev";

let recorder;
let audioChunks = [];
let stream;

const startBtn = document.getElementById("startBtn");
const stopBtn = document.getElementById("stopBtn");
const statusEl = document.getElementById("status");
const outputEl = document.getElementById("output");

startBtn.onclick = async () => {
  try {
    stream = await navigator.mediaDevices.getUserMedia({ audio: true });

    recorder = new MediaRecorder(stream, { mimeType: "audio/webm" });
    audioChunks = [];

    recorder.ondataavailable = e => {
      if (e.data.size > 0) audioChunks.push(e.data);
    };

    recorder.onstop = async () => {
      statusEl.textContent = "Evaluating...";
      startBtn.disabled = true;
      stopBtn.disabled = true;

      const blob = new Blob(audioChunks, { type: "audio/webm" });
      const buffer = await blob.arrayBuffer();

      try {
        const res = await fetch(WORKER_URL, {
          method: "POST",
          headers: {
            "Content-Type": "application/octet-stream"
          },
          body: buffer
        });

        const data = await res.json();

        outputEl.innerHTML = `
          <strong>You said:</strong><br>
          ${data.transcript || "(No speech detected)"}<br><br>

          <strong>Feedback:</strong><br>
          ${data.feedback || "Try again."}

          <div class="score">${data.score ?? 0}/10</div>
        `;

        statusEl.textContent = "Completed";

      } catch (err) {
        statusEl.textContent = "Server unavailable.";
        outputEl.innerHTML = "";
      }

      stream.getTracks().forEach(t => t.stop());
      startBtn.disabled = false;
    };

    recorder.start();
    statusEl.textContent = "Speaking...";
    startBtn.disabled = true;
    stopBtn.disabled = false;

    setTimeout(() => {
      if (recorder.state === "recording") recorder.stop();
    }, 5000);

  } catch (err) {
    alert("Microphone permission denied.");
  }
};

stopBtn.onclick = () => {
  if (recorder && recorder.state === "recording") {
    recorder.stop();
  }
};
</script>
</body>
</html>
