<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>Spoken English Practice | Simpatico HR</title>
<meta name="viewport" content="width=device-width, initial-scale=1">

<style>
body {
  margin: 0;
  background: #020617;
  font-family: system-ui;
  color: #e5e7eb;
  display: flex;
  justify-content: center;
  align-items: center;
  min-height: 100vh;
}
.card {
  width: 420px;
  background: #0f172a;
  border-radius: 18px;
  padding: 28px;
  border: 1px solid #1e293b;
}
h2 { text-align: center; margin-top: 0; }
#status {
  font-size: 13px;
  color: #38bdf8;
  text-align: center;
  margin: 10px 0;
}
button {
  width: 100%;
  padding: 14px;
  border-radius: 12px;
  border: none;
  background: #2563eb;
  color: white;
  font-weight: 600;
  cursor: pointer;
}
button.secondary {
  background: #1e293b;
  margin-top: 10px;
}
.result {
  margin-top: 18px;
  font-size: 14px;
  line-height: 1.6;
}
.score {
  font-size: 32px;
  font-weight: 700;
  text-align: center;
  margin-top: 10px;
}
</style>
</head>

<body>
<div class="card">
  <h2>Spoken English Practice</h2>
  <div id="status">Tap start and speak clearly for 5 seconds</div>

  <button id="startBtn">ðŸŽ¤ Start Speaking</button>
  <button id="stopBtn" class="secondary" disabled>Stop</button>

  <div id="output" class="result"></div>
</div>

<script>
let recorder;
let chunks = [];
let stream;
let audioContext;

const statusEl = document.getElementById("status");
const outputEl = document.getElementById("output");
const startBtn = document.getElementById("startBtn");
const stopBtn = document.getElementById("stopBtn");

const WORKER_URL = "https://evalis-ai.simpaticohrconsultancy.workers.dev";

startBtn.onclick = async () => {
  try {
    stream = await navigator.mediaDevices.getUserMedia({
      audio: {
        echoCancellation: true,
        noiseSuppression: true,
        autoGainControl: true
      }
    });

    /* ðŸ”Š MOBILE MIC BOOST (CRITICAL FIX) */
    audioContext = new AudioContext();
    const source = audioContext.createMediaStreamSource(stream);
    const gainNode = audioContext.createGain();
    gainNode.gain.value = 3.0; // boost volume
    source.connect(gainNode);

    recorder = new MediaRecorder(stream, { mimeType: "audio/webm" });
    chunks = [];

    recorder.ondataavailable = e => {
      if (e.data && e.data.size > 0) chunks.push(e.data);
    };

    recorder.onstop = async () => {
      stopBtn.disabled = true;
      statusEl.textContent = "Evaluating your English...";

      if (chunks.length === 0) {
        statusEl.textContent = "No audio captured.";
        startBtn.disabled = false;
        return;
      }

      const blob = new Blob(chunks, { type: "audio/webm" });
      const form = new FormData();
      form.append("audio", blob, "speech.webm");

      try {
        const res = await fetch(WORKER_URL, {
          method: "POST",
          body: form
        });

        const data = await res.json();

        outputEl.innerHTML = `
          <strong>You said:</strong><br>
          ${data.transcript || "(No speech detected)"}<br><br>

          <strong>Feedback:</strong><br>
          ${data.feedback || "Please speak clearly and continuously."}

          <div class="score">${data.score ?? 0}/10</div>
        `;

        statusEl.textContent = "Completed";

      } catch (err) {
        statusEl.textContent = "Evaluation failed.";
        outputEl.innerHTML = "";
      } finally {
        startBtn.disabled = false;
        stream.getTracks().forEach(t => t.stop());
        audioContext && audioContext.close();
      }
    };

    recorder.start();
    statusEl.textContent = "Speaking...";
    startBtn.disabled = true;
    stopBtn.disabled = false;

    setTimeout(() => {
      if (recorder.state === "recording") recorder.stop();
    }, 5000);

  } catch (err) {
    alert("Microphone permission denied.");
  }
};

stopBtn.onclick = () => {
  if (recorder && recorder.state === "recording") {
    recorder.stop();
  }
};
</script>

</body>
</html>
